{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06e2b67",
   "metadata": {},
   "source": [
    "# Epidemiology of CRRT- Analysis\n",
    "\n",
    "Author: Kaveri Chhikara\n",
    "\n",
    "Run this script after 01_cohort_identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6219f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import warnings\n",
    "import pyarrow\n",
    "from tableone import TableOne\n",
    "import seaborn as sns\n",
    "import sofa_score  \n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pyCLIF\n",
    "output_folder = '../output'\n",
    "## import outlier json\n",
    "with open('../config/outlier_config.json', 'r', encoding='utf-8') as f:\n",
    "    outlier_cfg = json.load(f)\n",
    "\n",
    "import os\n",
    "output_dir = \"../output/final\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba27607f",
   "metadata": {},
   "source": [
    "# Load CLIF wide and other cohort datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65075c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ids_df = pd.read_parquet(f'{output_folder}/intermediate/all_ids.parquet')\n",
    "adt_final_df = pd.read_parquet(f'{output_folder}/intermediate/adt_final.parquet')\n",
    "clif_wide_df = pd.read_parquet(f'{output_folder}/intermediate/clif_wide.parquet')\n",
    "crrt_df = pd.read_parquet(f'{output_folder}/intermediate/crrt_df.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd417188",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== all_ids_df dtypes ===\")\n",
    "print(all_ids_df.dtypes)\n",
    "print(\"\\n=== adt_final_df dtypes ===\") \n",
    "print(adt_final_df.dtypes)\n",
    "print(\"\\n=== clif_wide_df dtypes ===\")\n",
    "print(clif_wide_df.dtypes)\n",
    "print(\"\\n=== crrt_df dtypes ===\")\n",
    "print(crrt_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb1b989",
   "metadata": {},
   "source": [
    "# Combine CLIF wide with ADT\n",
    "\n",
    "Combine CLIF wide with ADT and forward fill location category and location type columns to get patient location info at each time point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb867033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) ANNOTATE CLIF-WIDE RECORDS WITH ADT LOCATION (FORWARD-FILL ONLY)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "adt_int = adt_final_df[[\n",
    "    \"encounter_block\",\n",
    "    \"in_dttm\", \"out_dttm\",\n",
    "    \"location_category\", \"location_type\"\n",
    "]]\n",
    "\n",
    "# 1a) Every flowsheet row matched to all ADT intervals for that encounter\n",
    "merged = clif_wide_df.merge(adt_int, on=\"encounter_block\", how=\"left\")\n",
    "\n",
    "# 1b) Keep only rows where recorded_dttm ∈ [in_dttm, out_dttm]\n",
    "mask = (\n",
    "    (merged[\"recorded_dttm\"] >= merged[\"in_dttm\"]) &\n",
    "    (merged[\"recorded_dttm\"] <= merged[\"out_dttm\"])\n",
    ")\n",
    "annot = merged.loc[mask, \n",
    "    [\"encounter_block\", \"recorded_dttm\", \"location_category\", \"location_type\"]\n",
    "].copy()\n",
    "\n",
    "# 1c) Forward-fill per encounter_block\n",
    "annot = (\n",
    "    annot\n",
    "    .sort_values([\"encounter_block\",\"recorded_dttm\"])\n",
    "    .groupby(\"encounter_block\", as_index=False)\n",
    "    .apply(lambda df: df.ffill())\n",
    "    .dropna(subset=[\"location_category\",\"location_type\"], how=\"all\")\n",
    "    # now has a flat index: (encounter_block, recorded_dttm, ...)\n",
    ")\n",
    "\n",
    "# 1d) Re-index `annot` on the two keys\n",
    "annot_indexed = annot.set_index([\"encounter_block\",\"recorded_dttm\"])[\n",
    "    [\"location_category\",\"location_type\"]\n",
    "]\n",
    "\n",
    "# 1e) Join back onto `clif_wide_df`\n",
    "clif_wide_df = (\n",
    "    clif_wide_df\n",
    "      .set_index([\"encounter_block\",\"recorded_dttm\"])\n",
    "      .join(annot_indexed, how=\"left\")\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Now clif_wide_annot has the ADT location forward-filled from the last interval that\n",
    "# covered each timestamp, with no peeking into future ADT rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603a116e",
   "metadata": {},
   "source": [
    "# Table One\n",
    "\n",
    "* Pre- 24 hr CRRT start\n",
    "* Post-24 hr CRRT start\n",
    "* Post-72 hr CRRT start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f209cf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 0) CONSTANTS & INPUTS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "output_folder = \"../output\"\n",
    "os.makedirs(os.path.join(output_folder, \"final\"), exist_ok=True)\n",
    "\n",
    "# path & mapping for SOFA\n",
    "tables_path = pyCLIF.helper['tables_path']\n",
    "id_mappings = all_ids_df[['encounter_block','hospitalization_id']].drop_duplicates()\n",
    "\n",
    "# lists of variables\n",
    "demog_cols    = [\"age_at_admission\",\"sex_category\",\"race_category\",\"ethnicity_category\"]\n",
    "adt_cols      = [\"location_category\",\"location_type\"]\n",
    "device_col    = \"device_category\"\n",
    "\n",
    "continuous_vars = [\n",
    "    # vasoactives\n",
    "    \"angiotensin\",\"dobutamine\",\"dopamine\",\"epinephrine\",\n",
    "    \"norepinephrine\",\"phenylephrine\",\"vasopressin\",\n",
    "    # labs\n",
    "    \"bicarbonate\",\"bun\",\"calcium_total\",\"chloride\",\"creatinine\",\"magnesium\",\n",
    "    \"glucose_serum\",\"lactate\",\"potassium\",\"sodium\",\"ph_arterial\",\n",
    "    # vents\n",
    "    \"fio2_set\",\"peep_set\",\"resp_rate_set\",\"tidal_volume_set\",\n",
    "    \"pressure_control_set\",\"pressure_support_set\",\"peak_inspiratory_pressure_set\",\n",
    "]\n",
    "\n",
    "crrt_vars = [\n",
    "    \"blood_flow_rate\",\n",
    "    \"pre_filter_replacement_fluid_rate\",\n",
    "    \"post_filter_replacement_fluid_rate\",\n",
    "    \"dialysate_flow_rate\",\n",
    "    \"ultrafiltration_out\",\n",
    "]\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) FIRST CRRT START PER ENCOUNTER\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "first_crrt = (\n",
    "    crrt_df\n",
    "    .groupby(\"encounter_block\", as_index=False)[\"recorded_dttm\"]\n",
    "    .min()\n",
    "    .rename(columns={\"recorded_dttm\":\"first_crrt_time\"})\n",
    ")\n",
    "\n",
    "# pull demographics + death\n",
    "demog = (\n",
    "    all_ids_df\n",
    "    .set_index(\"encounter_block\")[demog_cols + [\"death_dttm\"]]\n",
    ")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) helper: summarize any window\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def summarize_window(start_offset_h: int, end_offset_h: int, include_crrt: bool):\n",
    "    \"\"\"\n",
    "    Summarize for each encounter_block in [first_crrt_time+start_offset_h, first_crrt_time+end_offset_h]:\n",
    "     - demographics + died_within_window\n",
    "     - median [Q1,Q3] of continuous_vars\n",
    "     - last non-null ADT location + type\n",
    "     - last non-null device_category\n",
    "     - SOFA components + total\n",
    "     - if include_crrt: last CRRT mode + median [Q1,Q3] of crrt_vars\n",
    "    Returns DataFrame indexed by encounter_block.\n",
    "    \"\"\"\n",
    "\n",
    "    # 2a) window definitions\n",
    "    start_off = pd.Timedelta(hours=start_offset_h)\n",
    "    end_off   = pd.Timedelta(hours=end_offset_h)\n",
    "    bounds    = first_crrt.copy()\n",
    "    bounds[\"win_start\"] = bounds[\"first_crrt_time\"] + start_off\n",
    "    bounds[\"win_end\"]   = bounds[\"first_crrt_time\"] + end_off\n",
    "    bnd        = bounds.set_index(\"encounter_block\")\n",
    "\n",
    "    # 2b) CLIF-wide flowsheet slice\n",
    "    cw = (\n",
    "        clif_wide_df\n",
    "        .merge(bounds[[\"encounter_block\",\"win_start\",\"win_end\"]], on=\"encounter_block\", how=\"inner\")\n",
    "    )\n",
    "    cw = cw[(cw.recorded_dttm >= cw.win_start) & (cw.recorded_dttm <= cw.win_end)]\n",
    "\n",
    "    # continuous vars: median & IQR\n",
    "    med = cw.groupby(\"encounter_block\")[continuous_vars].median()\n",
    "    q1  = cw.groupby(\"encounter_block\")[continuous_vars].quantile(0.25)\n",
    "    q3  = cw.groupby(\"encounter_block\")[continuous_vars].quantile(0.75)\n",
    "    cont = (\n",
    "        med.add_suffix(\"_median\")\n",
    "           .join(q1.add_suffix(\"_q1\"))\n",
    "           .join(q3.add_suffix(\"_q3\"))\n",
    "    )\n",
    "\n",
    "    # ADT location/type: last non-null in window\n",
    "    loc_win = cw.dropna(subset=adt_cols, how=\"all\")\n",
    "    last_loc = (\n",
    "        loc_win.sort_values(\"recorded_dttm\")\n",
    "               .groupby(\"encounter_block\")[adt_cols]\n",
    "               .last()\n",
    "    )\n",
    "\n",
    "    # device_category: last non-null in window\n",
    "    dev_win = cw.dropna(subset=[device_col])\n",
    "    last_dev = (\n",
    "        dev_win.sort_values(\"recorded_dttm\")\n",
    "               .groupby(\"encounter_block\")[[device_col]]\n",
    "               .last()\n",
    "    )\n",
    "\n",
    "    # mortality flag\n",
    "    death_flag = (\n",
    "        demog[\"death_dttm\"]\n",
    "        .between(bnd[\"win_start\"], bnd[\"win_end\"])\n",
    "        .rename(\"died_within_window\")\n",
    "    )\n",
    "\n",
    "    # assemble core\n",
    "    df = (\n",
    "        bnd\n",
    "        .join(demog.drop(columns=\"death_dttm\"))\n",
    "        .join(death_flag)\n",
    "        .join(cont)\n",
    "        .join(last_loc)\n",
    "        .join(last_dev)\n",
    "    )\n",
    "\n",
    "    # 2c) SOFA\n",
    "    sofa_in = bounds[[\"encounter_block\"]].copy()\n",
    "    sofa_in[\"start_dttm\"] = bounds[\"win_start\"]\n",
    "    sofa_in[\"stop_dttm\"]  = bounds[\"win_end\"]\n",
    "    sofa_out = sofa_score.compute_sofa(\n",
    "        ids_w_dttm            = sofa_in,\n",
    "        tables_path           = tables_path,\n",
    "        use_hospitalization_id= False,\n",
    "        id_mapping            = id_mappings,\n",
    "        helper_module         = pyCLIF,\n",
    "        output_filepath       = None\n",
    "    )\n",
    "    sofa_cols = [\n",
    "      \"sofa_cv_97\",\"sofa_coag\",\"sofa_renal\",\n",
    "      \"sofa_liver\",\"sofa_resp\",\"sofa_cns\",\"sofa_total\"\n",
    "    ]\n",
    "    sofa_df = sofa_out.set_index(\"encounter_block\")[sofa_cols]\n",
    "    df = df.join(sofa_df)\n",
    "\n",
    "    # 2d) CRRT-specific (optional)\n",
    "    if include_crrt:\n",
    "        cr = crrt_df.merge(bounds.reset_index(), on=\"encounter_block\", how=\"inner\")\n",
    "        cr_win = cr[(cr.recorded_dttm >= cr.win_start) & (cr.recorded_dttm <= cr.win_end)]\n",
    "\n",
    "        # last CRRT mode\n",
    "        mode_win = cr_win.dropna(subset=[\"crrt_mode_category\"])\n",
    "        last_mode = (\n",
    "            mode_win.sort_values(\"recorded_dttm\")\n",
    "                    .groupby(\"encounter_block\")[\"crrt_mode_category\"]\n",
    "                    .last()\n",
    "                    .rename(\"last_crrt_mode\")\n",
    "        )\n",
    "\n",
    "        # CRRT cont. vars\n",
    "        cm = cr_win.groupby(\"encounter_block\")[crrt_vars].median()\n",
    "        c1 = cr_win.groupby(\"encounter_block\")[crrt_vars].quantile(0.25)\n",
    "        c3 = cr_win.groupby(\"encounter_block\")[crrt_vars].quantile(0.75)\n",
    "        crrt_cont = (\n",
    "            cm.add_suffix(\"_median\")\n",
    "              .join(c1.add_suffix(\"_q1\"))\n",
    "              .join(c3.add_suffix(\"_q3\"))\n",
    "        )\n",
    "\n",
    "        df = df.join(last_mode).join(crrt_cont)\n",
    "\n",
    "    return df.drop(columns=[\"first_crrt_time\",\"win_start\",\"win_end\"])\n",
    "\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) BUILD THE THREE WINDOWS\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "pre24  = summarize_window(-24,  0, include_crrt=False)\n",
    "post24 = summarize_window(  0, 24, include_crrt=True)\n",
    "post72 = summarize_window(  0, 72, include_crrt=True)\n",
    "\n",
    "# tag & stack\n",
    "for df, lbl in [(pre24,\"Pre-24h\"),(post24,\"Post-24h\"),(post72,\"Post-72h\")]:\n",
    "    df[\"window\"] = lbl\n",
    "\n",
    "combined = pd.concat([pre24,post24,post72], axis=0).reset_index()\n",
    "combined.to_csv(os.path.join(output_folder,\"intermediate\",\"combined_summary.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9aa327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) MAKE TABLEONE FOR EACH WINDOW (with SOFA)\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "def make_tableone(summary_df, window_label):\n",
    "    df = summary_df.reset_index()\n",
    "\n",
    "    # base set of categorical & continuous variables\n",
    "    cat_vars = [\n",
    "      \"sex_category\",\"race_category\",\"ethnicity_category\",\n",
    "      \"location_category\",\"location_type\",\"device_category\",\n",
    "      \"died_within_window\"\n",
    "    ]\n",
    "\n",
    "    cont_vars = (\n",
    "      [\"age_at_admission\"]\n",
    "      + continuous_vars\n",
    "      # add SOFA components here:\n",
    "      + [\"sofa_cv_97\",\"sofa_coag\",\"sofa_renal\",\n",
    "         \"sofa_liver\",\"sofa_resp\",\"sofa_cns\",\"sofa_total\"]\n",
    "    )\n",
    "\n",
    "    # for post-windows also include CRRT mode + CRRT vars\n",
    "    if \"last_crrt_mode\" in df.columns:\n",
    "        cat_vars.append(\"last_crrt_mode\")\n",
    "        cont_vars += crrt_vars\n",
    "\n",
    "    # flatten any *_median → base var and drop *_q1/_q3\n",
    "    for v in continuous_vars + crrt_vars:\n",
    "        m = f\"{v}_median\"\n",
    "        if m in df:\n",
    "            df[v] = df.pop(m)\n",
    "        for suf in (\"_q1\",\"_q3\"):\n",
    "            col = v + suf\n",
    "            if col in df:\n",
    "                df.pop(col)\n",
    "\n",
    "    # Round vasopressors to 4 decimal places\n",
    "    vasopressors = [\"angiotensin\", \"dobutamine\", \"dopamine\", \"epinephrine\",\n",
    "                    \"norepinephrine\", \"phenylephrine\", \"vasopressin\"]\n",
    "    for v in vasopressors:\n",
    "        if v in df.columns:\n",
    "            df[v] = df[v].round(4)\n",
    "\n",
    "    # build the TableOne; for all cont_vars it will automatically compute\n",
    "    # median [IQR] because we pass them in `nonnormal=`\n",
    "    tbl = TableOne(\n",
    "      df,\n",
    "      columns     = cat_vars + cont_vars,\n",
    "      categorical = cat_vars,\n",
    "      nonnormal   = cont_vars,\n",
    "      groupby     = None\n",
    "    )\n",
    "\n",
    "    # save & return\n",
    "    fname = f\"table1_{window_label.replace(' ','_')}.csv\"\n",
    "    tbl.to_csv(os.path.join(output_folder,\"final\",fname))\n",
    "    print(\"Table saved to:\", f\"{output_folder}/final/{fname}\")\n",
    "    return tbl\n",
    "\n",
    "# regenerate your tables:\n",
    "table_pre24  = make_tableone(pre24,  \"Pre-24h\")\n",
    "table_post24 = make_tableone(post24, \"Post-24h\")\n",
    "table_post72 = make_tableone(post72, \"Post-72h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500572ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 1) Extract the underlying pandas DataFrames from each TableOne\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "df_pre24  = pd.DataFrame(table_pre24.tableone).rename(columns={0: \"Pre-24h\",   \"Overall\": \"pre24_summary\", \"Missing\": \"pre24_missing\"})\n",
    "df_post24 = pd.DataFrame(table_post24.tableone).rename(columns={0: \"Post-24h\", \"Overall\": \"post24_summary\", \"Missing\": \"post24_missing\"})\n",
    "df_post72 = pd.DataFrame(table_post72.tableone).rename(columns={0: \"Post-72h\", \"Overall\": \"post72_summary\", \"Missing\": \"post72_missing\"})\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 2) Join them on their index (the \"characteristic\" labels) using post24/72 order\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# Get reference order from post24 or post72 if they exist\n",
    "ref_order = None\n",
    "if not df_post24.empty:\n",
    "    ref_order = df_post24.index.tolist()\n",
    "elif not df_post72.empty:\n",
    "    ref_order = df_post72.index.tolist()\n",
    "\n",
    "combined = (\n",
    "    df_pre24\n",
    "      .join(df_post24, how=\"outer\")\n",
    "      .join(df_post72, how=\"outer\")\n",
    ")\n",
    "\n",
    "# Reorder rows if we have a reference order\n",
    "if ref_order:\n",
    "    # Only use existing indices from reference order\n",
    "    valid_indices = [idx for idx in ref_order if idx in combined.index]\n",
    "    # Add any remaining indices that weren't in reference\n",
    "    remaining = combined.index.difference(valid_indices).tolist()\n",
    "    combined = combined.reindex(valid_indices + remaining)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 3) Clean up the index name and display\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "combined.index.name = \"Characteristic\"\n",
    "combined.reset_index(inplace=True)\n",
    "\n",
    "# Drop all *_missing columns\n",
    "missing_cols = [col for col in combined.columns if col.endswith('_missing')]\n",
    "combined = combined.drop(columns=missing_cols)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "# 4) Save to CSV if you like\n",
    "# ─────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "filename = f\"table1_all_windows_{pyCLIF.helper['site_name']}.csv\"\n",
    "combined.to_csv(os.path.join(output_folder, \"final\", filename), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31275d8c",
   "metadata": {},
   "source": [
    "# CRRT summary by modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa273891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first settings for each patient\n",
    "first_settings = crrt_df.sort_values(['encounter_block', 'recorded_dttm']).groupby(['encounter_block', 'crrt_mode_category']).first()\n",
    "\n",
    "# Get numeric columns for analysis\n",
    "numeric_cols = ['blood_flow_rate', 'pre_filter_replacement_fluid_rate', \n",
    "               'post_filter_replacement_fluid_rate', 'dialysate_flow_rate',\n",
    "               'ultrafiltration_out']\n",
    "\n",
    "# Calculate median and IQR of first settings by mode\n",
    "first_settings_summary = first_settings[numeric_cols].groupby('crrt_mode_category').agg(['median', lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)])\n",
    "first_settings_summary.columns = first_settings_summary.columns.map(lambda x: f\"{x[0]}_{x[1]}\" if x[1] == 'median' else f\"{x[0]}_q1\" if x[1] == '<lambda_0>' else f\"{x[0]}_q3\")\n",
    "\n",
    "# Calculate mean settings across entire hospitalization by mode\n",
    "hosp_avg_settings = crrt_df.groupby(['encounter_block', 'crrt_mode_category'])[numeric_cols].mean()\n",
    "mode_avg_settings = hosp_avg_settings.groupby('crrt_mode_category').agg(['mean', 'std'])\n",
    "mode_avg_settings.columns = mode_avg_settings.columns.map(lambda x: f\"{x[0]}_{x[1]}\")\n",
    "\n",
    "# Calculate duration for each mode\n",
    "crrt_df['next_time'] = crrt_df.groupby('encounter_block')['recorded_dttm'].shift(-1)\n",
    "crrt_df['duration_hrs'] = (crrt_df['next_time'] - crrt_df['recorded_dttm']).dt.total_seconds() / 3600\n",
    "\n",
    "mode_duration = crrt_df.groupby(['encounter_block', 'crrt_mode_category'])['duration_hrs'].sum()\n",
    "duration_summary = mode_duration.groupby('crrt_mode_category').agg(['mean', 'std', 'median', \n",
    "                                                                  lambda x: x.quantile(0.25),\n",
    "                                                                  lambda x: x.quantile(0.75)])\n",
    "duration_summary.columns = ['duration_mean_hrs', 'duration_std_hrs', 'duration_median_hrs', \n",
    "                          'duration_q1_hrs', 'duration_q3_hrs']\n",
    "\n",
    "# Save results\n",
    "first_settings_summary.to_csv(f'{output_folder}/final/crrt_first_settings.csv')\n",
    "mode_avg_settings.to_csv(f'{output_folder}/final/crrt_average_settings.csv')\n",
    "duration_summary.to_csv(f'{output_folder}/final/crrt_duration.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f351f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1) Build the display DataFrame of formatted strings\n",
    "params = [\n",
    "    \"blood_flow_rate\",\n",
    "    \"pre_filter_replacement_fluid_rate\",\n",
    "    \"post_filter_replacement_fluid_rate\",\n",
    "    \"dialysate_flow_rate\",\n",
    "    \"ultrafiltration_out\",\n",
    "]\n",
    "\n",
    "# This will be our new table: rows = modes, cols = params\n",
    "display_df = pd.DataFrame(index=first_settings_summary.index)\n",
    "\n",
    "for p in params:\n",
    "    med = first_settings_summary[f\"{p}_median\"]\n",
    "    q1  = first_settings_summary[f\"{p}_q1\"]\n",
    "    q3  = first_settings_summary[f\"{p}_q3\"]\n",
    "    \n",
    "    # format each row as \"median [q1–q3]\"\n",
    "    display_df[p] = [\n",
    "        f\"{int(m):,} [{int(lo):,}–{int(hi):,}]\" \n",
    "        if pd.notna(m) \n",
    "        else \"NA\"\n",
    "        for m, lo, hi in zip(med, q1, q3)\n",
    "    ]\n",
    "\n",
    "# optional: rename columns to more human-friendly labels\n",
    "display_df.columns = [\n",
    "    \"Blood flow (mL/hr)\",\n",
    "    \"Pre-filter repl (mL/hr)\",\n",
    "    \"Post-filter repl (mL/hr)\",\n",
    "    \"Dialysate flow (mL/hr)\",\n",
    "    \"Ultrafiltration (mL)\"\n",
    "]\n",
    "\n",
    "# Step 2) Draw with matplotlib.table\n",
    "fig, ax = plt.subplots(figsize=(10, 2 + 0.5 * len(display_df)))  # height scales with rows\n",
    "ax.axis(\"off\")\n",
    "\n",
    "tbl = ax.table(\n",
    "    cellText=display_df.values,\n",
    "    rowLabels=display_df.index,\n",
    "    colLabels=display_df.columns,\n",
    "    cellLoc=\"center\",\n",
    "    rowLoc=\"center\",\n",
    "    loc=\"center\"\n",
    ")\n",
    "\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(10)\n",
    "tbl.scale(1, 1.5)  # stretch rows a bit\n",
    "\n",
    "plt.title(f\"First CRRT Settings by CRRT Mode in {pyCLIF.helper['site_name']}: (Median [IQR])\", pad=20)\n",
    "plt.tight_layout()\n",
    "# Save the figure\n",
    "plt.savefig(f\"../output/final/graphs/first_crrt_settings.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466190dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1) Build the display DataFrame of formatted strings\n",
    "params = [\n",
    "    \"blood_flow_rate\",\n",
    "    \"pre_filter_replacement_fluid_rate\", \n",
    "    \"post_filter_replacement_fluid_rate\",\n",
    "    \"dialysate_flow_rate\",\n",
    "    \"ultrafiltration_out\"\n",
    "]\n",
    "\n",
    "# This will be our new table: rows = modes, cols = params\n",
    "display_df = pd.DataFrame(index=mode_avg_settings.index)\n",
    "\n",
    "for p in params:\n",
    "    mean = mode_avg_settings[f\"{p}_mean\"]\n",
    "    std = mode_avg_settings[f\"{p}_std\"]\n",
    "    \n",
    "    # format each row as \"mean ± std\" \n",
    "    display_df[p] = [\n",
    "        f\"{int(m):,}  ({int(s):,})\" \n",
    "        if pd.notna(m)\n",
    "        else \"NA\"\n",
    "        for m, s in zip(mean, std)\n",
    "    ]\n",
    "\n",
    "# optional: rename columns to more human-friendly labels\n",
    "display_df.columns = [\n",
    "    \"Blood flow (mL/hr)\",\n",
    "    \"Pre-filter repl (mL/hr)\", \n",
    "    \"Post-filter repl (mL/hr)\",\n",
    "    \"Dialysate flow (mL/hr)\",\n",
    "    \"Ultrafiltration (mL)\"\n",
    "]\n",
    "\n",
    "# Step 2) Draw with matplotlib.table\n",
    "fig, ax = plt.subplots(figsize=(10, 2 + 0.5 * len(display_df)))  # height scales with rows\n",
    "ax.axis(\"off\")\n",
    "\n",
    "tbl = ax.table(\n",
    "    cellText=display_df.values,\n",
    "    rowLabels=display_df.index,\n",
    "    colLabels=display_df.columns,\n",
    "    cellLoc=\"center\",\n",
    "    rowLoc=\"center\",\n",
    "    loc=\"center\"\n",
    ")\n",
    "\n",
    "tbl.auto_set_font_size(False)\n",
    "tbl.set_fontsize(10)\n",
    "tbl.scale(1, 1.5)  # stretch rows a bit\n",
    "\n",
    "plt.title(f\"Average CRRT Settings by CRRT Mode in {pyCLIF.helper['site_name']}: Mean (SD)\", pad=20)\n",
    "plt.tight_layout()\n",
    "# Save the figure\n",
    "plt.savefig(f\"../output/final/graphs/avg_crrt_settings.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7d737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add index as column for melt\n",
    "duration_summary_reset = duration_summary.reset_index()\n",
    "\n",
    "# Plot Duration on each CRRT mode\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=duration_summary_reset, \n",
    "            x='crrt_mode_category', y='duration_median_hrs', \n",
    "            color='skyblue')\n",
    "plt.errorbar(x=np.arange(len(duration_summary_reset)), \n",
    "             y=duration_summary_reset['duration_median_hrs'], \n",
    "             yerr=[duration_summary_reset['duration_median_hrs'] - duration_summary_reset['duration_q1_hrs'], \n",
    "                   duration_summary_reset['duration_q3_hrs'] - duration_summary_reset['duration_median_hrs']], \n",
    "             fmt='none', c='black', capsize=5)\n",
    "plt.title(\"Duration on CRRT Mode (Median and IQR)\")\n",
    "plt.ylabel(\"Hours\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "# Save the figure before showing and closing\n",
    "plt.savefig(f\"{output_dir}/graphs/crrt_mode_duration.png\")\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177feceb",
   "metadata": {},
   "source": [
    "# CRRT Mode Switches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze mode switches by looking at consecutive rows with different modes\n",
    "crrt_df['prev_mode'] = crrt_df.groupby('encounter_block')['crrt_mode_category'].shift(1)\n",
    "crrt_df['mode_switch'] = (\n",
    "    (crrt_df['crrt_mode_category'] != crrt_df['prev_mode']) &\n",
    "    (~crrt_df['prev_mode'].isna()) &\n",
    "    (~crrt_df['crrt_mode_category'].isna())  # ← exclude transitions TO NaN\n",
    ")\n",
    "\n",
    "# Count switches between each mode pair\n",
    "mode_switches = crrt_df[crrt_df['mode_switch']].groupby(['prev_mode', 'crrt_mode_category']).size()\n",
    "mode_switches = mode_switches.reset_index()\n",
    "mode_switches.columns = ['from_mode', 'to_mode', 'count']\n",
    "\n",
    "# Create pivot table for display\n",
    "mode_switches_pivot = mode_switches.pivot(index='from_mode', columns='to_mode', values='count').fillna(0)\n",
    "\n",
    "print(\"\\nCRRT Mode Switches:\")\n",
    "print(mode_switches_pivot)\n",
    "\n",
    "# Visualize mode switches as a heatmap\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(mode_switches_pivot, \n",
    "            annot=True, \n",
    "            fmt='.0f',\n",
    "            cmap='Blues',\n",
    "            cbar_kws={'label': f\"Number of Mode Switches {pyCLIF.helper['site_name']}\"})\n",
    "plt.title('CRRT Mode Mode Switch Matrix')\n",
    "plt.xlabel('To Mode')\n",
    "plt.ylabel('From Mode')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/graphs/crrt_mode_transitions_heatmap.png\")\n",
    "plt.close()\n",
    "\n",
    "# Calculate average number of mode switches per hospitalization\n",
    "switches_per_hosp = crrt_df.groupby('encounter_block')['mode_switch'].sum()\n",
    "avg_switches = switches_per_hosp.mean()\n",
    "median_switches = switches_per_hosp.median()\n",
    "\n",
    "print(f\"\\nAverage mode switches per hospitalization: {avg_switches:.2f}\")\n",
    "print(f\"Median mode switches per hospitalization: {median_switches:.2f}\")\n",
    "\n",
    "# Save mode switches matrix\n",
    "mode_switches_pivot.to_csv(f\"{output_dir}/crrt_mode_switches.csv\")\n",
    "\n",
    "# Save summary statistics\n",
    "with open(f\"{output_dir}/crrt_mode_switches_summary.txt\", \"w\") as f:\n",
    "    f.write(f\"Average mode switches per hospitalization: {avg_switches:.2f}\\n\")\n",
    "    f.write(f\"Median mode switches per hospitalization: {median_switches:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b545bf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure mode switches are correctly flagged\n",
    "crrt_df['prev_mode'] = crrt_df.groupby('encounter_block')['crrt_mode_category'].shift(1)\n",
    "crrt_df['mode_switch'] = (\n",
    "    crrt_df['crrt_mode_category'] != crrt_df['prev_mode']\n",
    ") & (~crrt_df['prev_mode'].isna())\n",
    "\n",
    "# Count unique encounters where a switch occurred between each mode pair\n",
    "mode_switch_encounters = (\n",
    "    crrt_df[crrt_df['mode_switch']]\n",
    "    .groupby(['prev_mode', 'crrt_mode_category'])['encounter_block']\n",
    "    .nunique()\n",
    "    .reset_index(name='encounter_count')\n",
    ")\n",
    "\n",
    "# Pivot for matrix view\n",
    "switch_matrix = mode_switch_encounters.pivot(\n",
    "    index='prev_mode',\n",
    "    columns='crrt_mode_category',\n",
    "    values='encounter_count'\n",
    ").fillna(0).astype(int)\n",
    "\n",
    "print(\"\\nUnique Encounters with CRRT Mode Switches:\")\n",
    "print(switch_matrix)\n",
    "\n",
    "# Save to CSV\n",
    "switch_matrix.to_csv(\"../output/final/unique_encounter_mode_switches.csv\")\n",
    "\n",
    "# Create heatmap for mode switches by encounter\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(switch_matrix,\n",
    "            annot=True,\n",
    "            fmt='d',\n",
    "            cmap='Blues',\n",
    "            cbar_kws={'label': 'Number of Unique Encounters with Mode Switches'})\n",
    "plt.title(f\"CRRT Mode Switches by Unique Encounters {pyCLIF.helper['site_name']}\")\n",
    "plt.xlabel('To Mode')\n",
    "plt.ylabel('From Mode')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{output_dir}/graphs/crrt_mode_transitions_by_encounter_heatmap.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024d00e8",
   "metadata": {},
   "source": [
    "# Hourly Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6ab615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build a relative‐hour field where hour=0 is 24h before CRRT\n",
    "df = (\n",
    "    clif_wide_df\n",
    "    .merge(first_crrt, on=\"encounter_block\", how=\"inner\")\n",
    ")\n",
    "# origin = first_crrt_time - 24h\n",
    "df[\"origin\"] = df[\"first_crrt_time\"] - pd.Timedelta(hours=24)\n",
    "df[\"rel_hr\"] = ((df[\"recorded_dttm\"] - df[\"origin\"]) \n",
    "                / pd.Timedelta(hours=1))\n",
    "# filter to [0, 96]\n",
    "df = df[(df[\"rel_hr\"] >= 0) & (df[\"rel_hr\"] <= 96)]\n",
    "\n",
    "# assign integer hour bins\n",
    "df[\"hour_bin\"] = df[\"rel_hr\"].floordiv(1).astype(int)\n",
    "\n",
    "# 2) Compute per‐hour median, Q1, Q3 for each variable\n",
    "agg = {}\n",
    "for v in continuous_vars:\n",
    "    agg[v] = [\"median\", lambda x: x.quantile(0.25), lambda x: x.quantile(0.75)]\n",
    "hourly = df.groupby(\"hour_bin\").agg(agg)\n",
    "# flatten columns\n",
    "hourly.columns = pd.Index([f\"{var}_{stat}\"\n",
    "                           for var,stat in hourly.columns],\n",
    "                          name=None)\n",
    "\n",
    "# 3) Plot grid of time‐series with shaded IQR and CRRT‐band\n",
    "n = len(continuous_vars)\n",
    "cols = 4\n",
    "rows = (n + cols - 1)//cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 2.5*rows), sharex=True)\n",
    "for ax, var in zip(axes.flat, continuous_vars):\n",
    "    m   = hourly[f\"{var}_median\"]\n",
    "    q1  = hourly[f\"{var}_<lambda_0>\"]  # this is the 0.25 quantile\n",
    "    q3  = hourly[f\"{var}_<lambda_1>\"]  # this is the 0.75 quantile\n",
    "\n",
    "    ax.plot(hourly.index, m)\n",
    "    ax.fill_between(hourly.index, q1, q3, alpha=0.3)\n",
    "    # highlight the first 24h of CRRT → that's rel_hr 24→48\n",
    "    ax.axvspan(24, 48, color=\"C1\", alpha=0.1)\n",
    "    ax.set_title(f\"{var} [median, IQR]\")\n",
    "    ax.set_xlim(0,96)\n",
    "    ax.set_xlabel(\"Hours\")\n",
    "    ax.set_ylabel(var)\n",
    "\n",
    "# hide any empty subplots\n",
    "for extra_ax in axes.flat[n:]:\n",
    "    extra_ax.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.suptitle(\"Trajectories of ICU Labs/Vasos/Vent Settings from CRRT-24hrs to CRRT+72hrs (Median[IQR])\", y=1.02)\n",
    "plt.savefig(\"../output/final/graphs/trajectories_median_iqr.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# save hourly data\n",
    "hourly = hourly.rename(\n",
    "    columns={f\"{v}_<lambda_0>\": f\"{v}_q1\",\n",
    "             f\"{v}_<lambda_1>\": f\"{v}_q3\"}\n",
    ")\n",
    "\n",
    "# 2) reset_index so `hour_bin` becomes a column again\n",
    "site_summary = hourly.reset_index().rename(columns={\"hour_bin\": \"hour\"})\n",
    "site_summary.to_csv(os.path.join(output_folder, \"final\", \"site_hourly_summary_median.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e400b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Build a relative‐hour field where hour=0 is 24h before CRRT\n",
    "df = (\n",
    "    clif_wide_df\n",
    "    .merge(first_crrt, on=\"encounter_block\", how=\"inner\")\n",
    ")\n",
    "# origin = first_crrt_time - 24h\n",
    "df[\"origin\"] = df[\"first_crrt_time\"] - pd.Timedelta(hours=24)\n",
    "df[\"rel_hr\"] = ((df[\"recorded_dttm\"] - df[\"origin\"]) \n",
    "                / pd.Timedelta(hours=1))\n",
    "# filter to [0, 96]\n",
    "df = df[(df[\"rel_hr\"] >= 0) & (df[\"rel_hr\"] <= 96)]\n",
    "\n",
    "# assign integer hour bins\n",
    "df[\"hour_bin\"] = df[\"rel_hr\"].floordiv(1).astype(int)\n",
    "\n",
    "# 2) Compute per‐hour mean and std for each variable\n",
    "agg = {}\n",
    "for v in continuous_vars:\n",
    "    agg[v] = [\"mean\", \"std\"]\n",
    "hourly = df.groupby(\"hour_bin\").agg(agg)\n",
    "# flatten columns\n",
    "hourly.columns = pd.Index([f\"{var}_{stat}\"\n",
    "                           for var,stat in hourly.columns],\n",
    "                          name=None)\n",
    "\n",
    "# 3) Plot grid of time‐series with shaded ±1 SD and CRRT‐band\n",
    "n = len(continuous_vars)\n",
    "cols = 4\n",
    "rows = (n + cols - 1)//cols\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 2.5*rows), sharex=True)\n",
    "for ax, var in zip(axes.flat, continuous_vars):\n",
    "    mean = hourly[f\"{var}_mean\"]\n",
    "    sd = hourly[f\"{var}_std\"]\n",
    "\n",
    "    ax.plot(hourly.index, mean)\n",
    "    ax.fill_between(hourly.index, mean-sd, mean+sd, alpha=0.3)\n",
    "    # highlight the first 24h of CRRT → that's rel_hr 24→48\n",
    "    ax.axvspan(24, 48, color=\"C1\", alpha=0.1)\n",
    "    ax.set_title(f\"{var} [mean ± SD]\")\n",
    "    ax.set_xlim(0,96)\n",
    "    ax.set_xlabel(\"Hours\")\n",
    "    ax.set_ylabel(var)\n",
    "\n",
    "# hide any empty subplots\n",
    "for extra_ax in axes.flat[n:]:\n",
    "    extra_ax.set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.suptitle(\"Trajectories of ICU Labs/Vasos/Vent Settings from CRRT-24hrs to CRRT+72hrs (Mean ± SD)\", y=1.02)\n",
    "plt.savefig(\"../output/final/graphs/trajectories_mean_sd.png\", bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# save hourly data\n",
    "hourly = hourly.rename(\n",
    "    columns={f\"{v}_<lambda_0>\": f\"{v}_q1\",\n",
    "             f\"{v}_<lambda_1>\": f\"{v}_q3\"}\n",
    ")\n",
    "\n",
    "# 2) reset_index so `hour_bin` becomes a column again\n",
    "site_summary = hourly.reset_index().rename(columns={\"hour_bin\": \"hour\"})\n",
    "site_summary.to_csv(os.path.join(output_folder, \"final\", \"site_hourly_summary_mean.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c8930b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202f0ff6",
   "metadata": {},
   "source": [
    "# Process CRRT Therapy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60987675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pyarrow\n",
    "import warnings\n",
    "import clifpy\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import clifpy\n",
    "import os\n",
    "\n",
    "print(\"=== Environment Verification ===\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"clifpy version: {clifpy.__version__}\")\n",
    "print(f\"clifpy location: {clifpy.__file__}\")\n",
    "\n",
    "print(\"\\n=== Python Path Check ===\")\n",
    "local_clifpy_path = \"/Users/kavenchhikara/Desktop/CLIF/CLIFpy\"\n",
    "if any(local_clifpy_path in path for path in sys.path):\n",
    "    print(\"⚠️  WARNING: Local CLIFpy still in path!\")\n",
    "    for path in sys.path:\n",
    "        if local_clifpy_path in path:\n",
    "            print(f\"   Found: {path}\")\n",
    "else:\n",
    "    print(\"✅ Clean environment - no local CLIFpy in path\")\n",
    "\n",
    "print(f\"\\n=== Working Directory ===\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "## import outlier json\n",
    "# with open('../config/outlier_config.json', 'r', encoding='utf-8') as f:\n",
    "#     outlier_cfg = json.load(f)\n",
    "\n",
    "print(f\"\\n=� Configuration:\")\n",
    "print(f\"   Data directory: {config['tables_path']}\")\n",
    "print(f\"   File type: {config['file_type']}\")\n",
    "print(f\"   Timezone: {config['timezone']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498513e",
   "metadata": {},
   "source": [
    "# Load intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframes saved as parquet files in 00_cohort.ipynb\n",
    "cohort_df = pd.read_parquet(\"../output/intermediate/cohort_df.parquet\")\n",
    "outcomes_df = pd.read_parquet(\"../output/intermediate/outcomes_df.parquet\")\n",
    "weight_df = pd.read_parquet(\"../output/intermediate/weight_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142c863",
   "metadata": {},
   "source": [
    "# CRRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f44dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Loading CRRT table\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from clifpy.clif_orchestrator import ClifOrchestrator\n",
    "\n",
    "# Initialize ClifOrchestrator\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=config['tables_path'],\n",
    "    filetype=config['file_type'],\n",
    "    timezone=config['timezone']\n",
    ")\n",
    "\n",
    "clif.load_table(\n",
    "    'crrt_therapy',\n",
    "    filters={'hospitalization_id': cohort_df['hospitalization_id'].unique().tolist()}\n",
    ")\n",
    "crrt_df = clif.crrt_therapy.df\n",
    "crrt_df = crrt_df.merge(\n",
    "    cohort_df[['hospitalization_id', 'encounter_block']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73757307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import handle_crrt_outliers\n",
    "\n",
    "# Apply outlier removal\n",
    "crrt_df, outlier_summary = handle_crrt_outliers(\n",
    "    crrt_df,\n",
    "    config_path='../config/outlier_config.json'\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# Validate Outlier Ranges\n",
    "# ============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRRT Parameter Distribution Validation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CRRT parameters to validate and plot\n",
    "crrt_params = {\n",
    "    'blood_flow_rate': {'expected_range': [150, 350], 'unit': 'mL/min'},\n",
    "    'dialysate_flow_rate': {'expected_range': [0, 10000], 'unit': 'mL/hr'},\n",
    "    'pre_filter_replacement_fluid_rate': {'expected_range': [0, 10000], 'unit': 'mL/hr'},\n",
    "    'post_filter_replacement_fluid_rate': {'expected_range': [0, 10000], 'unit': 'mL/hr'},\n",
    "    'ultrafiltration_out': {'expected_range': [0, 500], 'unit': 'mL/hr'}\n",
    "}\n",
    "\n",
    "# Check if means are within expected ranges\n",
    "print(\"\\n1. Validating parameter distributions...\")\n",
    "unit_warnings = []\n",
    "\n",
    "for param, info in crrt_params.items():\n",
    "    if param not in crrt_df.columns:\n",
    "        continue\n",
    "\n",
    "    values = crrt_df[param].dropna()\n",
    "    if len(values) == 0:\n",
    "        continue\n",
    "\n",
    "    mean_val = values.mean()\n",
    "    min_range, max_range = info['expected_range']\n",
    "    unit = info['unit']\n",
    "\n",
    "    print(f\"\\n   {param}:\")\n",
    "    print(f\"     Mean: {mean_val:.0f} {unit}\")\n",
    "    print(f\"     Expected range: {min_range}-{max_range} {unit}\")\n",
    "\n",
    "    # Check if mean is within range\n",
    "    if mean_val < min_range or mean_val > max_range:\n",
    "        warning_msg = f\"⚠️  WARNING: Mean ({mean_val:.0f}) is OUTSIDE expected range [{min_range}-{max_range}]\"\n",
    "        print(f\"     {warning_msg}\")\n",
    "        print(f\"     → Check if units are correct (expected: {unit})\")\n",
    "        unit_warnings.append({\n",
    "            'parameter': param,\n",
    "            'mean': mean_val,\n",
    "            'expected_range': [min_range, max_range],\n",
    "            'unit': unit\n",
    "        })\n",
    "    else:\n",
    "        print(f\"     ✓ Mean is within expected range\")\n",
    "\n",
    "if unit_warnings:\n",
    "    print(\"\\n\" + \"!\" * 80)\n",
    "    print(\"UNIT MISMATCH WARNINGS:\")\n",
    "    for w in unit_warnings:\n",
    "        print(f\"\\n   {w['parameter']}:\")\n",
    "        print(f\"     Mean: {w['mean']:.0f}\")\n",
    "        print(f\"     Expected range: {w['expected_range']} {w['unit']}\")\n",
    "        print(f\"     → Data may be in different units than expected!\")\n",
    "    print(\"!\" * 80)\n",
    "else:\n",
    "    print(\"\\n✓ All parameter means are within expected ranges\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Generate GRID Histograms: Parameters (rows) × Modes (columns)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Generating CRRT Parameter Histograms Grid by Mode\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get unique modes (sorted)\n",
    "modes = sorted(crrt_df['crrt_mode_category'].dropna().unique())\n",
    "n_modes = len(modes)\n",
    "n_params = len(crrt_params)\n",
    "\n",
    "# Create grid: rows = parameters, columns = modes\n",
    "fig, axes = plt.subplots(n_params, n_modes, figsize=(5 * n_modes, 4 * n_params))\n",
    "\n",
    "# Handle single row/column cases\n",
    "if n_params == 1 and n_modes == 1:\n",
    "    axes = np.array([[axes]])\n",
    "elif n_params == 1:\n",
    "    axes = axes.reshape(1, -1)\n",
    "elif n_modes == 1:\n",
    "    axes = axes.reshape(-1, 1)\n",
    "\n",
    "fig.suptitle('CRRT Parameter Distributions by Mode (After Outlier Removal)',\n",
    "            fontsize=16, fontweight='bold', y=0.995)\n",
    "\n",
    "# Plot grid\n",
    "for row_idx, (param, info) in enumerate(crrt_params.items()):\n",
    "    for col_idx, mode in enumerate(modes):\n",
    "        ax = axes[row_idx, col_idx]\n",
    "\n",
    "        # Check if parameter exists in data\n",
    "        if param not in crrt_df.columns:\n",
    "            ax.text(0.5, 0.5, f'{param}\\nNot Available',\n",
    "                    ha='center', va='center', fontsize=10)\n",
    "            ax.set_title(f'{mode.upper()}')\n",
    "            continue\n",
    "\n",
    "        # Filter data for this mode and parameter\n",
    "        mode_data = crrt_df[\n",
    "            (crrt_df['crrt_mode_category'] == mode) &\n",
    "            (crrt_df[param].notna())\n",
    "        ][param]\n",
    "\n",
    "        if len(mode_data) == 0:\n",
    "            ax.text(0.5, 0.5, 'No Data', ha='center', va='center', fontsize=10)\n",
    "            ax.set_title(f'{mode.upper()}')\n",
    "            continue\n",
    "\n",
    "        # Create histogram\n",
    "        ax.hist(mode_data, bins=20, alpha=0.7, color='steelblue', edgecolor='black')\n",
    "\n",
    "        # Calculate statistics\n",
    "        n = len(mode_data)\n",
    "        mean_val = mode_data.mean()\n",
    "        median_val = mode_data.median()\n",
    "\n",
    "        # Add vertical lines for mean and median\n",
    "        ax.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_val:.0f}')\n",
    "        ax.axvline(median_val, color='green', linestyle=':', linewidth=2, label=f'Median: {median_val:.0f}')\n",
    "\n",
    "        # Add statistics text box\n",
    "        stats_text = f'N = {n:,}\\nMean = {mean_val:.0f}\\nMedian = {median_val:.0f}'\n",
    "        ax.text(0.98, 0.97, stats_text, transform=ax.transAxes,\n",
    "                verticalalignment='top', horizontalalignment='right',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8),\n",
    "                fontsize=9)\n",
    "\n",
    "        # Set title (mode name) for top row only\n",
    "        if row_idx == 0:\n",
    "            ax.set_title(f'{mode.upper()}', fontsize=12, fontweight='bold')\n",
    "\n",
    "        # Set ylabel (parameter name) for first column only\n",
    "        if col_idx == 0:\n",
    "            ax.set_ylabel(f'{param.replace(\"_\", \" \").title()}\\n({info[\"unit\"]})',\n",
    "                        fontsize=10, fontweight='bold')\n",
    "\n",
    "        # Set xlabel for bottom row only\n",
    "        if row_idx == n_params - 1:\n",
    "            ax.set_xlabel(f'{info[\"unit\"]}', fontsize=9)\n",
    "\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.legend(loc='upper left', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "Path(\"../output/final\").mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig('../output/final/graphs/crrt_parameter_histograms_grid.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Grid histograms saved to: output/final/crrt_parameter_histograms_grid.png\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# Summary Statistics: Distribution of Settings by Mode Category\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRRT Settings Distribution by Mode Category\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for mode in modes:\n",
    "    mode_df = crrt_df[crrt_df['crrt_mode_category'] == mode]\n",
    "\n",
    "    row = {\n",
    "        'Mode': mode.upper(),\n",
    "        'N_Total': len(mode_df)\n",
    "    }\n",
    "\n",
    "    for param, info in crrt_params.items():\n",
    "        if param in mode_df.columns:\n",
    "            values = mode_df[param].dropna()\n",
    "            n = len(values)\n",
    "\n",
    "            if n > 0:\n",
    "                row[f'{param}_N'] = n\n",
    "                row[f'{param}_Mean'] = round(values.mean(), 1)\n",
    "                row[f'{param}_SD'] = round(values.std(), 1)\n",
    "                row[f'{param}_Median'] = round(values.median(), 1)\n",
    "                row[f'{param}_Q25'] = round(values.quantile(0.25), 1)\n",
    "                row[f'{param}_Q75'] = round(values.quantile(0.75), 1)\n",
    "                row[f'{param}_Min'] = round(values.min(), 1)\n",
    "                row[f'{param}_Max'] = round(values.max(), 1)\n",
    "            else:\n",
    "                row[f'{param}_N'] = 0\n",
    "                row[f'{param}_Mean'] = np.nan\n",
    "                row[f'{param}_SD'] = np.nan\n",
    "                row[f'{param}_Median'] = np.nan\n",
    "                row[f'{param}_Q25'] = np.nan\n",
    "                row[f'{param}_Q75'] = np.nan\n",
    "                row[f'{param}_Min'] = np.nan\n",
    "                row[f'{param}_Max'] = np.nan\n",
    "\n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Display summary\n",
    "print(\"\\nSummary by Mode (first few columns):\")\n",
    "display_cols = ['Mode', 'N_Total'] + [col for col in summary_df.columns if '_Mean' in col or '_Median' in col]\n",
    "print(summary_df[display_cols].to_string(index=False))\n",
    "\n",
    "# Save detailed summary\n",
    "summary_df.to_csv('../output/final/crrt_settings_distribution_by_mode.csv', index=False)\n",
    "print(f\"\\n✓ Detailed summary saved to: output/final/crrt_settings_distribution_by_mode.csv\")\n",
    "\n",
    "# Also create a simplified summary for quick reference\n",
    "simple_summary = []\n",
    "for mode in modes:\n",
    "    mode_df = crrt_df[crrt_df['crrt_mode_category'] == mode]\n",
    "\n",
    "    row = {'Mode': mode.upper(), 'N': len(mode_df)}\n",
    "\n",
    "    for param, info in crrt_params.items():\n",
    "        if param in mode_df.columns:\n",
    "            values = mode_df[param].dropna()\n",
    "            if len(values) > 0:\n",
    "                # Format as \"Median [Q25-Q75]\"\n",
    "                row[param] = f\"{values.median():.0f} [{values.quantile(0.25):.0f}-{values.quantile(0.75):.0f}]\"\n",
    "            else:\n",
    "                row[param] = \"No data\"\n",
    "\n",
    "    simple_summary.append(row)\n",
    "\n",
    "simple_summary_df = pd.DataFrame(simple_summary)\n",
    "\n",
    "# Display simple summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Quick Reference: Median [IQR] by Mode\")\n",
    "print(\"=\" * 80)\n",
    "print(simple_summary_df.to_string(index=False))\n",
    "\n",
    "# Save simple summary\n",
    "simple_summary_df.to_csv('../output/final/crrt_settings_summary_simple.csv', index=False)\n",
    "print(f\"\\n✓ Simple summary saved to: output/final/crrt_settings_summary_simple.csv\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb256a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Processing CRRT Data\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"   CRRT therapy loaded: {len(clif.crrt_therapy.df):,} rows\")\n",
    "print(f\"   Unique CRRT therapy hospitalizations: {clif.crrt_therapy.df['hospitalization_id'].nunique()}\")\n",
    "# ============================================================================\n",
    "# STEP 1: Define CRRT Initiation Time\n",
    "# ============================================================================\n",
    "print(\"\\n1. Defining CRRT initiation time...\")\n",
    "\n",
    "# Filter crrt_df to only include hospitalization_ids present in the cohort\n",
    "crrt_cohort = crrt_df[crrt_df['hospitalization_id'].isin(cohort_df['hospitalization_id'])].copy()\n",
    "\n",
    "# Sort by encounter_block and time\n",
    "crrt_cohort = crrt_cohort.sort_values(['encounter_block', 'recorded_dttm'])\n",
    "\n",
    "# Create indicator for any CRRT activity (any non-null flow rate)\n",
    "crrt_cohort['has_crrt_activity'] = (\n",
    "    crrt_cohort['dialysate_flow_rate'].notna() |\n",
    "    crrt_cohort['ultrafiltration_out'].notna() |\n",
    "    crrt_cohort['pre_filter_replacement_fluid_rate'].notna() |\n",
    "    crrt_cohort['post_filter_replacement_fluid_rate'].notna()\n",
    ")\n",
    "\n",
    "# Get CRRT initiation time (first non-null flow rate per encounter_block)\n",
    "crrt_initiation = (crrt_cohort[crrt_cohort['has_crrt_activity']]\n",
    "                    .groupby('encounter_block')\n",
    "                    .agg({'recorded_dttm': 'min'})\n",
    "                    .reset_index())\n",
    "crrt_initiation.rename(columns={'recorded_dttm': 'crrt_initiation_time'}, inplace=True)\n",
    "\n",
    "print(f\"   CRRT initiation times identified for: {len(crrt_initiation):,} encounter_blocks\")\n",
    "print(f\"   Date range: {crrt_initiation['crrt_initiation_time'].min()} to {crrt_initiation['crrt_initiation_time'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed1f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show number of unique encounter_blocks in crrt_cohort and crrt_initiation\n",
    "num_blocks_cohort = crrt_cohort['encounter_block'].nunique()\n",
    "num_blocks_initiation = crrt_initiation['encounter_block'].nunique()\n",
    "\n",
    "print(f\"Unique encounter_blocks in crrt_cohort: {num_blocks_cohort}\")\n",
    "print(f\"Unique encounter_blocks in crrt_initiation: {num_blocks_initiation}\")\n",
    "\n",
    "# Analyze and explain the apparent paradox\n",
    "blocks_cohort_set = set(crrt_cohort['encounter_block'])\n",
    "blocks_initiation_set = set(crrt_initiation['encounter_block'])\n",
    "\n",
    "missing_initiation = blocks_cohort_set - blocks_initiation_set\n",
    "missing_cohort = blocks_initiation_set - blocks_cohort_set\n",
    "\n",
    "print(f\"Encounter_blocks in crrt_cohort not in crrt_initiation: {len(missing_initiation)}\")\n",
    "print(f\"Encounter_blocks in crrt_initiation not in crrt_cohort: {len(missing_cohort)}\")\n",
    "\n",
    "if len(missing_initiation) > 0:\n",
    "    print(\"Some encounter_blocks in crrt_cohort never had CRRT initiation recorded (no non-null activity).\")\n",
    "if len(missing_cohort) > 0:\n",
    "    print(\"Some encounter_blocks have CRRT initiation but aren't present in crrt_cohort (unexpected).\")\n",
    "\n",
    "# Save DataFrames explaining the differences, if any\n",
    "crrt_cohort_only = crrt_cohort.loc[crrt_cohort['encounter_block'].isin(missing_initiation)].copy()\n",
    "crrt_initiation_only = crrt_initiation.loc[crrt_initiation['encounter_block'].isin(missing_cohort)].copy()\n",
    "\n",
    "# Display for debugging if needed\n",
    "print(\"crrt_cohort_only shape:\", crrt_cohort_only.shape)\n",
    "print(\"crrt_initiation_only shape:\", crrt_initiation_only.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8ca784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Forward Fill Blood Flow Rate\n",
    "# ============================================================================\n",
    "print(\"\\n2. Forward filling blood flow rate...\")\n",
    "\n",
    "# Merge initiation times back to crrt_cohort\n",
    "crrt_cohort = crrt_cohort.merge(crrt_initiation, on='encounter_block', how='left')\n",
    "\n",
    "# Only consider records at or after CRRT initiation\n",
    "crrt_cohort = crrt_cohort[crrt_cohort['recorded_dttm'] >= crrt_cohort['crrt_initiation_time']].copy()\n",
    "\n",
    "# Forward fill blood_flow_rate within each encounter_block\n",
    "# BUT only when dialysate_flow_rate OR ultrafiltration_out are NOT missing\n",
    "crrt_cohort['bfr_ffill_eligible'] = (\n",
    "    crrt_cohort['dialysate_flow_rate'].notna() |\n",
    "    crrt_cohort['ultrafiltration_out'].notna()\n",
    ")\n",
    "\n",
    "# Forward fill blood flow rate only for eligible rows\n",
    "crrt_cohort['blood_flow_rate_filled'] = np.where(\n",
    "    crrt_cohort['bfr_ffill_eligible'],\n",
    "    crrt_cohort.groupby('encounter_block')['blood_flow_rate'].ffill(),\n",
    "    crrt_cohort['blood_flow_rate']\n",
    ")\n",
    "\n",
    "print(f\"   Blood flow rate forward filled for eligible records\")\n",
    "print(f\"   Records with filled BFR: {crrt_cohort['blood_flow_rate_filled'].notna().sum():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 3: Determine on_crrt Status\n",
    "# ============================================================================\n",
    "print(\"\\n3. Determining on_crrt status...\")\n",
    "\n",
    "# on_crrt = 1 when blood_flow_rate is explicitly non-zero (after ffill)\n",
    "crrt_cohort['on_crrt'] = np.where(\n",
    "    (crrt_cohort['blood_flow_rate_filled'].notna()) &\n",
    "    (crrt_cohort['blood_flow_rate_filled'] > 0),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(f\"   Records with on_crrt = 1: {(crrt_cohort['on_crrt'] == 1).sum():,}\")\n",
    "print(f\"   Records with on_crrt = 0: {(crrt_cohort['on_crrt'] == 0).sum():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Get CRRT Parameters at Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n4. Getting CRRT parameters at initiation time...\")\n",
    "\n",
    "# Filter to records at exactly the initiation time\n",
    "crrt_at_initiation = crrt_cohort[\n",
    "    crrt_cohort['recorded_dttm'] == crrt_cohort['crrt_initiation_time']\n",
    "].copy()\n",
    "\n",
    "print(f\"   CRRT records at initiation: {len(crrt_at_initiation):,}\")\n",
    "print(f\"   Unique encounter blocks: {crrt_at_initiation['encounter_block'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Get Closest Weight to CRRT Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n5. Finding closest weights to CRRT initiation time...\")\n",
    "\n",
    "# Assuming weights_df has columns: encounter_block, recorded_dttm, weight_kg\n",
    "# Filter for weights that exist\n",
    "weights_clean = weight_df.copy()\n",
    "# Rename vital_value to weight_kg if necessary, and drop vital_category\n",
    "if 'vital_value' in weights_clean.columns:\n",
    "    weights_clean = weights_clean.rename(columns={'vital_value': 'weight_kg'})\n",
    "if 'vital_category' in weights_clean.columns:\n",
    "    weights_clean = weights_clean.drop(columns=['vital_category'])\n",
    "# weights_clean = weights_clean[weights_clean['weight_kg'].notna()].copy()\n",
    "# del weight_df\n",
    "print(f\"   Weight records available: {len(weights_clean):,}\")\n",
    "\n",
    "# Merge weights with initiation times\n",
    "combined = crrt_initiation.merge(weights_clean, on='encounter_block', how='inner')\n",
    "\n",
    "# For each encounter_block, try to find the closest weight before or at initiation.\n",
    "before_mask = combined['recorded_dttm'] <= combined['crrt_initiation_time']\n",
    "combined_before = combined[before_mask].copy()\n",
    "\n",
    "# Take the closest (latest) weight before or at initiation per encounter_block\n",
    "combined_before_sorted = combined_before.sort_values(['encounter_block', 'recorded_dttm'])\n",
    "closest_before = (combined_before_sorted\n",
    "                  .groupby('encounter_block')\n",
    "                  .last()\n",
    "                  .reset_index())\n",
    "\n",
    "# Identify encounter_blocks still missing weight before/up to initiation\n",
    "all_blocks = set(combined['encounter_block'])\n",
    "blocks_with_before = set(closest_before['encounter_block'])\n",
    "blocks_missing = all_blocks - blocks_with_before\n",
    "\n",
    "# For those blocks, take the first weight available after initiation \n",
    "# after_mask = (\n",
    "#     combined['encounter_block'].isin(blocks_missing) &\n",
    "#     (combined['recorded_dttm'] > combined['crrt_initiation_time']) &\n",
    "#     (combined['recorded_dttm'] <= combined['crrt_initiation_time'] + pd.Timedelta(hours=24))\n",
    "# )\n",
    "after_mask = (\n",
    "    combined['encounter_block'].isin(blocks_missing) &\n",
    "    (combined['recorded_dttm'] > combined['crrt_initiation_time']) &\n",
    "    (combined['weight_kg'].notnull())\n",
    ")\n",
    "combined_after = combined[after_mask].copy()\n",
    "# For each, take the earliest (first) after-initiation weight\n",
    "combined_after_sorted = combined_after.sort_values(['encounter_block', 'recorded_dttm'])\n",
    "first_after = (combined_after_sorted\n",
    "               .groupby('encounter_block')\n",
    "               .first()\n",
    "               .reset_index())\n",
    "\n",
    "num_taken_after = len(first_after)\n",
    "print(f\"   Number of weights from after initiation (within 24h): {num_taken_after}\")\n",
    "\n",
    "# Combine both sets\n",
    "combined_final = pd.concat([closest_before, first_after], axis=0, ignore_index=True)\n",
    "combined = combined_final\n",
    "\n",
    "# For each encounter_block, get the weight closest to initiation\n",
    "closest_weights = (combined\n",
    "                .sort_values(['encounter_block', 'recorded_dttm'])\n",
    "                .groupby('encounter_block')\n",
    "                .last()\n",
    "                .reset_index())\n",
    "\n",
    "closest_weights = closest_weights[['encounter_block', 'weight_kg']]\n",
    "\n",
    "print(f\"   Weights found for: {len(closest_weights):,} encounter_blocks\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 6: Combine CRRT Data with Weights\n",
    "# ============================================================================\n",
    "print(\"\\n6. Combining CRRT data with weights...\")\n",
    "\n",
    "index_crrt_df = crrt_at_initiation.merge(\n",
    "    closest_weights,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   Final dataset: {len(index_crrt_df):,} records\")\n",
    "print(f\"   Records with weights: {index_crrt_df['weight_kg'].notna().sum():,}\")\n",
    "print(f\"   Records with CRRT mode: {index_crrt_df['crrt_mode_category'].notna().sum():,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 7: Calculate CRRT Dose at Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n7. Calculating CRRT dose at initiation...\")\n",
    "\n",
    "# Fill NaN values with 0 for flow rate calculations\n",
    "flow_cols = ['dialysate_flow_rate', 'pre_filter_replacement_fluid_rate',\n",
    "            'post_filter_replacement_fluid_rate']\n",
    "index_crrt_df[flow_cols] = index_crrt_df[flow_cols].fillna(0)\n",
    "\n",
    "# Standardize mode category to lowercase\n",
    "index_crrt_df['crrt_mode_category'] = index_crrt_df['crrt_mode_category'].str.lower()\n",
    "\n",
    "print(\"\\n   Mode distribution at initiation:\")\n",
    "print(index_crrt_df['crrt_mode_category'].value_counts())\n",
    "\n",
    "# Calculate total flow based on mode (vectorized approach)\n",
    "conditions = [\n",
    "    index_crrt_df['crrt_mode_category'] == 'cvvhd',\n",
    "    index_crrt_df['crrt_mode_category'] == 'cvvh',\n",
    "    index_crrt_df['crrt_mode_category'] == 'cvvhdf'\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    # CVVHD: Dialysate flow rate alone\n",
    "    index_crrt_df['dialysate_flow_rate'],\n",
    "    # CVVH: Replacement fluid rate (pre + post)\n",
    "    index_crrt_df['pre_filter_replacement_fluid_rate'] + index_crrt_df['post_filter_replacement_fluid_rate'],\n",
    "    # CVVHDF: All flows combined\n",
    "    index_crrt_df['dialysate_flow_rate'] + index_crrt_df['pre_filter_replacement_fluid_rate'] +\n",
    "    index_crrt_df['post_filter_replacement_fluid_rate']\n",
    "]\n",
    "\n",
    "index_crrt_df['total_flow_rate'] = np.select(conditions, choices, default=np.nan)\n",
    "\n",
    "print(f\"   Total flow rates calculated: {index_crrt_df['total_flow_rate'].notna().sum():,}\")\n",
    "\n",
    "# Calculate dose: total_flow_rate / weight_kg\n",
    "index_crrt_df['crrt_dose_ml_kg_hr'] = np.where(\n",
    "    (index_crrt_df['weight_kg'] > 0) & (index_crrt_df['total_flow_rate'] > 0),\n",
    "    index_crrt_df['total_flow_rate'] / index_crrt_df['weight_kg'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 8: Calculate 30-Day Mortality from CRRT Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n8. Calculating 30-day mortality from CRRT initiation...\")\n",
    "\n",
    "# Merge with outcomes_df\n",
    "index_crrt_df = index_crrt_df.merge(\n",
    "    outcomes_df[['encounter_block', 'death_dttm', 'died', 'in_hosp_death']],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Calculate days from CRRT initiation to death\n",
    "index_crrt_df['days_crrt_to_death'] = np.where(\n",
    "    index_crrt_df['death_dttm'].notna(),\n",
    "    (index_crrt_df['death_dttm'] - index_crrt_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 30-day mortality from CRRT initiation\n",
    "index_crrt_df['death_30d_from_crrt'] = np.where(\n",
    "    (index_crrt_df['days_crrt_to_death'].notna()) &\n",
    "    (index_crrt_df['days_crrt_to_death'] <= 30),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(f\"   Deaths within 30 days of CRRT initiation: {index_crrt_df['death_30d_from_crrt'].sum():,}\")\n",
    "print(f\"   30-day mortality rate: {index_crrt_df['death_30d_from_crrt'].mean() * 100:.1f}%\")\n",
    "print(f\"   In-hospital mortality: {index_crrt_df['in_hosp_death'].sum():,} ({index_crrt_df['in_hosp_death'].mean() * 100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 9: Summary Statistics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRRT Dose Summary Statistics at Initiation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dose_available = index_crrt_df['crrt_dose_ml_kg_hr'].notna()\n",
    "print(f\"\\n   CRRT doses calculated: {dose_available.sum():,}/{len(index_crrt_df):,} ({dose_available.mean()*100:.1f}%)\")\n",
    "\n",
    "if dose_available.sum() > 0:\n",
    "    dose_stats = index_crrt_df['crrt_dose_ml_kg_hr'].describe()\n",
    "    print(f\"\\n   Dose statistics (mL/kg/hr):\")\n",
    "    print(f\"     Mean ± SD: {dose_stats['mean']:.1f} ± {dose_stats['std']:.1f}\")\n",
    "    print(f\"     Median [IQR]: {dose_stats['50%']:.1f} [{dose_stats['25%']:.1f}-{dose_stats['75%']:.1f}]\")\n",
    "    print(f\"     Range: {dose_stats['min']:.1f} - {dose_stats['max']:.1f}\")\n",
    "\n",
    "    # Clinical targets analysis\n",
    "    print(f\"\\n   Clinical Target Analysis:\")\n",
    "    target_range = ((index_crrt_df['crrt_dose_ml_kg_hr'] >= 20) &\n",
    "                    (index_crrt_df['crrt_dose_ml_kg_hr'] <= 25)).sum()\n",
    "    below_target = (index_crrt_df['crrt_dose_ml_kg_hr'] < 20).sum()\n",
    "    above_target = (index_crrt_df['crrt_dose_ml_kg_hr'] > 25).sum()\n",
    "\n",
    "    print(f\"     Below target (<20 mL/kg/hr): {below_target:,} ({below_target/dose_available.sum()*100:.1f}%)\")\n",
    "    print(f\"     Within target (20-25 mL/kg/hr): {target_range:,} ({target_range/dose_available.sum()*100:.1f}%)\")\n",
    "    print(f\"     Above target (>25 mL/kg/hr): {above_target:,} ({above_target/dose_available.sum()*100:.1f}%)\")\n",
    "\n",
    "# Mode breakdown with dose and mortality\n",
    "print(f\"\\n   Dose and Mortality by CRRT Mode:\")\n",
    "for mode in index_crrt_df['crrt_mode_category'].unique():\n",
    "    if pd.notna(mode):\n",
    "        mode_data = index_crrt_df[index_crrt_df['crrt_mode_category'] == mode]\n",
    "        mode_doses = mode_data['crrt_dose_ml_kg_hr'].dropna()\n",
    "\n",
    "        if len(mode_data) > 0:\n",
    "            print(f\"     {mode.upper()}:\")\n",
    "            print(f\"       Count: {len(mode_data):,} ({len(mode_data)/len(index_crrt_df)*100:.1f}%)\")\n",
    "            if len(mode_doses) > 0:\n",
    "                print(f\"       Mean dose: {mode_doses.mean():.1f} mL/kg/hr\")\n",
    "                print(f\"       Median dose: {mode_doses.median():.1f} mL/kg/hr\")\n",
    "            print(f\"       30-day mortality: {mode_data['death_30d_from_crrt'].sum():,} ({mode_data['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "\n",
    "# ---- Added visualization of CRRT dose distribution by mode ----\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Only plot if at least some doses and mode info available\n",
    "import os\n",
    "\n",
    "mode_dose_data = index_crrt_df[['crrt_mode_category', 'crrt_dose_ml_kg_hr']].copy()\n",
    "mode_dose_data = mode_dose_data[\n",
    "    mode_dose_data['crrt_dose_ml_kg_hr'].notna() & mode_dose_data['crrt_mode_category'].notna()\n",
    "]\n",
    "\n",
    "output_graphs_dir = \"../output/final/graphs\"\n",
    "os.makedirs(output_graphs_dir, exist_ok=True)\n",
    "\n",
    "if not mode_dose_data.empty:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.violinplot(\n",
    "        data=mode_dose_data,\n",
    "        x='crrt_mode_category',\n",
    "        y='crrt_dose_ml_kg_hr',\n",
    "        inner='box',\n",
    "        cut=0,\n",
    "        scale='width'\n",
    "    )\n",
    "    plt.title(\"Distribution of CRRT Dose by CRRT Mode at Initiation\")\n",
    "    plt.xlabel(\"CRRT Mode Category\")\n",
    "    plt.ylabel(\"CRRT Dose (mL/kg/hr)\")\n",
    "    plt.grid(axis='y', ls='--', alpha=0.4)\n",
    "    plt.tight_layout()\n",
    "    fig_path = os.path.join(output_graphs_dir, \"crrt_dose_by_mode_violin.png\")\n",
    "    plt.savefig(fig_path, dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: Create Final Analysis Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating Final Analysis Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "analysis_columns = [\n",
    "    'encounter_block',\n",
    "    'hospitalization_id',\n",
    "    'crrt_initiation_time',\n",
    "    'crrt_mode_category',\n",
    "    'weight_kg',\n",
    "    'blood_flow_rate_filled',\n",
    "    'on_crrt',\n",
    "    'total_flow_rate',\n",
    "    'crrt_dose_ml_kg_hr',\n",
    "    'dialysate_flow_rate',\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'ultrafiltration_out',\n",
    "    'died',\n",
    "    'in_hosp_death',\n",
    "    'death_30d_from_crrt',\n",
    "    'days_crrt_to_death',\n",
    "    'death_dttm'\n",
    "]\n",
    "\n",
    "crrt_analysis_df = index_crrt_df[analysis_columns].copy()\n",
    "\n",
    "print(f\"\\n   Final analysis dataset created:\")\n",
    "print(f\"     Total records: {len(crrt_analysis_df):,}\")\n",
    "print(f\"     Unique encounter blocks: {crrt_analysis_df['encounter_block'].nunique():,}\")\n",
    "print(f\"     Records with valid dose: {crrt_analysis_df['crrt_dose_ml_kg_hr'].notna().sum():,}\")\n",
    "print(f\"     Records with weight: {crrt_analysis_df['weight_kg'].notna().sum():,}\")\n",
    "print(f\"     30-day mortality: {crrt_analysis_df['death_30d_from_crrt'].sum():,} ({crrt_analysis_df['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ CRRT analysis completed successfully!\")\n",
    "print(f\"   Dataset 'crrt_analysis_df' ready for further analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac66833",
   "metadata": {},
   "source": [
    "# SOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_cohort_df = combined_final[['hospitalization_id', 'encounter_block', 'crrt_initiation_time']].copy()\n",
    "sofa_cohort_df['start_dttm'] = sofa_cohort_df['crrt_initiation_time']\n",
    "sofa_cohort_df['end_dttm'] = sofa_cohort_df['start_dttm'] + pd.Timedelta(hours=6)\n",
    "\n",
    "# Keep only required columns\n",
    "sofa_cohort_df = sofa_cohort_df[['hospitalization_id','encounter_block', 'start_dttm', 'end_dttm']]\n",
    "sofa_cohort_ids = cohort_df['hospitalization_id'].astype(str).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import sofa_calculator\n",
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sofa_calculator)\n",
    "from sofa_calculator import compute_sofa_polars\n",
    "\n",
    "\n",
    "# Rename columns to match sofa_calculator requirements\n",
    "sofa_input_df = sofa_cohort_df.rename(columns={\n",
    "    'start_time': 'start_dttm',\n",
    "    'end_time': 'end_dttm'\n",
    "})\n",
    "\n",
    "# Convert pandas → Polars\n",
    "sofa_input_pl = pl.from_pandas(sofa_input_df)\n",
    "\n",
    "#  Call SOFA Calculator\n",
    "\n",
    "print(\"Calculating SOFA scores...\")\n",
    "sofa_scores_pl = compute_sofa_polars(\n",
    "    data_directory=config['tables_path'],\n",
    "    cohort_df=sofa_input_pl,\n",
    "    filetype=config['file_type'],\n",
    "    id_name='encounter_block',  # Group by encounter blocks\n",
    "    extremal_type='worst',\n",
    "    fill_na_scores_with_zero=False,  # Leave null as requested\n",
    "    remove_outliers=True,\n",
    "    timezone=config['timezone']\n",
    ")\n",
    "\n",
    "# Convert Results Back to Pandas\n",
    "\n",
    "# Convert Polars → pandas\n",
    "sofa_scores_df = sofa_scores_pl.to_pandas()\n",
    "\n",
    "print(f\"✓ SOFA scores calculated for {len(sofa_scores_df)} encounter blocks\")\n",
    "print(f\"  Mean total SOFA: {sofa_scores_df['sofa_total'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create histogram of SOFA total scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "ax.hist(sofa_scores_df['sofa_total'].dropna(),\n",
    "        bins=range(0, int(sofa_scores_df['sofa_total'].max()) + 2),\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color='steelblue')\n",
    "\n",
    "# Add vertical line for mean\n",
    "mean_sofa = sofa_scores_df['sofa_total'].mean()\n",
    "ax.axvline(mean_sofa, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {mean_sofa:.1f}')\n",
    "\n",
    "# Add vertical line for median\n",
    "median_sofa = sofa_scores_df['sofa_total'].median()\n",
    "ax.axvline(median_sofa, color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {median_sofa:.1f}')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('SOFA Total Score', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Encounters', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distribution of SOFA Total Scores at CRRT Initiation',\n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = f'n = {sofa_scores_df[\"sofa_total\"].notna().sum()}\\n'\n",
    "stats_text += f'Mean ± SD: {mean_sofa:.1f} ± {sofa_scores_df[\"sofa_total\"].std():.1f}\\n'\n",
    "stats_text += f'Median [IQR]: {median_sofa:.1f} [{sofa_scores_df[\"sofa_total\"].quantile(0.25):.1f}-{sofa_scores_df[\"sofa_total\"].quantile(0.75):.1f}]'\n",
    "\n",
    "ax.text(0.98, 0.97, stats_text,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Legend\n",
    "# ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('../output/final/graphs/sofa_total_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Histogram saved to output/final/graphs/sofa_total_distribution.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "outcomes_with_sofa = outcomes_df.merge(sofa_scores_df, on='encounter_block', how='left')\n",
    "# Calculate mortality rate by SOFA total score\n",
    "mortality_by_sofa = outcomes_with_sofa.groupby('sofa_total').agg({\n",
    "    'in_hosp_death': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "mortality_by_sofa.columns = ['sofa_total', 'deaths', 'n_encounters', 'mortality_rate']\n",
    "mortality_by_sofa['mortality_pct'] = mortality_by_sofa['mortality_rate'] * 100\n",
    "\n",
    "# Sort by SOFA score\n",
    "mortality_by_sofa = mortality_by_sofa.sort_values('sofa_total')\n",
    "\n",
    "# Save CSV for this SOFA vs mortality data\n",
    "mortality_by_sofa.to_csv('../output/final/sofa_mortality_data.csv', index=False)\n",
    "print(\"✓ SOFA-mortality summary CSV saved to ../output/final/sofa_mortality_data.csv\")\n",
    "\n",
    "# Create figure with two subplots (main plot + table)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.05)\n",
    "ax_main = fig.add_subplot(gs[0])\n",
    "ax_table = fig.add_subplot(gs[1])\n",
    "\n",
    "# Main plot - Mortality rate bars\n",
    "bars = ax_main.bar(mortality_by_sofa['sofa_total'],\n",
    "                    mortality_by_sofa['mortality_pct'],\n",
    "                    color='steelblue',\n",
    "                    edgecolor='black',\n",
    "                    alpha=0.7,\n",
    "                    width=0.8)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, (sofa, pct, n) in enumerate(zip(mortality_by_sofa['sofa_total'],\n",
    "                                        mortality_by_sofa['mortality_pct'],\n",
    "                                        mortality_by_sofa['n_encounters'])):\n",
    "    ax_main.text(sofa, pct + 1, f'{pct:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Main plot formatting\n",
    "ax_main.set_ylabel('In-Hospital Mortality (%)', fontsize=12, fontweight='bold')\n",
    "ax_main.set_title('In-Hospital Mortality by SOFA Total Score at CRRT Initiation',\n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "ax_main.set_ylim(0, mortality_by_sofa['mortality_pct'].max() * 1.15)\n",
    "ax_main.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax_main.set_xlim(mortality_by_sofa['sofa_total'].min() - 0.5,\n",
    "                mortality_by_sofa['sofa_total'].max() + 0.5)\n",
    "\n",
    "# Remove x-axis labels from main plot (will show in table)\n",
    "ax_main.set_xticklabels([])\n",
    "ax_main.set_xlabel('')\n",
    "\n",
    "# Create table with encounter counts\n",
    "ax_table.axis('tight')\n",
    "ax_table.axis('off')\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "    [f'{int(score)}' for score in mortality_by_sofa['sofa_total']],\n",
    "    [f'n={int(n)}' for n in mortality_by_sofa['n_encounters']]\n",
    "]\n",
    "\n",
    "# Create table\n",
    "table = ax_table.table(cellText=table_data,\n",
    "                        rowLabels=['SOFA Score', 'N Encounters'],\n",
    "                        cellLoc='center',\n",
    "                        loc='center',\n",
    "                        colWidths=[1/len(mortality_by_sofa)] * len(mortality_by_sofa))\n",
    "\n",
    "# Format table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style table cells\n",
    "for i in range(len(table_data)):\n",
    "    for j in range(len(mortality_by_sofa)):\n",
    "        cell = table[(i, j)]\n",
    "        cell.set_facecolor('lightgray' if i == 0 else 'white')\n",
    "        cell.set_text_props(weight='bold' if i == 0 else 'normal')\n",
    "\n",
    "# Style row labels\n",
    "for i in range(len(table_data)):\n",
    "    cell = table[(i, -1)]\n",
    "    cell.set_facecolor('lightsteelblue')\n",
    "    cell.set_text_props(weight='bold', ha='right')\n",
    "\n",
    "# Add overall statistics box\n",
    "overall_mortality = outcomes_with_sofa['in_hosp_death'].mean() * 100\n",
    "total_n = len(outcomes_with_sofa)\n",
    "stats_text = f'Overall Mortality: {overall_mortality:.1f}%\\nTotal N: {total_n:,}'\n",
    "\n",
    "ax_main.text(0.02, 0.98, stats_text,\n",
    "            transform=ax_main.transAxes,\n",
    "            fontsize=11,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('../output/final/graphs/mortality_by_sofa_score.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Mortality by SOFA score plot saved to output/final/graphs/mortality_by_sofa_score.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead81b42",
   "metadata": {},
   "source": [
    "# Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labs\n",
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['po2_arterial','pco2_arterial', 'ph_arterial','ph_venous', 'bicarbonate','so2_arterial',\n",
    "                    'sodium', 'potassium', 'chloride', 'calcium_total', 'magnesium', 'creatinine', \n",
    "                    'bun', 'glucose_serum', 'lactate', 'hemoglobin' ]\n",
    "\n",
    "# labs_of_interest = ['ph_arterial', 'lactate', 'bicarbonate', 'potassium']\n",
    "\n",
    "print(f\"\\nLoading labs table...\")\n",
    "clif.load_table(\n",
    "    'labs',\n",
    "    columns=labs_required_columns,\n",
    "    filters={\n",
    "        'hospitalization_id': cohort_df['hospitalization_id'].unique().tolist(),\n",
    "        'lab_category': labs_of_interest\n",
    "    }\n",
    ")\n",
    "print(f\"   Labs loaded: {len(clif.labs.df):,} rows\")\n",
    "print(f\"   Unique lab categories: {clif.labs.df['lab_category'].nunique()}\")\n",
    "print(f\"   Unique lab hospitalizations: {clif.labs.df['hospitalization_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32388f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Get Most Recent Labs Within 6h of CRRT Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Processing Labs - Most Recent Within 6h of CRRT Initiation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get labs dataframe\n",
    "labs_df = clif.labs.df.copy()\n",
    "\n",
    "# Merge with CRRT initiation times to get the reference time\n",
    "labs_with_crrt = labs_df.merge(\n",
    "    crrt_analysis_df[['encounter_block', 'hospitalization_id', 'crrt_initiation_time']],\n",
    "    on='hospitalization_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"   Labs after merging with CRRT cohort: {len(labs_with_crrt):,}\")\n",
    "\n",
    "# Filter for labs within 6 hours BEFORE CRRT initiation\n",
    "labs_before = labs_with_crrt[\n",
    "    (labs_with_crrt['lab_result_dttm'] <= labs_with_crrt['crrt_initiation_time']) &\n",
    "    (labs_with_crrt['lab_result_dttm'] >= labs_with_crrt['crrt_initiation_time'] - pd.Timedelta(hours=24))\n",
    "].copy()\n",
    "\n",
    "# Filter for labs within 6 hours AFTER CRRT initiation\n",
    "labs_after = labs_with_crrt[\n",
    "    (labs_with_crrt['lab_result_dttm'] > labs_with_crrt['crrt_initiation_time']) &\n",
    "    (labs_with_crrt['lab_result_dttm'] <= labs_with_crrt['crrt_initiation_time'] + pd.Timedelta(hours=24))\n",
    "].copy()\n",
    "\n",
    "print(f\"   Labs within 6h before CRRT: {len(labs_before):,}\")\n",
    "print(f\"   Labs within 6h after CRRT: {len(labs_after):,}\")\n",
    "\n",
    "# Strategy: Prioritize BEFORE, then AFTER\n",
    "# For each encounter_block + lab_category:\n",
    "#   1. If lab exists BEFORE initiation: take the MOST RECENT (closest to initiation)\n",
    "#   2. If no lab BEFORE: take the EARLIEST lab AFTER initiation\n",
    "\n",
    "# Get most recent lab BEFORE initiation per encounter_block + lab_category\n",
    "labs_before_sorted = labs_before.sort_values(['encounter_block', 'lab_category', 'lab_result_dttm'])\n",
    "labs_before_most_recent = (labs_before_sorted\n",
    "                            .groupby(['encounter_block', 'lab_category'])\n",
    "                            .last()  # Most recent = closest to initiation\n",
    "                            .reset_index())\n",
    "labs_before_most_recent['source'] = 'before'\n",
    "\n",
    "# Get earliest lab AFTER initiation per encounter_block + lab_category\n",
    "labs_after_sorted = labs_after.sort_values(['encounter_block', 'lab_category', 'lab_result_dttm'])\n",
    "labs_after_earliest = (labs_after_sorted\n",
    "                        .groupby(['encounter_block', 'lab_category'])\n",
    "                        .first()  # Earliest = closest to initiation\n",
    "                        .reset_index())\n",
    "labs_after_earliest['source'] = 'after'\n",
    "\n",
    "# Identify which encounter_block + lab_category combinations have BEFORE labs\n",
    "before_keys = set(labs_before_most_recent[['encounter_block', 'lab_category']].apply(tuple, axis=1))\n",
    "\n",
    "# Filter AFTER labs to only those WITHOUT a BEFORE lab\n",
    "labs_after_filtered = labs_after_earliest[\n",
    "    ~labs_after_earliest[['encounter_block', 'lab_category']].apply(tuple, axis=1).isin(before_keys)\n",
    "]\n",
    "\n",
    "# Combine: all BEFORE labs + AFTER labs (only where no BEFORE exists)\n",
    "labs_final = pd.concat([labs_before_most_recent, labs_after_filtered], ignore_index=True)\n",
    "\n",
    "print(f\"\\n   Final lab selection:\")\n",
    "print(f\"     From BEFORE window: {(labs_final['source'] == 'before').sum():,}\")\n",
    "print(f\"     From AFTER window: {(labs_final['source'] == 'after').sum():,}\")\n",
    "print(f\"     Total unique encounter_block + lab combinations: {len(labs_final):,}\")\n",
    "\n",
    "# Pivot to wide format (one row per encounter_block, one column per lab)\n",
    "labs_wide = labs_final.pivot(\n",
    "    index='encounter_block',\n",
    "    columns='lab_category',\n",
    "    values='lab_value_numeric'\n",
    ").reset_index()\n",
    "\n",
    "# Add suffix to lab column names for clarity\n",
    "labs_wide.columns = ['encounter_block'] + [f'{col}_peri_crrt' for col in labs_wide.columns if col != 'encounter_block']\n",
    "\n",
    "print(f\"\\n   Labs in wide format:\")\n",
    "print(f\"     Encounter blocks: {len(labs_wide):,}\")\n",
    "print(f\"     Lab columns: {list(labs_wide.columns)}\")\n",
    "\n",
    "# Show availability by lab\n",
    "print(f\"\\n   Lab value availability (non-null):\")\n",
    "for col in labs_wide.columns:\n",
    "    if col != 'encounter_block':\n",
    "        n_available = labs_wide[col].notna().sum()\n",
    "        pct = n_available / len(labs_wide) * 100\n",
    "        print(f\"     {col}: {n_available:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Merge back with CRRT analysis dataset\n",
    "crrt_with_labs = crrt_analysis_df.merge(\n",
    "    labs_wide,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n   Final dataset with labs:\")\n",
    "print(f\"     Total records: {len(crrt_with_labs):,}\")\n",
    "print(f\"     Records with at least one lab: {(crrt_with_labs[[col for col in crrt_with_labs.columns if '_peri_crrt' in col]].notna().any(axis=1)).sum():,}\")\n",
    "\n",
    "print(\"\\n✅ Lab processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Identify Encounter Blocks Without Labs\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Identifying Encounter Blocks Without Labs\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get all lab columns\n",
    "lab_columns = [col for col in crrt_with_labs.columns if '_peri_crrt' in col]\n",
    "\n",
    "# Identify encounters with NO labs documented (all lab columns are null)\n",
    "crrt_with_labs['has_any_lab'] = crrt_with_labs[lab_columns].notna().any(axis=1)\n",
    "encounters_without_labs = crrt_with_labs[~crrt_with_labs['has_any_lab']].copy()\n",
    "\n",
    "# Summary statistics\n",
    "total_encounters = len(crrt_with_labs)\n",
    "encounters_with_labs = crrt_with_labs['has_any_lab'].sum()\n",
    "encounters_without_labs_count = len(encounters_without_labs)\n",
    "\n",
    "print(f\"\\n   Lab Documentation Status:\")\n",
    "print(f\"     Total encounter blocks: {total_encounters:,}\")\n",
    "print(f\"     With at least one lab: {encounters_with_labs:,} ({encounters_with_labs/total_encounters*100:.1f}%)\")\n",
    "print(f\"     WITHOUT any labs: {encounters_without_labs_count:,} ({encounters_without_labs_count/total_encounters*100:.1f}%)\")\n",
    "\n",
    "# Show breakdown by lab category availability\n",
    "print(f\"\\n   Lab-specific availability:\")\n",
    "for lab_col in lab_columns:\n",
    "    n_available = crrt_with_labs[lab_col].notna().sum()\n",
    "    pct = n_available / total_encounters * 100\n",
    "    lab_name = lab_col.replace('_peri_crrt', '')\n",
    "    print(f\"     {lab_name}: {n_available:,}/{total_encounters:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Show characteristics of encounters without labs\n",
    "if len(encounters_without_labs) > 0:\n",
    "    print(f\"\\n   Characteristics of encounters WITHOUT labs:\")\n",
    "    print(f\"     CRRT modes:\")\n",
    "    mode_dist = encounters_without_labs['crrt_mode_category'].value_counts()\n",
    "    for mode, count in mode_dist.items():\n",
    "        print(f\"       {mode}: {count:,} ({count/len(encounters_without_labs)*100:.1f}%)\")\n",
    "\n",
    "    print(f\"     Mortality:\")\n",
    "    print(f\"       30-day deaths: {encounters_without_labs['death_30d_from_crrt'].sum():,} ({encounters_without_labs['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "    print(f\"       In-hospital deaths: {encounters_without_labs['in_hosp_death'].sum():,} ({encounters_without_labs['in_hosp_death'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Optional: Save list of encounter blocks without labs for QC\n",
    "encounters_without_labs_list = encounters_without_labs[['encounter_block', 'hospitalization_id', 'crrt_initiation_time']].copy()\n",
    "\n",
    "print(f\"\\n   Sample encounter blocks without labs (first 10):\")\n",
    "if len(encounters_without_labs_list) > 0:\n",
    "    print(encounters_without_labs_list.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"     None - all encounters have at least one lab!\")\n",
    "\n",
    "# Create analysis-ready dataset flag\n",
    "# You may want to exclude encounters without labs from certain analyses\n",
    "crrt_with_labs['analysis_ready'] = crrt_with_labs['has_any_lab']\n",
    "\n",
    "print(f\"\\n   Analysis-ready encounters (with labs): {crrt_with_labs['analysis_ready'].sum():,}\")\n",
    "print(f\"   Encounters to exclude (no labs): {(~crrt_with_labs['analysis_ready']).sum():,}\")\n",
    "\n",
    "print(\"\\n✅ Lab completeness check completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71afefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crrt_with_labs.to_parquet('../output/intermediate/crrt_analysis_with_labs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5a1fc",
   "metadata": {},
   "source": [
    "# Competing Risk Dataset\n",
    "\n",
    "Outcome coding:  \n",
    "\n",
    "* 0 = Censored (>90 days or still hospitalized)\n",
    "* 1 = Discharged alive (within 90 days)\n",
    "* 2 = Died (within 90 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in [(\"outcomes_with_sofa\", outcomes_with_sofa), \n",
    "                    (\"crrt_analysis_df\", crrt_analysis_df), \n",
    "                    (\"crrt_with_labs\", crrt_with_labs)]:\n",
    "    print(f\"\\nDataFrame: {df_name}\")\n",
    "    print(f\"Columns ({len(df.columns)}): {list(df.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbe032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Create Competing Risk Analysis Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating Competing Risk Analysis Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Merge All Data Sources\n",
    "# ============================================================================\n",
    "print(\"\\n1. Merging data sources...\")\n",
    "\n",
    "# Start with CRRT data (has crrt_initiation_time and CRRT parameters)\n",
    "competing_risk_df = crrt_with_labs.copy()\n",
    "\n",
    "print(f\"   Starting with CRRT data: {len(competing_risk_df):,} encounter blocks\")\n",
    "\n",
    "# Merge demographics and outcomes from outcomes_with_sofa\n",
    "# Select relevant columns (avoid duplicates)\n",
    "outcomes_cols = [\n",
    "    'encounter_block',\n",
    "    'age_at_admission',\n",
    "    'sex_category',\n",
    "    'race_category',\n",
    "    'ethnicity_category',\n",
    "    'icu_los_days',\n",
    "    'hosp_los_days',\n",
    "    'admission_type_category',\n",
    "    'discharge_category',\n",
    "    'first_vital_dttm',\n",
    "    'last_vital_dttm',\n",
    "    'final_outcome_dttm', \n",
    "    'sofa_cv_97',\n",
    "    'sofa_coag',\n",
    "    'sofa_liver',\n",
    "    'sofa_resp',\n",
    "    'sofa_cns',\n",
    "    'sofa_renal',\n",
    "    'sofa_total'\n",
    "]\n",
    "\n",
    "# Check which columns exist in outcomes_with_sofa\n",
    "available_cols = [col for col in outcomes_cols if col in outcomes_with_sofa.columns]\n",
    "\n",
    "competing_risk_df = competing_risk_df.merge(\n",
    "    outcomes_with_sofa[available_cols],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   After merging outcomes: {len(competing_risk_df):,} rows, {len(competing_risk_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Calculate Time-to-Event (Days from CRRT to Discharge/Death)\n",
    "# ============================================================================\n",
    "print(\"\\n2. Calculating time-to-event...\")\n",
    "\n",
    "# For discharged alive: use last_vital_dttm as proxy for discharge time\n",
    "# For died: use final_outcome_dttm (most accurate death timestamp)\n",
    "competing_risk_df['discharge_dttm'] = competing_risk_df['last_vital_dttm']\n",
    "\n",
    "# Calculate time to event in days\n",
    "competing_risk_df['time_to_event_days'] = np.where(\n",
    "    competing_risk_df['died'] == 1,\n",
    "    # If died: time from CRRT to final_outcome_dttm\n",
    "    (competing_risk_df['final_outcome_dttm'] - competing_risk_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600),\n",
    "    # If alive: time from CRRT to discharge\n",
    "    (competing_risk_df['discharge_dttm'] - competing_risk_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600)\n",
    ")\n",
    "\n",
    "# Handle negative or zero times\n",
    "negative_times = (competing_risk_df['time_to_event_days'] < 0).sum()\n",
    "if negative_times > 0:\n",
    "    print(f\"   ⚠️  {negative_times} records with negative time-to-event (setting to 0.5 days)\")\n",
    "    competing_risk_df.loc[competing_risk_df['time_to_event_days'] < 0, 'time_to_event_days'] = 0.5\n",
    "\n",
    "zero_times = (competing_risk_df['time_to_event_days'] == 0).sum()\n",
    "if zero_times > 0:\n",
    "    print(f\"   ⚠️  {zero_times} records with zero time-to-event (setting to 0.5 days)\")\n",
    "    competing_risk_df.loc[competing_risk_df['time_to_event_days'] == 0, 'time_to_event_days'] = 0.5\n",
    "\n",
    "print(f\"   Time-to-event range: {competing_risk_df['time_to_event_days'].min():.1f} - {competing_risk_df['time_to_event_days'].max():.1f} days\")\n",
    "print(f\"   Median: {competing_risk_df['time_to_event_days'].median():.1f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Apply 90-Day Censoring and Calculate 90-Day Mortality\n",
    "# ============================================================================\n",
    "print(\"\\n3. Applying 90-day censoring...\")\n",
    "\n",
    "# Cap at 90 days\n",
    "competing_risk_df['time_to_event_90d'] = competing_risk_df['time_to_event_days'].clip(upper=90)\n",
    "\n",
    "# Flag censoring\n",
    "competing_risk_df['censored_at_90d'] = (competing_risk_df['time_to_event_days'] > 90).astype(int)\n",
    "\n",
    "# Calculate 90-day mortality from CRRT initiation\n",
    "competing_risk_df['death_90d_from_crrt'] = (\n",
    "    (competing_risk_df['died'] == 1) &\n",
    "    (competing_risk_df['time_to_event_days'] <= 90)\n",
    ").astype(int)\n",
    "\n",
    "events_censored = competing_risk_df['censored_at_90d'].sum()\n",
    "deaths_90d = competing_risk_df['death_90d_from_crrt'].sum()\n",
    "\n",
    "print(f\"   Events censored at 90 days: {events_censored:,} ({events_censored/len(competing_risk_df)*100:.1f}%)\")\n",
    "print(f\"   Deaths within 90 days of CRRT: {deaths_90d:,} ({deaths_90d/len(competing_risk_df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create Competing Risk Outcome Variable\n",
    "# ============================================================================\n",
    "print(\"\\n4. Creating competing risk outcome variable...\")\n",
    "\n",
    "# Outcome coding:\n",
    "# 0 = Censored (>90 days or still hospitalized)\n",
    "# 1 = Discharged alive (within 90 days)\n",
    "# 2 = Died (within 90 days)\n",
    "\n",
    "competing_risk_df['outcome'] = 0  # Default: censored\n",
    "\n",
    "# Discharged alive within 90 days\n",
    "competing_risk_df.loc[\n",
    "    (competing_risk_df['death_90d_from_crrt'] == 0) &\n",
    "    (competing_risk_df['time_to_event_days'] <= 90),\n",
    "    'outcome'\n",
    "] = 1\n",
    "\n",
    "# Died within 90 days\n",
    "competing_risk_df.loc[\n",
    "    competing_risk_df['death_90d_from_crrt'] == 1,\n",
    "    'outcome'\n",
    "] = 2\n",
    "\n",
    "# Outcome distribution\n",
    "print(f\"\\n   Outcome distribution:\")\n",
    "outcome_labels = {0: 'Censored (>90d)', 1: 'Discharged alive', 2: 'Died'}\n",
    "for outcome_val in [0, 1, 2]:\n",
    "    count = (competing_risk_df['outcome'] == outcome_val).sum()\n",
    "    pct = count / len(competing_risk_df) * 100\n",
    "    print(f\"     {outcome_labels[outcome_val]}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Select Final Columns\n",
    "# ============================================================================\n",
    "print(\"\\n5. Selecting final analysis columns...\")\n",
    "\n",
    "final_columns = [\n",
    "    # Identifiers\n",
    "    'encounter_block',\n",
    "\n",
    "    # Time and outcome\n",
    "    'crrt_initiation_time',\n",
    "    'time_to_event_90d',\n",
    "    'outcome',\n",
    "    'censored_at_90d',\n",
    "\n",
    "    # Demographics\n",
    "    'age_at_admission',\n",
    "    'sex_category',\n",
    "    'race_category',\n",
    "    'ethnicity_category',\n",
    "\n",
    "    # CRRT parameters\n",
    "    'crrt_mode_category',\n",
    "    'crrt_dose_ml_kg_hr',\n",
    "    'blood_flow_rate_filled',\n",
    "    'dialysate_flow_rate',\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'ultrafiltration_out',\n",
    "    'total_flow_rate',\n",
    "    'weight_kg',\n",
    "    'on_crrt',\n",
    "\n",
    "    # Labs (peri-CRRT)\n",
    "    'ph_arterial_peri_crrt',\n",
    "    'lactate_peri_crrt',\n",
    "    'bicarbonate_peri_crrt',\n",
    "    'potassium_peri_crrt',\n",
    "    'sodium_peri_crrt',\n",
    "    'creatinine_peri_crrt',\n",
    "    'bun_peri_crrt',\n",
    "    'hemoglobin_peri_crrt',\n",
    "    'glucose_serum_peri_crrt',\n",
    "\n",
    "    # SOFA scores\n",
    "    'sofa_cv_97',\n",
    "    'sofa_coag',\n",
    "    'sofa_liver',\n",
    "    'sofa_resp',\n",
    "    'sofa_cns',\n",
    "    'sofa_renal',\n",
    "    'sofa_total',\n",
    "\n",
    "    # LOS\n",
    "    'icu_los_days',\n",
    "    'hosp_los_days',\n",
    "\n",
    "    # Quality flags\n",
    "    'has_any_lab',\n",
    "    'analysis_ready'\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "available_final_cols = [col for col in final_columns if col in competing_risk_df.columns]\n",
    "competing_risk_final = competing_risk_df[available_final_cols].copy()\n",
    "\n",
    "print(f\"   Final dataset: {len(competing_risk_final):,} rows × {len(competing_risk_final.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Data Validation\n",
    "# ============================================================================\n",
    "print(\"\\n6. Data validation...\")\n",
    "\n",
    "# Check for impossible values\n",
    "issues = []\n",
    "\n",
    "# Time-to-event validation\n",
    "if (competing_risk_final['time_to_event_90d'] < 0).any():\n",
    "    issues.append(\"Negative time-to-event values\")\n",
    "\n",
    "# Age validation\n",
    "if 'age_at_admission' in competing_risk_final.columns:\n",
    "    invalid_age = ((competing_risk_final['age_at_admission'] < 18) |\n",
    "                    (competing_risk_final['age_at_admission'] > 120)).sum()\n",
    "    if invalid_age > 0:\n",
    "        issues.append(f\"{invalid_age} records with invalid age\")\n",
    "\n",
    "# Outcome validation\n",
    "if competing_risk_final['outcome'].isna().any():\n",
    "    issues.append(\"Missing outcome values\")\n",
    "\n",
    "if issues:\n",
    "    print(\"   ⚠️  Data quality issues:\")\n",
    "    for issue in issues:\n",
    "        print(f\"     - {issue}\")\n",
    "else:\n",
    "    print(\"   ✓ No data quality issues detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Summary Statistics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n   Cohort Size: {len(competing_risk_final):,} encounter blocks\")\n",
    "\n",
    "print(f\"\\n   Competing Risk Outcomes:\")\n",
    "for outcome_val in [0, 1, 2]:\n",
    "    count = (competing_risk_final['outcome'] == outcome_val).sum()\n",
    "    pct = count / len(competing_risk_final) * 100\n",
    "    print(f\"     {outcome_labels[outcome_val]}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Time-to-Event (days):\")\n",
    "print(f\"     Mean ± SD: {competing_risk_final['time_to_event_90d'].mean():.1f} ± {competing_risk_final['time_to_event_90d'].std():.1f}\")\n",
    "print(f\"     Median [IQR]: {competing_risk_final['time_to_event_90d'].median():.1f} [{competing_risk_final['time_to_event_90d'].quantile(0.25):.1f}-{competing_risk_final['time_to_event_90d'].quantile(0.75):.1f}]\")\n",
    "\n",
    "if 'age_at_admission' in competing_risk_final.columns:\n",
    "    print(f\"\\n   Age at Admission (years):\")\n",
    "    print(f\"     Mean ± SD: {competing_risk_final['age_at_admission'].mean():.1f} ± {competing_risk_final['age_at_admission'].std():.1f}\")\n",
    "\n",
    "if 'crrt_dose_ml_kg_hr' in competing_risk_final.columns:\n",
    "    dose_available = competing_risk_final['crrt_dose_ml_kg_hr'].notna()\n",
    "    print(f\"\\n   CRRT Dose (mL/kg/hr):\")\n",
    "    print(f\"     Available: {dose_available.sum():,}/{len(competing_risk_final):,} ({dose_available.mean()*100:.1f}%)\")\n",
    "    if dose_available.any():\n",
    "        print(f\"     Mean ± SD: {competing_risk_final['crrt_dose_ml_kg_hr'].mean():.1f} ± {competing_risk_final['crrt_dose_ml_kg_hr'].std():.1f}\")\n",
    "\n",
    "if 'has_any_lab' in competing_risk_final.columns:\n",
    "    print(f\"\\n   Lab Availability:\")\n",
    "    with_labs = competing_risk_final['has_any_lab'].sum()\n",
    "    print(f\"     With labs: {with_labs:,} ({with_labs/len(competing_risk_final)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3298b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_risk_final.to_parquet(\"../output/intermediate/competing_risk_final.parquet\")\n",
    "competing_risk_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae00ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive Statistics & Data Quality\n",
    "\n",
    "# Overall summary\n",
    "print(f\"Total encounters: {len(competing_risk_final):,}\")\n",
    "print(f\"Outcome distribution:\")\n",
    "print(competing_risk_final['outcome'].value_counts().sort_index())\n",
    "\n",
    "# Check missingness for key variables\n",
    "key_vars = ['crrt_dose_ml_kg_hr', 'age_at_admission', 'weight_kg',\n",
    "            'crrt_mode_category', 'sofa_total']\n",
    "print(\"\\nMissingness in key variables:\")\n",
    "for var in key_vars:\n",
    "    missing = competing_risk_final[var].isna().sum()\n",
    "    print(f\"  {var}: {missing} ({missing/len(competing_risk_final)*100:.1f}%)\")\n",
    "\n",
    "# Lab availability\n",
    "print(f\"\\nAnalysis-ready (complete labs): {competing_risk_final['analysis_ready'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a55d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Distribution of time-to-event by outcome\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "competing_risk_final[competing_risk_final['outcome']==1]['time_to_event_90d'].hist(bins=30, ax=ax[0])\n",
    "ax[0].set_title('Time to Discharge (Alive)')\n",
    "competing_risk_final[competing_risk_final['outcome']==2]['time_to_event_90d'].hist(bins=30, ax=ax[1])\n",
    "ax[1].set_title('Time to Death')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62704b10",
   "metadata": {},
   "source": [
    "# TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_table_one_competing_risk, print_table_one_summary\n",
    "\n",
    "# Full Table 1 stratified by outcome\n",
    "table1 = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by='outcome',\n",
    "    output_path='../output/final/table1_by_outcome.csv'\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "display(table1)\n",
    "\n",
    "# Quick summary to console\n",
    "print_table_one_summary(competing_risk_final)\n",
    "\n",
    "# Table 1 by CRRT mode instead\n",
    "table1_mode = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by='crrt_mode_category',\n",
    "    output_path='../output/final/table1_by_crrt_mode.csv'\n",
    ")\n",
    "\n",
    "# Overall only (no stratification)\n",
    "table1_overall = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by=None,\n",
    "    output_path='../output/final/table1_overall.csv'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

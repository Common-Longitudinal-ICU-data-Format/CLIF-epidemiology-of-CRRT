{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202f0ff6",
   "metadata": {},
   "source": [
    "# Process CRRT Therapy Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60987675",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pyarrow\n",
    "import warnings\n",
    "import clifpy\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import clifpy\n",
    "import os\n",
    "\n",
    "print(\"=== Environment Verification ===\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"clifpy version: {clifpy.__version__}\")\n",
    "print(f\"clifpy location: {clifpy.__file__}\")\n",
    "\n",
    "print(\"\\n=== Python Path Check ===\")\n",
    "local_clifpy_path = \"/Users/kavenchhikara/Desktop/CLIF/CLIFpy\"\n",
    "if any(local_clifpy_path in path for path in sys.path):\n",
    "    print(\"⚠️  WARNING: Local CLIFpy still in path!\")\n",
    "    for path in sys.path:\n",
    "        if local_clifpy_path in path:\n",
    "            print(f\"   Found: {path}\")\n",
    "else:\n",
    "    print(\"✅ Clean environment - no local CLIFpy in path\")\n",
    "\n",
    "print(f\"\\n=== Working Directory ===\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "## import outlier json\n",
    "# with open('../config/outlier_config.json', 'r', encoding='utf-8') as f:\n",
    "#     outlier_cfg = json.load(f)\n",
    "\n",
    "print(f\"\\n=� Configuration:\")\n",
    "print(f\"   Data directory: {config['tables_path']}\")\n",
    "print(f\"   File type: {config['file_type']}\")\n",
    "print(f\"   Timezone: {config['timezone']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3498513e",
   "metadata": {},
   "source": [
    "# Load intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631cba5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the dataframes saved as parquet files in 00_cohort.ipynb\n",
    "cohort_df = pd.read_parquet(\"../output/intermediate/cohort_df.parquet\")\n",
    "outcomes_df = pd.read_parquet(\"../output/intermediate/outcomes_df.parquet\")\n",
    "weight_df = pd.read_parquet(\"../output/intermediate/weight_df.parquet\")\n",
    "crrt_at_initiation = pd.read_parquet(\"../output/intermediate/crrt_at_initiation.parquet\")\n",
    "crrt_initiation = pd.read_parquet(\"../output/intermediate/crrt_initiation.parquet\")\n",
    "index_crrt_df = pd.read_parquet(\"../output/intermediate/index_crrt_df.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6142c863",
   "metadata": {},
   "source": [
    "# CRRT Dose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e08f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Calculate 30-Day Mortality from CRRT Initiation\n",
    "# ============================================================================\n",
    "print(\"\\nCalculating 30-day mortality from CRRT initiation...\")\n",
    "\n",
    "index_crrt_df = index_crrt_df.merge(\n",
    "    outcomes_df[['encounter_block', 'death_dttm', 'died', 'in_hosp_death']],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "index_crrt_df['days_crrt_to_death'] = np.where(\n",
    "    index_crrt_df['death_dttm'].notna(),\n",
    "    (index_crrt_df['death_dttm'] - index_crrt_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "index_crrt_df['death_30d_from_crrt'] = np.where(\n",
    "    (index_crrt_df['days_crrt_to_death'].notna()) &\n",
    "    (index_crrt_df['days_crrt_to_death'] <= 30),\n",
    "    1,\n",
    "    0\n",
    ")\n",
    "\n",
    "print(f\"   Deaths within 30 days of CRRT initiation: {index_crrt_df['death_30d_from_crrt'].sum():,}\")\n",
    "print(f\"   30-day mortality rate: {index_crrt_df['death_30d_from_crrt'].mean() * 100:.1f}%\")\n",
    "print(f\"   In-hospital mortality: {index_crrt_df['in_hosp_death'].sum():,} ({index_crrt_df['in_hosp_death'].mean() * 100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "#  Summary Statistics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CRRT Dose Summary Statistics at Initiation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "dose_available = index_crrt_df['crrt_dose_ml_kg_hr'].notna()\n",
    "print(f\"\\n   CRRT doses calculated: {dose_available.sum():,}/{len(index_crrt_df):,} ({dose_available.mean()*100:.1f}%)\")\n",
    "\n",
    "if dose_available.sum() > 0:\n",
    "    dose_stats = index_crrt_df['crrt_dose_ml_kg_hr'].describe()\n",
    "    print(f\"\\n   Dose statistics (mL/kg/hr):\")\n",
    "    print(f\"     Mean ± SD: {dose_stats['mean']:.1f} ± {dose_stats['std']:.1f}\")\n",
    "    print(f\"     Median [IQR]: {dose_stats['50%']:.1f} [{dose_stats['25%']:.1f}-{dose_stats['75%']:.1f}]\")\n",
    "    print(f\"     Range: {dose_stats['min']:.1f} - {dose_stats['max']:.1f}\")\n",
    "\n",
    "    print(f\"\\n   Clinical Target Analysis:\")\n",
    "    target_range = ((index_crrt_df['crrt_dose_ml_kg_hr'] >= 20) &\n",
    "                    (index_crrt_df['crrt_dose_ml_kg_hr'] <= 25)).sum()\n",
    "    below_target = (index_crrt_df['crrt_dose_ml_kg_hr'] < 20).sum()\n",
    "    above_target = (index_crrt_df['crrt_dose_ml_kg_hr'] > 25).sum()\n",
    "\n",
    "    print(f\"     Below target (<20 mL/kg/hr): {below_target:,} ({below_target/dose_available.sum()*100:.1f}%)\")\n",
    "    print(f\"     Within target (20-25 mL/kg/hr): {target_range:,} ({target_range/dose_available.sum()*100:.1f}%)\")\n",
    "    print(f\"     Above target (>25 mL/kg/hr): {above_target:,} ({above_target/dose_available.sum()*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Dose and Mortality by CRRT Mode:\")\n",
    "for mode in index_crrt_df['crrt_mode_category'].unique():\n",
    "    if pd.notna(mode):\n",
    "        mode_data = index_crrt_df[index_crrt_df['crrt_mode_category'] == mode]\n",
    "        mode_doses = mode_data['crrt_dose_ml_kg_hr'].dropna()\n",
    "\n",
    "        if len(mode_data) > 0:\n",
    "            print(f\"     {mode.upper()}:\")\n",
    "            print(f\"       Count: {len(mode_data):,} ({len(mode_data)/len(index_crrt_df)*100:.1f}%)\")\n",
    "            if len(mode_doses) > 0:\n",
    "                print(f\"       Mean dose: {mode_doses.mean():.1f} mL/kg/hr\")\n",
    "                print(f\"       Median dose: {mode_doses.median():.1f} mL/kg/hr\")\n",
    "            print(f\"       30-day mortality: {mode_data['death_30d_from_crrt'].sum():,} ({mode_data['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 10: Create Final Analysis Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating Final Analysis Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "analysis_columns = [\n",
    "    'encounter_block',\n",
    "    'hospitalization_id',\n",
    "    'crrt_initiation_time',\n",
    "    'crrt_mode_category',\n",
    "    'weight_kg',\n",
    "    'total_flow_rate',\n",
    "    'crrt_dose_ml_kg_hr',\n",
    "    'total_flow_rate_full',\n",
    "    'crrt_dose_ml_kg_hr_full', \n",
    "    'dialysate_flow_rate',\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'ultrafiltration_out',\n",
    "    'died',\n",
    "    'in_hosp_death',\n",
    "    'death_30d_from_crrt',\n",
    "    'days_crrt_to_death',\n",
    "    'death_dttm',\n",
    "    'duration_days', 'imv_duration_days'\n",
    "]\n",
    "\n",
    "crrt_analysis_df = index_crrt_df[analysis_columns].copy()\n",
    "\n",
    "print(f\"\\n   Final analysis dataset created:\")\n",
    "print(f\"     Total records: {len(crrt_analysis_df):,}\")\n",
    "print(f\"     Unique encounter blocks: {crrt_analysis_df['encounter_block'].nunique():,}\")\n",
    "print(f\"     Records with valid dose: {crrt_analysis_df['crrt_dose_ml_kg_hr'].notna().sum():,}\")\n",
    "print(f\"     Records with weight: {crrt_analysis_df['weight_kg'].notna().sum():,}\")\n",
    "print(f\"     30-day mortality: {crrt_analysis_df['death_30d_from_crrt'].sum():,} ({crrt_analysis_df['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ CRRT analysis completed successfully!\")\n",
    "print(f\"   Dataset 'crrt_analysis_df' ready for further analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff68d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "crrt_analysis_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac66833",
   "metadata": {},
   "source": [
    "# SOFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e24c6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_cohort_df = index_crrt_df[['hospitalization_id', 'encounter_block', 'crrt_initiation_time']].copy()\n",
    "sofa_cohort_df['start_dttm'] = sofa_cohort_df['crrt_initiation_time'] + pd.Timedelta(hours=-12)\n",
    "sofa_cohort_df['end_dttm'] = sofa_cohort_df['crrt_initiation_time'] + pd.Timedelta(hours=3)\n",
    "\n",
    "# Keep only required columns\n",
    "sofa_cohort_df = sofa_cohort_df[['hospitalization_id','encounter_block', 'start_dttm', 'end_dttm']]\n",
    "sofa_cohort_ids = cohort_df['hospitalization_id'].astype(str).unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import sofa_calculator\n",
    "import importlib\n",
    "import sys\n",
    "importlib.reload(sofa_calculator)\n",
    "from sofa_calculator import compute_sofa_polars\n",
    "\n",
    "\n",
    "# Rename columns to match sofa_calculator requirements\n",
    "sofa_input_df = sofa_cohort_df.rename(columns={\n",
    "    'start_time': 'start_dttm',\n",
    "    'end_time': 'end_dttm'\n",
    "})\n",
    "\n",
    "# Convert pandas → Polars\n",
    "sofa_input_pl = pl.from_pandas(sofa_input_df)\n",
    "\n",
    "#  Call SOFA Calculator\n",
    "\n",
    "print(\"Calculating SOFA scores...\")\n",
    "sofa_scores_pl = compute_sofa_polars(\n",
    "    data_directory=config['tables_path'],\n",
    "    cohort_df=sofa_input_pl,\n",
    "    filetype=config['file_type'],\n",
    "    id_name='encounter_block',  # Group by encounter blocks\n",
    "    extremal_type='worst',\n",
    "    fill_na_scores_with_zero=False,  # Leave null as requested\n",
    "    remove_outliers=True,\n",
    "    timezone=config['timezone']\n",
    ")\n",
    "\n",
    "# Convert Results Back to Pandas\n",
    "\n",
    "# Convert Polars → pandas\n",
    "sofa_scores_df = sofa_scores_pl.to_pandas()\n",
    "\n",
    "print(f\"✓ SOFA scores calculated for {len(sofa_scores_df)} encounter blocks\")\n",
    "print(f\"  Mean total SOFA: {sofa_scores_df['sofa_total'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05be607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create histogram of SOFA total scores\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Plot histogram\n",
    "ax.hist(sofa_scores_df['sofa_total'].dropna(),\n",
    "        bins=range(0, int(sofa_scores_df['sofa_total'].max()) + 2),\n",
    "        edgecolor='black',\n",
    "        alpha=0.7,\n",
    "        color='steelblue')\n",
    "\n",
    "# Add vertical line for mean\n",
    "mean_sofa = sofa_scores_df['sofa_total'].mean()\n",
    "ax.axvline(mean_sofa, color='red', linestyle='--', linewidth=2,\n",
    "            label=f'Mean: {mean_sofa:.1f}')\n",
    "\n",
    "# Add vertical line for median\n",
    "median_sofa = sofa_scores_df['sofa_total'].median()\n",
    "ax.axvline(median_sofa, color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'Median: {median_sofa:.1f}')\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel('SOFA Total Score', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('Number of Encounters', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Distribution of SOFA Total Scores at CRRT Initiation',\n",
    "            fontsize=14, fontweight='bold', pad=20)\n",
    "\n",
    "# Add grid\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# Add statistics text box\n",
    "stats_text = f'n = {sofa_scores_df[\"sofa_total\"].notna().sum()}\\n'\n",
    "stats_text += f'Mean ± SD: {mean_sofa:.1f} ± {sofa_scores_df[\"sofa_total\"].std():.1f}\\n'\n",
    "stats_text += f'Median [IQR]: {median_sofa:.1f} [{sofa_scores_df[\"sofa_total\"].quantile(0.25):.1f}-{sofa_scores_df[\"sofa_total\"].quantile(0.75):.1f}]'\n",
    "\n",
    "ax.text(0.98, 0.97, stats_text,\n",
    "        transform=ax.transAxes,\n",
    "        fontsize=10,\n",
    "        verticalalignment='top',\n",
    "        horizontalalignment='right',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "# Legend\n",
    "# ax.legend(loc='upper right', fontsize=10)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('../output/final/graphs/sofa_total_distribution.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Histogram saved to output/final/graphs/sofa_total_distribution.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df62b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "outcomes_with_sofa = outcomes_df.merge(sofa_scores_df, on='encounter_block', how='left')\n",
    "# Calculate mortality rate by SOFA total score\n",
    "mortality_by_sofa = outcomes_with_sofa.groupby('sofa_total').agg({\n",
    "    'in_hosp_death': ['sum', 'count', 'mean']\n",
    "}).reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "mortality_by_sofa.columns = ['sofa_total', 'deaths', 'n_encounters', 'mortality_rate']\n",
    "mortality_by_sofa['mortality_pct'] = mortality_by_sofa['mortality_rate'] * 100\n",
    "\n",
    "# Sort by SOFA score\n",
    "mortality_by_sofa = mortality_by_sofa.sort_values('sofa_total')\n",
    "\n",
    "# Save CSV for this SOFA vs mortality data\n",
    "mortality_by_sofa.to_csv('../output/final/sofa_mortality_data.csv', index=False)\n",
    "print(\"✓ SOFA-mortality summary CSV saved to ../output/final/sofa_mortality_data.csv\")\n",
    "\n",
    "# Create figure with two subplots (main plot + table)\n",
    "fig = plt.figure(figsize=(14, 8))\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.05)\n",
    "ax_main = fig.add_subplot(gs[0])\n",
    "ax_table = fig.add_subplot(gs[1])\n",
    "\n",
    "# Main plot - Mortality rate bars\n",
    "bars = ax_main.bar(mortality_by_sofa['sofa_total'],\n",
    "                    mortality_by_sofa['mortality_pct'],\n",
    "                    color='steelblue',\n",
    "                    edgecolor='black',\n",
    "                    alpha=0.7,\n",
    "                    width=0.8)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, (sofa, pct, n) in enumerate(zip(mortality_by_sofa['sofa_total'],\n",
    "                                        mortality_by_sofa['mortality_pct'],\n",
    "                                        mortality_by_sofa['n_encounters'])):\n",
    "    ax_main.text(sofa, pct + 1, f'{pct:.1f}%',\n",
    "                ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# Main plot formatting\n",
    "ax_main.set_ylabel('In-Hospital Mortality (%)', fontsize=12, fontweight='bold')\n",
    "ax_main.set_title('In-Hospital Mortality by SOFA Total Score at CRRT Initiation',\n",
    "                fontsize=14, fontweight='bold', pad=20)\n",
    "ax_main.set_ylim(0, mortality_by_sofa['mortality_pct'].max() * 1.15)\n",
    "ax_main.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "ax_main.set_xlim(mortality_by_sofa['sofa_total'].min() - 0.5,\n",
    "                mortality_by_sofa['sofa_total'].max() + 0.5)\n",
    "\n",
    "# Remove x-axis labels from main plot (will show in table)\n",
    "ax_main.set_xticklabels([])\n",
    "ax_main.set_xlabel('')\n",
    "\n",
    "# Create table with encounter counts\n",
    "ax_table.axis('tight')\n",
    "ax_table.axis('off')\n",
    "\n",
    "# Prepare table data\n",
    "table_data = [\n",
    "    [f'{int(score)}' for score in mortality_by_sofa['sofa_total']],\n",
    "    [f'n={int(n)}' for n in mortality_by_sofa['n_encounters']]\n",
    "]\n",
    "\n",
    "# Create table\n",
    "table = ax_table.table(cellText=table_data,\n",
    "                        rowLabels=['SOFA Score', 'N Encounters'],\n",
    "                        cellLoc='center',\n",
    "                        loc='center',\n",
    "                        colWidths=[1/len(mortality_by_sofa)] * len(mortality_by_sofa))\n",
    "\n",
    "# Format table\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Style table cells\n",
    "for i in range(len(table_data)):\n",
    "    for j in range(len(mortality_by_sofa)):\n",
    "        cell = table[(i, j)]\n",
    "        cell.set_facecolor('lightgray' if i == 0 else 'white')\n",
    "        cell.set_text_props(weight='bold' if i == 0 else 'normal')\n",
    "\n",
    "# Style row labels\n",
    "for i in range(len(table_data)):\n",
    "    cell = table[(i, -1)]\n",
    "    cell.set_facecolor('lightsteelblue')\n",
    "    cell.set_text_props(weight='bold', ha='right')\n",
    "\n",
    "# Add overall statistics box\n",
    "overall_mortality = outcomes_with_sofa['in_hosp_death'].mean() * 100\n",
    "total_n = len(outcomes_with_sofa)\n",
    "stats_text = f'Overall Mortality: {overall_mortality:.1f}%\\nTotal N: {total_n:,}'\n",
    "\n",
    "ax_main.text(0.02, 0.98, stats_text,\n",
    "            transform=ax_main.transAxes,\n",
    "            fontsize=11,\n",
    "            verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Save figure\n",
    "plt.savefig('../output/final/graphs/mortality_by_sofa_score.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Mortality by SOFA score plot saved to output/final/graphs/mortality_by_sofa_score.png\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead81b42",
   "metadata": {},
   "source": [
    "# Labs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a4d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy.clif_orchestrator import ClifOrchestrator\n",
    "\n",
    "# Initialize ClifOrchestrator\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=config['tables_path'],\n",
    "    filetype=config['file_type'],\n",
    "    timezone=config['timezone']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labs\n",
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['po2_arterial','pco2_arterial', 'ph_arterial','ph_venous', 'bicarbonate','so2_arterial',\n",
    "                    'sodium', 'potassium', 'chloride', 'calcium_total', 'magnesium', 'creatinine', \n",
    "                    'bun', 'glucose_serum', 'lactate', 'hemoglobin', 'phosphate']\n",
    "\n",
    "# labs_of_interest = ['ph_arterial', 'lactate', 'bicarbonate', 'potassium']\n",
    "\n",
    "print(f\"\\nLoading labs table...\")\n",
    "clif.load_table(\n",
    "    'labs',\n",
    "    columns=labs_required_columns,\n",
    "    filters={\n",
    "        'hospitalization_id': cohort_df['hospitalization_id'].unique().tolist(),\n",
    "        'lab_category': labs_of_interest\n",
    "    }\n",
    ")\n",
    "print(f\"   Labs loaded: {len(clif.labs.df):,} rows\")\n",
    "print(f\"   Unique lab categories: {clif.labs.df['lab_category'].nunique()}\")\n",
    "print(f\"   Unique lab hospitalizations: {clif.labs.df['hospitalization_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32388f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Get Most Recent Labs Within 6h of CRRT Initiation\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Processing Labs - Most Recent Within 6h of CRRT Initiation\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get labs dataframe\n",
    "labs_df = clif.labs.df.copy()\n",
    "\n",
    "# Merge with CRRT initiation times to get the reference time\n",
    "labs_with_crrt = labs_df.merge(\n",
    "    crrt_analysis_df[['encounter_block', 'hospitalization_id', 'crrt_initiation_time']],\n",
    "    on='hospitalization_id',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"   Labs after merging with CRRT cohort: {len(labs_with_crrt):,}\")\n",
    "\n",
    "# Filter for labs within 6 hours BEFORE CRRT initiation\n",
    "labs_before = labs_with_crrt[\n",
    "    (labs_with_crrt['lab_result_dttm'] <= labs_with_crrt['crrt_initiation_time']) &\n",
    "    (labs_with_crrt['lab_result_dttm'] >= labs_with_crrt['crrt_initiation_time'] - pd.Timedelta(hours=12))\n",
    "].copy()\n",
    "\n",
    "# Filter for labs within 6 hours AFTER CRRT initiation\n",
    "labs_after = labs_with_crrt[\n",
    "    (labs_with_crrt['lab_result_dttm'] > labs_with_crrt['crrt_initiation_time']) &\n",
    "    (labs_with_crrt['lab_result_dttm'] <= labs_with_crrt['crrt_initiation_time'] + pd.Timedelta(hours=3))\n",
    "].copy()\n",
    "\n",
    "print(f\"   Labs within 6h before CRRT: {len(labs_before):,}\")\n",
    "print(f\"   Labs within 6h after CRRT: {len(labs_after):,}\")\n",
    "\n",
    "# Strategy: Prioritize BEFORE, then AFTER\n",
    "# For each encounter_block + lab_category:\n",
    "#   1. If lab exists BEFORE initiation: take the MOST RECENT (closest to initiation)\n",
    "#   2. If no lab BEFORE: take the EARLIEST lab AFTER initiation\n",
    "\n",
    "# Get most recent lab BEFORE initiation per encounter_block + lab_category\n",
    "labs_before_sorted = labs_before.sort_values(['encounter_block', 'lab_category', 'lab_result_dttm'])\n",
    "labs_before_most_recent = (labs_before_sorted\n",
    "                            .groupby(['encounter_block', 'lab_category'])\n",
    "                            .last()  # Most recent = closest to initiation\n",
    "                            .reset_index())\n",
    "labs_before_most_recent['source'] = 'before'\n",
    "\n",
    "# Get earliest lab AFTER initiation per encounter_block + lab_category\n",
    "labs_after_sorted = labs_after.sort_values(['encounter_block', 'lab_category', 'lab_result_dttm'])\n",
    "labs_after_earliest = (labs_after_sorted\n",
    "                        .groupby(['encounter_block', 'lab_category'])\n",
    "                        .first()  # Earliest = closest to initiation\n",
    "                        .reset_index())\n",
    "labs_after_earliest['source'] = 'after'\n",
    "\n",
    "# Identify which encounter_block + lab_category combinations have BEFORE labs\n",
    "before_keys = set(labs_before_most_recent[['encounter_block', 'lab_category']].apply(tuple, axis=1))\n",
    "\n",
    "# Filter AFTER labs to only those WITHOUT a BEFORE lab\n",
    "labs_after_filtered = labs_after_earliest[\n",
    "    ~labs_after_earliest[['encounter_block', 'lab_category']].apply(tuple, axis=1).isin(before_keys)\n",
    "]\n",
    "\n",
    "# Combine: all BEFORE labs + AFTER labs (only where no BEFORE exists)\n",
    "labs_final = pd.concat([labs_before_most_recent, labs_after_filtered], ignore_index=True)\n",
    "\n",
    "print(f\"\\n   Final lab selection:\")\n",
    "print(f\"     From BEFORE window: {(labs_final['source'] == 'before').sum():,}\")\n",
    "print(f\"     From AFTER window: {(labs_final['source'] == 'after').sum():,}\")\n",
    "print(f\"     Total unique encounter_block + lab combinations: {len(labs_final):,}\")\n",
    "\n",
    "# Pivot to wide format (one row per encounter_block, one column per lab)\n",
    "labs_wide = labs_final.pivot(\n",
    "    index='encounter_block',\n",
    "    columns='lab_category',\n",
    "    values='lab_value_numeric'\n",
    ").reset_index()\n",
    "\n",
    "# Add suffix to lab column names for clarity\n",
    "labs_wide.columns = ['encounter_block'] + [f'{col}_peri_crrt' for col in labs_wide.columns if col != 'encounter_block']\n",
    "\n",
    "print(f\"\\n   Labs in wide format:\")\n",
    "print(f\"     Encounter blocks: {len(labs_wide):,}\")\n",
    "print(f\"     Lab columns: {list(labs_wide.columns)}\")\n",
    "\n",
    "# Show availability by lab\n",
    "print(f\"\\n   Lab value availability (non-null):\")\n",
    "for col in labs_wide.columns:\n",
    "    if col != 'encounter_block':\n",
    "        n_available = labs_wide[col].notna().sum()\n",
    "        pct = n_available / len(labs_wide) * 100\n",
    "        print(f\"     {col}: {n_available:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Merge back with CRRT analysis dataset\n",
    "crrt_with_labs = crrt_analysis_df.merge(\n",
    "    labs_wide,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\n   Final dataset with labs:\")\n",
    "print(f\"     Total records: {len(crrt_with_labs):,}\")\n",
    "print(f\"     Records with at least one lab: {(crrt_with_labs[[col for col in crrt_with_labs.columns if '_peri_crrt' in col]].notna().any(axis=1)).sum():,}\")\n",
    "\n",
    "print(\"\\n✅ Lab processing completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffc2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Identify Encounter Blocks Without Labs\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Identifying Encounter Blocks Without Labs\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get all lab columns\n",
    "lab_columns = [col for col in crrt_with_labs.columns if '_peri_crrt' in col]\n",
    "\n",
    "# Identify encounters with NO labs documented (all lab columns are null)\n",
    "crrt_with_labs['has_any_lab'] = crrt_with_labs[lab_columns].notna().any(axis=1)\n",
    "encounters_without_labs = crrt_with_labs[~crrt_with_labs['has_any_lab']].copy()\n",
    "\n",
    "# Summary statistics\n",
    "total_encounters = len(crrt_with_labs)\n",
    "encounters_with_labs = crrt_with_labs['has_any_lab'].sum()\n",
    "encounters_without_labs_count = len(encounters_without_labs)\n",
    "\n",
    "print(f\"\\n   Lab Documentation Status:\")\n",
    "print(f\"     Total encounter blocks: {total_encounters:,}\")\n",
    "print(f\"     With at least one lab: {encounters_with_labs:,} ({encounters_with_labs/total_encounters*100:.1f}%)\")\n",
    "print(f\"     WITHOUT any labs: {encounters_without_labs_count:,} ({encounters_without_labs_count/total_encounters*100:.1f}%)\")\n",
    "\n",
    "# Show breakdown by lab category availability\n",
    "print(f\"\\n   Lab-specific availability:\")\n",
    "for lab_col in lab_columns:\n",
    "    n_available = crrt_with_labs[lab_col].notna().sum()\n",
    "    pct = n_available / total_encounters * 100\n",
    "    lab_name = lab_col.replace('_peri_crrt', '')\n",
    "    print(f\"     {lab_name}: {n_available:,}/{total_encounters:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Show characteristics of encounters without labs\n",
    "if len(encounters_without_labs) > 0:\n",
    "    print(f\"\\n   Characteristics of encounters WITHOUT labs:\")\n",
    "    print(f\"     CRRT modes:\")\n",
    "    mode_dist = encounters_without_labs['crrt_mode_category'].value_counts()\n",
    "    for mode, count in mode_dist.items():\n",
    "        print(f\"       {mode}: {count:,} ({count/len(encounters_without_labs)*100:.1f}%)\")\n",
    "\n",
    "    print(f\"     Mortality:\")\n",
    "    print(f\"       30-day deaths: {encounters_without_labs['death_30d_from_crrt'].sum():,} ({encounters_without_labs['death_30d_from_crrt'].mean()*100:.1f}%)\")\n",
    "    print(f\"       In-hospital deaths: {encounters_without_labs['in_hosp_death'].sum():,} ({encounters_without_labs['in_hosp_death'].mean()*100:.1f}%)\")\n",
    "\n",
    "# Optional: Save list of encounter blocks without labs for QC\n",
    "encounters_without_labs_list = encounters_without_labs[['encounter_block', 'hospitalization_id', 'crrt_initiation_time']].copy()\n",
    "\n",
    "print(f\"\\n   Sample encounter blocks without labs (first 10):\")\n",
    "if len(encounters_without_labs_list) > 0:\n",
    "    print(encounters_without_labs_list.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"     None - all encounters have at least one lab!\")\n",
    "\n",
    "# Create analysis-ready dataset flag\n",
    "# You may want to exclude encounters without labs from certain analyses\n",
    "crrt_with_labs['analysis_ready'] = crrt_with_labs['has_any_lab']\n",
    "\n",
    "print(f\"\\n   Analysis-ready encounters (with labs): {crrt_with_labs['analysis_ready'].sum():,}\")\n",
    "print(f\"   Encounters to exclude (no labs): {(~crrt_with_labs['analysis_ready']).sum():,}\")\n",
    "\n",
    "print(\"\\n✅ Lab completeness check completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71afefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "crrt_with_labs.to_parquet('../output/intermediate/crrt_analysis_with_labs.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a5a1fc",
   "metadata": {},
   "source": [
    "# Competing Risk Dataset\n",
    "\n",
    "Outcome coding:  \n",
    "\n",
    "* 0 = Censored (>90 days or still hospitalized)\n",
    "* 1 = Discharged alive (within 90 days)\n",
    "* 2 = Died (within 90 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b9f966",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df_name, df in [(\"outcomes_with_sofa\", outcomes_with_sofa), \n",
    "                    (\"crrt_analysis_df\", crrt_analysis_df), \n",
    "                    (\"crrt_with_labs\", crrt_with_labs)]:\n",
    "    print(f\"\\nDataFrame: {df_name}\")\n",
    "    print(f\"Columns ({len(df.columns)}): {list(df.columns)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbe032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# Create Competing Risk Analysis Dataset\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Creating Competing Risk Analysis Dataset\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 1: Merge All Data Sources\n",
    "# ============================================================================\n",
    "print(\"\\n1. Merging data sources...\")\n",
    "\n",
    "# Start with CRRT data (has crrt_initiation_time and CRRT parameters)\n",
    "competing_risk_df = crrt_with_labs.copy()\n",
    "\n",
    "print(f\"   Starting with CRRT data: {len(competing_risk_df):,} encounter blocks\")\n",
    "\n",
    "# Merge demographics and outcomes from outcomes_with_sofa\n",
    "# Select relevant columns (avoid duplicates)\n",
    "outcomes_cols = [\n",
    "    'encounter_block',\n",
    "    'age_at_admission',\n",
    "    'sex_category',\n",
    "    'race_category',\n",
    "    'ethnicity_category',\n",
    "    'icu_los_days',\n",
    "    'hosp_los_days',\n",
    "    'duration_days', 'imv_duration_days',\n",
    "    'admission_type_category',\n",
    "    'discharge_category',\n",
    "    'first_vital_dttm',\n",
    "    'last_vital_dttm',\n",
    "    'final_outcome_dttm', \n",
    "    'sofa_cv_97',\n",
    "    'sofa_coag',\n",
    "    'sofa_liver',\n",
    "    'sofa_resp',\n",
    "    'sofa_cns',\n",
    "    'sofa_renal',\n",
    "    'sofa_total'\n",
    "]\n",
    "\n",
    "# Check which columns exist in outcomes_with_sofa\n",
    "available_cols = [col for col in outcomes_cols if col in outcomes_with_sofa.columns]\n",
    "\n",
    "competing_risk_df = competing_risk_df.merge(\n",
    "    outcomes_with_sofa[available_cols],\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"   After merging outcomes: {len(competing_risk_df):,} rows, {len(competing_risk_df.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bb75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 2: Calculate Time-to-Event (Days from CRRT to Discharge/Death)\n",
    "# ============================================================================\n",
    "print(\"\\n2. Calculating time-to-event...\")\n",
    "\n",
    "# For discharged alive: use last_vital_dttm as proxy for discharge time\n",
    "# For died: use final_outcome_dttm (most accurate death timestamp)\n",
    "competing_risk_df['discharge_dttm'] = competing_risk_df['last_vital_dttm']\n",
    "\n",
    "# Calculate time to event in days\n",
    "competing_risk_df['time_to_event_days'] = np.where(\n",
    "    competing_risk_df['died'] == 1,\n",
    "    # If died: time from CRRT to final_outcome_dttm\n",
    "    (competing_risk_df['final_outcome_dttm'] - competing_risk_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600),\n",
    "    # If alive: time from CRRT to discharge\n",
    "    (competing_risk_df['discharge_dttm'] - competing_risk_df['crrt_initiation_time']).dt.total_seconds() / (24 * 3600)\n",
    ")\n",
    "\n",
    "# Handle negative or zero times\n",
    "negative_times = (competing_risk_df['time_to_event_days'] < 0).sum()\n",
    "if negative_times > 0:\n",
    "    print(f\"   ⚠️  {negative_times} records with negative time-to-event (setting to 0.5 days)\")\n",
    "    competing_risk_df.loc[competing_risk_df['time_to_event_days'] < 0, 'time_to_event_days'] = 0.5\n",
    "\n",
    "zero_times = (competing_risk_df['time_to_event_days'] == 0).sum()\n",
    "if zero_times > 0:\n",
    "    print(f\"   ⚠️  {zero_times} records with zero time-to-event (setting to 0.5 days)\")\n",
    "    competing_risk_df.loc[competing_risk_df['time_to_event_days'] == 0, 'time_to_event_days'] = 0.5\n",
    "\n",
    "print(f\"   Time-to-event range: {competing_risk_df['time_to_event_days'].min():.1f} - {competing_risk_df['time_to_event_days'].max():.1f} days\")\n",
    "print(f\"   Median: {competing_risk_df['time_to_event_days'].median():.1f} days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e57dd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 3: Apply 90-Day Censoring and Calculate 90-Day Mortality\n",
    "# ============================================================================\n",
    "print(\"\\n3. Applying 90-day censoring...\")\n",
    "\n",
    "# Cap at 90 days\n",
    "competing_risk_df['time_to_event_90d'] = competing_risk_df['time_to_event_days'].clip(upper=90)\n",
    "\n",
    "# Flag censoring\n",
    "competing_risk_df['censored_at_90d'] = (competing_risk_df['time_to_event_days'] > 90).astype(int)\n",
    "\n",
    "# Calculate 90-day mortality from CRRT initiation\n",
    "competing_risk_df['death_90d_from_crrt'] = (\n",
    "    (competing_risk_df['died'] == 1) &\n",
    "    (competing_risk_df['time_to_event_days'] <= 90)\n",
    ").astype(int)\n",
    "\n",
    "events_censored = competing_risk_df['censored_at_90d'].sum()\n",
    "deaths_90d = competing_risk_df['death_90d_from_crrt'].sum()\n",
    "\n",
    "print(f\"   Events censored at 90 days: {events_censored:,} ({events_censored/len(competing_risk_df)*100:.1f}%)\")\n",
    "print(f\"   Deaths within 90 days of CRRT: {deaths_90d:,} ({deaths_90d/len(competing_risk_df)*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# STEP 4: Create Competing Risk Outcome Variable\n",
    "# ============================================================================\n",
    "print(\"\\n4. Creating competing risk outcome variable...\")\n",
    "\n",
    "# Outcome coding:\n",
    "# 0 = Censored (>90 days or still hospitalized)\n",
    "# 1 = Discharged alive (within 90 days)\n",
    "# 2 = Died (within 90 days)\n",
    "\n",
    "competing_risk_df['outcome'] = 0  # Default: censored\n",
    "\n",
    "# Discharged alive within 90 days\n",
    "competing_risk_df.loc[\n",
    "    (competing_risk_df['death_90d_from_crrt'] == 0) &\n",
    "    (competing_risk_df['time_to_event_days'] <= 90),\n",
    "    'outcome'\n",
    "] = 1\n",
    "\n",
    "# Died within 90 days\n",
    "competing_risk_df.loc[\n",
    "    competing_risk_df['death_90d_from_crrt'] == 1,\n",
    "    'outcome'\n",
    "] = 2\n",
    "\n",
    "# Outcome distribution\n",
    "print(f\"\\n   Outcome distribution:\")\n",
    "outcome_labels = {0: 'Censored (>90d)', 1: 'Discharged alive', 2: 'Died'}\n",
    "for outcome_val in [0, 1, 2]:\n",
    "    count = (competing_risk_df['outcome'] == outcome_val).sum()\n",
    "    pct = count / len(competing_risk_df) * 100\n",
    "    print(f\"     {outcome_labels[outcome_val]}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7ca452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 5: Select Final Columns\n",
    "# ============================================================================\n",
    "print(\"\\n5. Selecting final analysis columns...\")\n",
    "\n",
    "final_columns = [\n",
    "    # Identifiers\n",
    "    'encounter_block',\n",
    "\n",
    "    # Time and outcome\n",
    "    'crrt_initiation_time',\n",
    "    'time_to_event_90d',\n",
    "    'outcome',\n",
    "    'censored_at_90d',\n",
    "\n",
    "    # Demographics\n",
    "    'age_at_admission',\n",
    "    'sex_category',\n",
    "    'race_category',\n",
    "    'ethnicity_category',\n",
    "\n",
    "    # CRRT parameters\n",
    "    'crrt_mode_category',\n",
    "    'crrt_dose_ml_kg_hr',\n",
    "    'crrt_dose_ml_kg_hr_full',\n",
    "    'dialysate_flow_rate',\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'ultrafiltration_out',\n",
    "    'total_flow_rate',\n",
    "    'weight_kg',\n",
    "\n",
    "    # Labs (peri-CRRT)\n",
    "    'ph_arterial_peri_crrt',\n",
    "    'lactate_peri_crrt',\n",
    "    'bicarbonate_peri_crrt',\n",
    "    'potassium_peri_crrt',\n",
    "    'sodium_peri_crrt',\n",
    "    'creatinine_peri_crrt',\n",
    "    'bun_peri_crrt',\n",
    "    'hemoglobin_peri_crrt',\n",
    "    'glucose_serum_peri_crrt',\n",
    "    'phosphate_peri_crrt',\n",
    "\n",
    "\n",
    "    # SOFA scores\n",
    "    'sofa_cv_97',\n",
    "    'sofa_coag',\n",
    "    'sofa_liver',\n",
    "    'sofa_resp',\n",
    "    'sofa_cns',\n",
    "    'sofa_renal',\n",
    "    'sofa_total',\n",
    "\n",
    "    # LOS\n",
    "    'icu_los_days',\n",
    "    'hosp_los_days',\n",
    "\n",
    "    # Quality flags\n",
    "    'has_any_lab',\n",
    "    'analysis_ready',\n",
    "\n",
    "    #'Treatment Duration'\n",
    "    'duration_days', \n",
    "    'imv_duration_days'\n",
    "]\n",
    "\n",
    "# Keep only columns that exist\n",
    "available_final_cols = [col for col in final_columns if col in competing_risk_df.columns]\n",
    "competing_risk_final = competing_risk_df[available_final_cols].copy()\n",
    "\n",
    "print(f\"   Final dataset: {len(competing_risk_final):,} rows × {len(competing_risk_final.columns)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 6: Data Validation\n",
    "# ============================================================================\n",
    "print(\"\\n6. Data validation...\")\n",
    "\n",
    "# Check for impossible values\n",
    "issues = []\n",
    "\n",
    "# Time-to-event validation\n",
    "if (competing_risk_final['time_to_event_90d'] < 0).any():\n",
    "    issues.append(\"Negative time-to-event values\")\n",
    "\n",
    "# Age validation\n",
    "if 'age_at_admission' in competing_risk_final.columns:\n",
    "    invalid_age = ((competing_risk_final['age_at_admission'] < 18) |\n",
    "                    (competing_risk_final['age_at_admission'] > 120)).sum()\n",
    "    if invalid_age > 0:\n",
    "        issues.append(f\"{invalid_age} records with invalid age\")\n",
    "\n",
    "# Outcome validation\n",
    "if competing_risk_final['outcome'].isna().any():\n",
    "    issues.append(\"Missing outcome values\")\n",
    "\n",
    "if issues:\n",
    "    print(\"   ⚠️  Data quality issues:\")\n",
    "    for issue in issues:\n",
    "        print(f\"     - {issue}\")\n",
    "else:\n",
    "    print(\"   ✓ No data quality issues detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7c7969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 7: Summary Statistics\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Summary Statistics\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\n   Cohort Size: {len(competing_risk_final):,} encounter blocks\")\n",
    "\n",
    "print(f\"\\n   Competing Risk Outcomes:\")\n",
    "for outcome_val in [0, 1, 2]:\n",
    "    count = (competing_risk_final['outcome'] == outcome_val).sum()\n",
    "    pct = count / len(competing_risk_final) * 100\n",
    "    print(f\"     {outcome_labels[outcome_val]}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\n   Time-to-Event (days):\")\n",
    "print(f\"     Mean ± SD: {competing_risk_final['time_to_event_90d'].mean():.1f} ± {competing_risk_final['time_to_event_90d'].std():.1f}\")\n",
    "print(f\"     Median [IQR]: {competing_risk_final['time_to_event_90d'].median():.1f} [{competing_risk_final['time_to_event_90d'].quantile(0.25):.1f}-{competing_risk_final['time_to_event_90d'].quantile(0.75):.1f}]\")\n",
    "\n",
    "if 'age_at_admission' in competing_risk_final.columns:\n",
    "    print(f\"\\n   Age at Admission (years):\")\n",
    "    print(f\"     Mean ± SD: {competing_risk_final['age_at_admission'].mean():.1f} ± {competing_risk_final['age_at_admission'].std():.1f}\")\n",
    "\n",
    "if 'crrt_dose_ml_kg_hr' in competing_risk_final.columns:\n",
    "    dose_available = competing_risk_final['crrt_dose_ml_kg_hr'].notna()\n",
    "    print(f\"\\n   CRRT Dose (mL/kg/hr):\")\n",
    "    print(f\"     Available: {dose_available.sum():,}/{len(competing_risk_final):,} ({dose_available.mean()*100:.1f}%)\")\n",
    "    if dose_available.any():\n",
    "        print(f\"     Mean ± SD: {competing_risk_final['crrt_dose_ml_kg_hr'].mean():.1f} ± {competing_risk_final['crrt_dose_ml_kg_hr'].std():.1f}\")\n",
    "\n",
    "if 'has_any_lab' in competing_risk_final.columns:\n",
    "    print(f\"\\n   Lab Availability:\")\n",
    "    with_labs = competing_risk_final['has_any_lab'].sum()\n",
    "    print(f\"     With labs: {with_labs:,} ({with_labs/len(competing_risk_final)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3298b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "competing_risk_final.to_parquet(\"../output/intermediate/competing_risk_final.parquet\")\n",
    "competing_risk_final.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae00ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descriptive Statistics & Data Quality\n",
    "\n",
    "# Overall summary\n",
    "print(f\"Total encounters: {len(competing_risk_final):,}\")\n",
    "print(f\"Outcome distribution:\")\n",
    "print(competing_risk_final['outcome'].value_counts().sort_index())\n",
    "\n",
    "# Check missingness for key variables\n",
    "key_vars = ['crrt_dose_ml_kg_hr', 'crrt_dose_ml_kg_hr_full','age_at_admission', 'weight_kg',\n",
    "            'crrt_mode_category', 'sofa_total']\n",
    "print(\"\\nMissingness in key variables:\")\n",
    "for var in key_vars:\n",
    "    missing = competing_risk_final[var].isna().sum()\n",
    "    print(f\"  {var}: {missing} ({missing/len(competing_risk_final)*100:.1f}%)\")\n",
    "\n",
    "# Lab availability\n",
    "print(f\"\\nAnalysis-ready (complete labs): {competing_risk_final['analysis_ready'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a55d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Distribution of time-to-event by outcome\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "competing_risk_final[competing_risk_final['outcome']==1]['time_to_event_90d'].hist(bins=30, ax=ax[0])\n",
    "ax[0].set_title('Time to Discharge (Alive)')\n",
    "competing_risk_final[competing_risk_final['outcome']==2]['time_to_event_90d'].hist(bins=30, ax=ax[1])\n",
    "ax[1].set_title('Time to Death')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62704b10",
   "metadata": {},
   "source": [
    "# TableOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee0fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_table_one_competing_risk, print_table_one_summary\n",
    "\n",
    "# Full Table 1 stratified by outcome\n",
    "table1 = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by='outcome',\n",
    "    output_path='../output/final/table1_by_outcome.csv'\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "display(table1)\n",
    "\n",
    "# Quick summary to console\n",
    "print_table_one_summary(competing_risk_final)\n",
    "\n",
    "# Table 1 by CRRT mode instead\n",
    "table1_mode = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by='crrt_mode_category',\n",
    "    output_path='../output/final/table1_by_crrt_mode.csv'\n",
    ")\n",
    "\n",
    "# Overall only (no stratification)\n",
    "table1_overall = create_table_one_competing_risk(\n",
    "    competing_risk_final,\n",
    "    stratify_by=None,\n",
    "    output_path='../output/final/table1_overall.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431e646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Read the data from parquet file\n",
    "parquet_path = \"/Users/kavenchhikara/Projects/CLIF/CLIF-epidemiology-of-CRRT/output/intermediate/competing_risk_final.parquet\"\n",
    "competing_risk_final_from_parquet = pd.read_parquet(parquet_path)\n",
    "# Preview the loaded dataframe\n",
    "# display(competing_risk_final_from_parquet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

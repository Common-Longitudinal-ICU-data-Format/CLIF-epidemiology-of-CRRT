{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7a55492",
   "metadata": {},
   "source": [
    "# Epidemiology of CRRT\n",
    "\n",
    "Author: Kaveri Chhikara\n",
    "\n",
    "This script identifies the cohort using CLIF 2.1 tables\n",
    "**Requirements**\n",
    "\n",
    "* Required table filenames should be `clif_patient`, `clif_hospitalization`, `clif_adt`, `clif_vitals`, `clif_labs`, `clif_medication_admin_continuous`, `clif_respiratory_support` ,`crrt_therapy`, `clif_hospital_diagnosis`\n",
    "* Within each table, the following variables and categories are required.\n",
    "\n",
    "| Table Name | Required Variables | Required Categories |\n",
    "| --- | --- | --- |\n",
    "| **clif_patient** | `patient_id`, `race_category`, `ethnicity_category`, `sex_category`, `death_dttm` | - |\n",
    "| **clif_hospitalization** | `patient_id`, `hospitalization_id`, `admission_dttm`, `discharge_dttm`, `age_at_admission`, `discharge_category` | - |\n",
    "| **clif_adt** |  `hospitalization_id`, `hospital_id`,`in_dttm`, `out_dttm`, `location_category`, `location_type` | - |\n",
    "| **clif_vitals** | `hospitalization_id`, `recorded_dttm`, `vital_category`, `vital_value` | heart_rate, resp_rate, sbp, dbp, map, spo2, weight_kg, height_cm |\n",
    "| **clif_labs** | `hospitalization_id`, `lab_result_dttm`, `lab_category`, `lab_value` | sodium, potassium, chloride, bicarbonate, bun, creatinine, glucose_serum, calcium_total, lactate, magnesium, ph_arterial, ph_venous, po2_arterial |\n",
    "| **clif_medication_admin_continuous** | `hospitalization_id`, `admin_dttm`, `med_name`, `med_category`, `med_dose`, `med_dose_unit` | norepinephrine, epinephrine, phenylephrine, vasopressin, dopamine, angiotensin, dobutamine, milrinone, isoproterenol |\n",
    "| **clif_respiratory_support** | `hospitalization_id`, `recorded_dttm`, `device_category`, `mode_category`, `tracheostomy`, `fio2_set`, `lpm_set`, `resp_rate_set`, `peep_set`, `resp_rate_obs`, `tidal_volume_set`, `pressure_control_set`, `pressure_support_set`, `peak_inspiratory_pressure_set`, `tidal_volume_obs` | - |\n",
    "| **clif_crrt_therapy** | `hospitalization_id`, `recorded_dttm`, `crrt_mode_name`, `crrt_mode_category`, `device_id`, `blood_flow_rate`, `dialysate_flow_rate`, `pre_filter_replacement_fluid_rate`,`post_filter_replacement_fluid_rate`, `ultrafilteration_out` | - |\n",
    "| **clif_hospital_diagnosis** | `hospitalization_id`, `diagnosis_code`, `present_on_admission` | - |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3527d88",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ae96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import json\n",
    "import pyarrow\n",
    "import warnings\n",
    "import clifpy\n",
    "from typing import Union\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "import clifpy\n",
    "import os\n",
    "\n",
    "print(\"=== Environment Verification ===\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"clifpy version: {clifpy.__version__}\")\n",
    "print(f\"clifpy location: {clifpy.__file__}\")\n",
    "\n",
    "print(\"\\n=== Python Path Check ===\")\n",
    "local_clifpy_path = \"/Users/kavenchhikara/Desktop/CLIF/CLIFpy\"\n",
    "if any(local_clifpy_path in path for path in sys.path):\n",
    "    print(\"⚠️  WARNING: Local CLIFpy still in path!\")\n",
    "    for path in sys.path:\n",
    "        if local_clifpy_path in path:\n",
    "            print(f\"   Found: {path}\")\n",
    "else:\n",
    "    print(\"✅ Clean environment - no local CLIFpy in path\")\n",
    "\n",
    "print(f\"\\n=== Working Directory ===\")\n",
    "print(f\"Current directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423e2fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration\n",
    "config_path = \"../config/config.json\"\n",
    "with open(config_path, 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "## import outlier json\n",
    "# with open('../config/outlier_config.json', 'r', encoding='utf-8') as f:\n",
    "#     outlier_cfg = json.load(f)\n",
    "\n",
    "print(f\"\\n=� Configuration:\")\n",
    "print(f\"   Data directory: {config['tables_path']}\")\n",
    "print(f\"   File type: {config['file_type']}\")\n",
    "print(f\"   Timezone: {config['timezone']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b73fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Create output directories if they do not exist\n",
    "os.makedirs(\"../output/final/graphs\", exist_ok=True)\n",
    "os.makedirs(\"../output/intermediate\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc3f969",
   "metadata": {},
   "source": [
    "# Required columns and categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61e0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Defining Required Data Elements\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Full patient table \n",
    "\n",
    "# Full hospitalization table \n",
    "\n",
    "# Full ADT table\n",
    "\n",
    "# Vitals\n",
    "vitals_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'vital_category',\n",
    "    'vital_value'\n",
    "]\n",
    "vitals_of_interest = ['heart_rate', 'respiratory_rate', 'sbp', 'dbp', 'map', 'spo2', 'weight_kg', 'height_cm']\n",
    "\n",
    "#Labs\n",
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['po2_arterial','pco2_arterial', 'ph_arterial','ph_venous', 'bicarbonate','so2_arterial',\n",
    "                    'sodium', 'potassium', 'chloride', 'calcium_total', 'magnesium', 'creatinine', \n",
    "                    'bun', 'glucose_serum', 'lactate', 'hemoglobin' ]\n",
    "\n",
    "# Continuous administered meds\n",
    "meds_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'admin_dttm',\n",
    "    'med_name',\n",
    "    'med_category',\n",
    "    'med_dose',\n",
    "    'med_dose_unit'\n",
    "]\n",
    "meds_of_interest = [\n",
    "    'norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin',\n",
    "    'dopamine', 'angiotensin', 'dobutamine', 'milrinone', 'isoproterenol',\n",
    "    'propofol', 'midazolam', 'lorazepam', 'dexmedetomidine', \n",
    "    'vecuronium', 'rocuronium', 'cisatracurium', 'pancuronium'\n",
    "]\n",
    "\n",
    "# Respiratory Support \n",
    "rst_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'device_name',\n",
    "    'device_category',\n",
    "    'mode_name', \n",
    "    'mode_category',\n",
    "    'tracheostomy',\n",
    "    'fio2_set',\n",
    "    'lpm_set',\n",
    "    'resp_rate_set',\n",
    "    'peep_set',\n",
    "    'resp_rate_obs',\n",
    "    'tidal_volume_set', \n",
    "    'pressure_control_set',\n",
    "    'pressure_support_set',\n",
    "    'peak_inspiratory_pressure_set',\n",
    "    'peak_inspiratory_pressure_obs',\n",
    "    'plateau_pressure_obs',\n",
    "    'minute_vent_obs'\n",
    "]\n",
    "\n",
    "# Full crrt table\n",
    "crrt_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'crrt_mode_category',\n",
    "    'blood_flow_rate',\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'dialysate_flow_rate',\n",
    "    'ultrafiltration_out'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dc995a",
   "metadata": {},
   "source": [
    "# Cohort Identification\n",
    "\n",
    "\n",
    "**Inclusion**\n",
    "1. Adults\n",
    "2. Admitted between January 1, 2018 to December, 31, 2024\n",
    "3. Receiving CRRT- must have DFR or UF documented at any point in the hospitalization\n",
    "4. Data completeness- Must have weight & CRRT settings  documented\n",
    "\n",
    "**Exclusion**\n",
    "1. Prior to admission ICD codes for ESRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7504810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155f53b",
   "metadata": {},
   "source": [
    "## Step0: Load Core Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38583e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Loading CLIF Tables\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from clifpy.clif_orchestrator import ClifOrchestrator\n",
    "\n",
    "# Initialize ClifOrchestrator\n",
    "clif = ClifOrchestrator(\n",
    "    data_directory=config['tables_path'],\n",
    "    filetype=config['file_type'],\n",
    "    timezone=config['timezone']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81062564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 0: Load Core Tables (Patient, Hospitalization, ADT)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 0: Load Core Tables (Patient, Hospitalization, ADT)\")\n",
    "print(\"=\" * 80)\n",
    "core_tables = ['patient', 'hospitalization', 'adt']\n",
    "\n",
    "print(f\"\\nLoading {len(core_tables)} core tables...\")\n",
    "for table_name in core_tables:\n",
    "    print(f\"   Loading {table_name}...\", end=\" \")\n",
    "    try:\n",
    "        clif.load_table(table_name)\n",
    "        table = getattr(clif, table_name)\n",
    "        print(f\"✓ ({len(table.df):,} rows)\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error: {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"\\nCore tables loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a9c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "hosp_df = clif.hospitalization.df\n",
    "adt_df = clif.adt.df\n",
    "\n",
    "# Merge to get age information\n",
    "all_encounters = pd.merge(\n",
    "    hosp_df[[\"patient_id\", \"hospitalization_id\", \"admission_dttm\", \"discharge_dttm\", \n",
    "             \"age_at_admission\", \"discharge_category\"]],\n",
    "    adt_df[[\"hospitalization_id\", \"hospital_id\", \"in_dttm\", \"out_dttm\", \n",
    "            \"location_category\", \"location_type\"]],\n",
    "    on='hospitalization_id',\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2c4bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates by ['hospitalization_id', 'in_dttm', 'out_dttm']\n",
    "dup_counts = all_encounters.duplicated(subset=['hospitalization_id', 'in_dttm', 'out_dttm']).sum()\n",
    "if dup_counts > 0:\n",
    "    print(f\"Warning: {dup_counts} duplicate (hospitalization_id, in_dttm, out_dttm) entries found in all_encounters.\")\n",
    "else:\n",
    "    print(\"No duplicate (hospitalization_id, in_dttm, out_dttm) entries found in all_encounters.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a74bac",
   "metadata": {},
   "source": [
    "## Step1: Date & Age filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7186fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# STEP 1: Identify Adult Patients (Age >= 18) and Admissions 2018-2024\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Step 1: Identifying Adult Patients (Age >= 18) and Admissions 2018-2024\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"Applying initial cohort filters...\")\n",
    "\n",
    "# Use only the relevant columns from all_encounters\n",
    "adult_encounters = all_encounters[\n",
    "    [\n",
    "        'patient_id', 'hospitalization_id', 'admission_dttm', 'discharge_dttm',\n",
    "        'age_at_admission', 'discharge_category', 'hospital_id',\n",
    "        'in_dttm', 'out_dttm', 'location_category', 'location_type'\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Filter for adult patients (age >= 18) and valid age\n",
    "adult_encounters = adult_encounters[\n",
    "    (adult_encounters['age_at_admission'] >= 18) & (adult_encounters['age_at_admission'].notna())\n",
    "]\n",
    "\n",
    "# Filter for admission years 2018-2024\n",
    "adult_encounters = adult_encounters[\n",
    "    (adult_encounters['admission_dttm'].dt.year >= 2018) & (adult_encounters['admission_dttm'].dt.year <= 2024)\n",
    "]\n",
    "\n",
    "print(f\"\\nFiltering Results:\")\n",
    "print(f\"   Total hospitalizations: {len(all_encounters['hospitalization_id'].unique()):,}\")\n",
    "print(f\"   Adult hospitalizations (age >= 18, 2018-2024): {len(adult_encounters['hospitalization_id'].unique()):,}\")\n",
    "print(f\"   Excluded (age < 18 or outside 2018-2024): {len(all_encounters['hospitalization_id'].unique()) - len(adult_encounters['hospitalization_id'].unique()):,}\")\n",
    "\n",
    "\n",
    "strobe_counts[\"0_total_hospitalizations\"] = len(all_encounters['hospitalization_id'].unique())\n",
    "strobe_counts[\"1_adult_hospitalizations\"] = len(adult_encounters['hospitalization_id'].unique())\n",
    "# Get list of adult hospitalization IDs for filtering\n",
    "adult_hosp_ids = set(adult_encounters['hospitalization_id'].unique())\n",
    "print(f\"\\n   Unique adult hospitalization IDs: {len(adult_hosp_ids):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a76e43d",
   "metadata": {},
   "source": [
    "## Step1B: Stitch hospitalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702bb752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clifpy.utils.stitching_encounters import stitch_encounters\n",
    "\n",
    "# Instead of multiple copies, work with references and clean up\n",
    "hosp_filtered = clif.hospitalization.df[clif.hospitalization.df['hospitalization_id'].isin(adult_hosp_ids)]\n",
    "adt_filtered = clif.adt.df[clif.adt.df['hospitalization_id'].isin(adult_hosp_ids)]\n",
    "\n",
    "hosp_stitched, adt_stitched, encounter_mapping = stitch_encounters(\n",
    "    hospitalization=hosp_filtered,\n",
    "    adt=adt_filtered,\n",
    "    time_interval=6  \n",
    ")\n",
    "\n",
    "# Direct assignment without additional copies\n",
    "clif.hospitalization.df = hosp_stitched\n",
    "clif.adt.df = adt_stitched\n",
    "\n",
    "# Store the encounter mapping in the orchestrator for later use\n",
    "clif.encounter_mapping = encounter_mapping\n",
    "\n",
    "# Clean up intermediate variables\n",
    "del hosp_filtered, adt_filtered\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f522545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After your stitching code, add these calculations:\n",
    "\n",
    "# Calculate stitching statistics\n",
    "strobe_counts['1b_before_stitching'] = len(adult_hosp_ids)  # Original adult hospitalizations\n",
    "strobe_counts['1b_after_stitching'] = len(hosp_stitched['encounter_block'].unique())  # Unique encounter blocks after stitching\n",
    "strobe_counts['1b_stitched_hosp_ids'] = strobe_counts['1b_before_stitching'] - strobe_counts['1b_after_stitching']  # Number of hospitalizations that were linked\n",
    "\n",
    "print(f\"\\nEncounter Stitching Results:\")\n",
    "print(f\"   Number of unique hospitalizations before stitching: {strobe_counts['1b_before_stitching']:,}\")\n",
    "print(f\"   Number of unique encounter blocks after stitching: {strobe_counts['1b_after_stitching']:,}\")\n",
    "print(f\"   Number of linked hospitalization ids: {strobe_counts['1b_stitched_hosp_ids']:,}\")\n",
    "\n",
    "# Optional: Show the encounter mapping details\n",
    "print(f\"\\nEncounter Mapping Details:\")\n",
    "print(f\"   Total encounter mappings created: {len(encounter_mapping):,}\")\n",
    "if len(encounter_mapping) > 0:\n",
    "    # Show some examples of how many original hospitalizations were combined\n",
    "    mapping_counts = encounter_mapping.groupby('encounter_block').size()\n",
    "    print(f\"   Encounter blocks with multiple hospitalizations: {(mapping_counts > 1).sum():,}\")\n",
    "    print(f\"   Maximum hospitalizations combined into one block: {mapping_counts.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b61028",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df = encounter_mapping.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a8ef2e",
   "metadata": {},
   "source": [
    "## Step2: Identify CRRT Encounters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLoading crrt_therapy table...\")\n",
    "try:\n",
    "    clif.load_table(\n",
    "        'crrt_therapy',\n",
    "        filters={'hospitalization_id': list(adult_hosp_ids)}\n",
    "    )\n",
    "    print(f\"   CRRT therapy loaded: {len(clif.crrt_therapy.df):,} rows\")\n",
    "    print(f\"   Unique CRRT therapy hospitalizations: {clif.crrt_therapy.df['hospitalization_id'].nunique()}\")\n",
    "except Exception as e:\n",
    "    print(f\"   CRRT therapy not available or error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbc09c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update CRRT therapy DataFrame with encounter blocks\n",
    "clif.crrt_therapy.df = clif.crrt_therapy.df.merge(\n",
    "    clif.encounter_mapping[['hospitalization_id', 'encounter_block']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "n_crrt_hosp = clif.crrt_therapy.df['hospitalization_id'].nunique()\n",
    "n_crrt_blocks = clif.crrt_therapy.df['encounter_block'].nunique()\n",
    "crrt_hosp_ids = set(clif.crrt_therapy.df['hospitalization_id'].unique())\n",
    "\n",
    "print(f\"Updated CRRT therapy DataFrame:\")\n",
    "print(f\"   Total CRRT records: {len(clif.crrt_therapy.df):,}\")\n",
    "print(f\"   Records with encounter blocks: {clif.crrt_therapy.df['encounter_block'].notna().sum():,}\")\n",
    "print(f\"   Unique encounter blocks in CRRT data: {n_crrt_blocks}\")\n",
    "print(f\"   Unique hospitalizations  in CRRT data: {n_crrt_hosp}\")\n",
    "\n",
    "strobe_counts[\"2_crrt_hospitalizations\"] = n_crrt_hosp\n",
    "strobe_counts[\"2_crrt_blocks\"] = n_crrt_blocks\n",
    "\n",
    "# Filter cohort_df to only hospitalizations present in CRRT data\n",
    "cohort_df = cohort_df[cohort_df['hospitalization_id'].isin(crrt_hosp_ids)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2cad0",
   "metadata": {},
   "source": [
    "## Step3: Exclude ESRD encounters\n",
    "\n",
    "Prior to admission ICD codes for ESRD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d592396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLoading Hospital dx table...\")\n",
    "try:\n",
    "    clif.load_table(\n",
    "        'hospital_diagnosis',\n",
    "        filters={'hospitalization_id': list(crrt_hosp_ids)}\n",
    "    )\n",
    "    print(f\"   Hospital dx loaded: {len(clif.hospital_diagnosis.df):,} rows\")\n",
    "    print(f\"   Unique Hospital dx hospitalizations: {clif.hospital_diagnosis.df['hospitalization_id'].nunique()}\")\n",
    "\n",
    "    print(\"Merge encounter blocks with diagnosis\")\n",
    "    clif.hospital_diagnosis.df = clif.hospital_diagnosis.df.merge(\n",
    "                    clif.encounter_mapping[['hospitalization_id', 'encounter_block']],\n",
    "                    on='hospitalization_id',\n",
    "                    how='left')\n",
    "\n",
    "    n_dx_hosp = clif.hospital_diagnosis.df['hospitalization_id'].nunique()\n",
    "    n_dx_blocks = clif.hospital_diagnosis.df['encounter_block'].nunique()\n",
    "    cohort_hosp_ids = set(clif.hospital_diagnosis.df['hospitalization_id'].unique())\n",
    "    cohort_blocks = set(clif.hospital_diagnosis.df['encounter_block'].unique())\n",
    "    print(f\"   Total Hospital dx records: {len(clif.hospital_diagnosis.df):,}\")\n",
    "    print(f\"   Records with encounter blocks: {clif.hospital_diagnosis.df['encounter_block'].notna().sum():,}\")\n",
    "    print(f\"   Unique encounter blocks in Hospital dx data: {n_dx_blocks}\")\n",
    "    print(f\"   Unique hospitalizations  in Hospital dx data: {n_dx_hosp}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Hospital dx not available or error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c985b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "hospital_diagnosis_df = clif.hospital_diagnosis.df.copy()\n",
    "\n",
    "print(\"Hospital dx column names :\", hospital_diagnosis_df.columns)\n",
    "# Clean and standardize diagnosis codes\n",
    "hospital_diagnosis_df['diagnosis_code'] = hospital_diagnosis_df['diagnosis_code'].str.replace('.', '').str.lower()\n",
    "\n",
    "if 'present_on_admission' in hospital_diagnosis_df.columns:\n",
    "    hospital_diagnosis_df = hospital_diagnosis_df.rename(columns={'present_on_admission': 'poa_present'})\n",
    "\n",
    "# Check present_on_admission column type and standardize to int8\n",
    "if 'poa_present' in hospital_diagnosis_df.columns:\n",
    "    # Only allow 1 (present on admission) or 0 (not present on admission)\n",
    "    # Any other value (including Exempt, Unknown, Unspecified, NA) is set to 0\n",
    "    hospital_diagnosis_df['poa_present'] = hospital_diagnosis_df['poa_present'].astype(str).str.lower()\n",
    "    hospital_diagnosis_df['poa_present'] = hospital_diagnosis_df['poa_present'].map(\n",
    "        {'yes': 1, 'y': 1, 'true': 1, '1': 1, 'no': 0, 'n': 0, 'false': 0, '0': 0}\n",
    "    ).fillna(0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e2bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ESRD diagnosis codes\n",
    "# Let's debug why we're not finding ESRD codes\n",
    "esrd_codes = [\n",
    "    'z992',    # Dependence on renal dialysis\n",
    "    'z9115',   # Patient's noncompliance with renal dialysis\n",
    "    'i120',    # Hypertensive chronic kidney disease with stage 5 CKD or ESRD\n",
    "    'n186',    # End stage renal disease\n",
    "    'i132',    # Hypertensive heart and chronic kidney disease with heart failure and ESRD\n",
    "    'z992',    # Dependence on renal dialysis (alternate code)\n",
    "    'i120',    # Hypertensive chronic kidney disease with stage 5 CKD or ESRD (alternate code)\n",
    "    'z91158',  # Patient's noncompliance with renal dialysis (alternate code)\n",
    "    'i1311',   # Hypertensive heart and chronic kidney disease with heart failure and stage 5 CKD\n",
    "    'i132',    # Hypertensive heart and chronic kidney disease with ESRD (alternate code)\n",
    "    '5856',     #ICD9 :End stage renal disease\n",
    "    '40391',    #ICD9: Hypertensive chronic kidney disease, unspecified, with chronic kidney disease stage V or end stage renal disease\n",
    "    '40311',     #ICD9: Hypertensive chronic kidney disease, benign, with chronic kidney disease stage V or end stage renal disease\n",
    "    'v4511',     #ICD9: Renal dialysis status\n",
    "    'v4512'     #ICD9: Noncompliance with renal dialysis\n",
    "]\n",
    "\n",
    "# Get hospitalization IDs with ESRD diagnoses and print debug info\n",
    "print(\"\\nNumber of rows matching ESRD codes:\", hospital_diagnosis_df['diagnosis_code'].isin(esrd_codes).sum())\n",
    "\n",
    "\n",
    "# Count how many ESRD codes have present_on_admission = 1, 0, or NA\n",
    "esrd_poa_counts = hospital_diagnosis_df[\n",
    "    hospital_diagnosis_df['diagnosis_code'].isin(esrd_codes)\n",
    "]['poa_present'].value_counts(dropna=False)\n",
    "print(\"Present_on_admission values for ESRD codes:\")\n",
    "print(esrd_poa_counts)\n",
    "\n",
    "# Use a more inclusive approach for ESRD identification\n",
    "# Include cases where present_on_admission is 1 OR NA (assuming NA means unknown/possible)\n",
    "esrd_mask = (\n",
    "    hospital_diagnosis_df['diagnosis_code'].isin(esrd_codes) & \n",
    "    ((hospital_diagnosis_df['poa_present'] == 1) | \n",
    "        (hospital_diagnosis_df['poa_present'].isna()))\n",
    ")\n",
    "hosp_ids_with_esrd = hospital_diagnosis_df[esrd_mask]['hospitalization_id'].unique()\n",
    "blocks_with_esrd = hospital_diagnosis_df[esrd_mask]['encounter_block'].unique()\n",
    "\n",
    "print(f\"Hospitalizations with ESRD (including NA present_on_admission): {len(hosp_ids_with_esrd)}\")\n",
    "\n",
    "\n",
    "strobe_counts['3_hospitalizations_with_esrd'] = len(hosp_ids_with_esrd)\n",
    "strobe_counts['3_encounter_blocks_with_esrd'] = len(blocks_with_esrd)\n",
    "\n",
    "\n",
    "# Filter out hospitalizations with ESRD\n",
    "cohort_df = cohort_df[~cohort_df['hospitalization_id'].isin(hosp_ids_with_esrd)].copy()\n",
    "cohort_hosp_ids = set(cohort_df['hospitalization_id'].unique())\n",
    "cohort_blocks = set(cohort_df['encounter_block'].unique())\n",
    "# Create cohort subset excluding hospitalizations with ESRD\n",
    "strobe_counts['3_encounter_blocks_without_esrd'] = len(cohort_blocks)  # Count blocks without ESRD\n",
    "strobe_counts['3_hospitalizations_without_esrd'] = len(cohort_hosp_ids)  # Count hospitalizations without ESRD\n",
    "\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42aec46e",
   "metadata": {},
   "source": [
    "## Step4: Data availability, and CRRT Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643037bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nLoading labs table...\")\n",
    "clif.load_table(\n",
    "    'vitals',\n",
    "    columns=vitals_required_columns,\n",
    "    filters={\n",
    "        'hospitalization_id': list(cohort_hosp_ids)\n",
    "    }\n",
    ")\n",
    "print(f\"   Vitals loaded: {len(clif.vitals.df):,} rows\")\n",
    "print(f\"   Unique vitals categories: {clif.vitals.df['vital_category'].nunique()}\")\n",
    "print(f\"   Unique vitals hospitalizations: {clif.vitals.df['hospitalization_id'].nunique()}\")\n",
    "\n",
    "clif.vitals.df = clif.vitals.df.merge(\n",
    "    clif.encounter_mapping[['hospitalization_id', 'encounter_block']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39738ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitals_range = clif.vitals.df.groupby('encounter_block').agg({\n",
    "    'recorded_dttm': ['min', 'max']\n",
    "}).reset_index()\n",
    "vitals_range.columns = ['encounter_block', 'first_vital_dttm', 'last_vital_dttm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd93f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only rows where vital_category is 'weight_kg'\n",
    "weight_df = clif.vitals.df[clif.vitals.df['vital_category'] == 'weight_kg'].copy()\n",
    "# Identify the number of hospitalizations that do not have weight recorded\n",
    "hosp_with_weight = set(weight_df['hospitalization_id'].unique())\n",
    "hosp_without_weight = cohort_hosp_ids - hosp_with_weight\n",
    "print(f\"Number of hospitalizations without recorded weight: {len(hosp_without_weight)}\")\n",
    "\n",
    "clif.vitals.df = None ## clear from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6118388",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df = cohort_df[~cohort_df['hospitalization_id'].isin(hosp_without_weight)].copy()\n",
    "cohort_hosp_ids = set(cohort_df['hospitalization_id'].unique())\n",
    "cohort_blocks = set(cohort_df['encounter_block'].unique())\n",
    "strobe_counts['4_encounter_blocks_with_weight'] = len(cohort_blocks)  # Count blocks without weight\n",
    "strobe_counts['4_hospitalizations_with_weight'] = len(cohort_hosp_ids)  # Count hospitalizations without weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f4a477",
   "metadata": {},
   "outputs": [],
   "source": [
    "crrt_df = clif.crrt_therapy.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e1d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the number of encounters who do not have any CRRT settings documented: \n",
    "# pre_filter_replacement_fluid_rate, post_filter_replacement_fluid_rate, dialysate_flow_rate, ultrafiltration_out\n",
    "# Filter crrt_df to only include hospitalization_id present in cohort_df\n",
    "crrt_df = crrt_df[crrt_df['hospitalization_id'].isin(cohort_df['hospitalization_id'])]\n",
    "\n",
    "crrt_settings_cols = [\n",
    "    'pre_filter_replacement_fluid_rate',\n",
    "    'post_filter_replacement_fluid_rate',\n",
    "    'dialysate_flow_rate',\n",
    "    'ultrafiltration_out'\n",
    "]\n",
    "# Find encounter_blocks with ANY crrt settings recorded\n",
    "crrt_settings_present = crrt_df.groupby('encounter_block')[crrt_settings_cols].apply(\n",
    "    lambda df: df.notnull().any().any()\n",
    ")\n",
    "crrt_blocks_with_settings = set(crrt_settings_present[crrt_settings_present].index)\n",
    "crrt_blocks_without_settings = set(crrt_df['encounter_block'].unique()) - crrt_blocks_with_settings\n",
    "num_encounters_without_crrt_settings = len(crrt_blocks_without_settings)\n",
    "print(f\"Number of encounter blocks without any recorded CRRT settings: {num_encounters_without_crrt_settings}\")\n",
    "\n",
    "# Filter cohort_df to only include encounter_blocks with at least one CRRT setting recorded\n",
    "cohort_df = cohort_df[cohort_df['encounter_block'].isin(crrt_blocks_with_settings)].copy()\n",
    "cohort_hosp_ids = set(cohort_df['hospitalization_id'].unique())\n",
    "cohort_blocks = set(cohort_df['encounter_block'].unique())\n",
    "strobe_counts['5_encounter_blocks_with_crrt_settings'] = len(cohort_blocks)\n",
    "strobe_counts['5_hospitalizations_with_crrt_settings'] = len(cohort_hosp_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c5778d",
   "metadata": {},
   "source": [
    "## Cohort Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5097c941",
   "metadata": {},
   "source": [
    "## AKI\n",
    "\n",
    "Majority of the cohort should have an ICD code for AKI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c06241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AKI Codes Sanity check\n",
    "\n",
    "# Define AKI ICD-10 codes\n",
    "aki_codes = [\n",
    "    # ICD-10 codes for acute kidney injury\n",
    "    'n170', 'n171', 'n172', 'n178', 'n179',  # Acute kidney failure codes\n",
    "    'r34',   # Anuria and oliguria\n",
    "    'n990', # Post-procedural kidney failure\n",
    "    't795',  # Traumatic anuria\n",
    "    '5845',  # ICD9 Acute kidney failure with lesion of tubular necrosis\n",
    "    '5849',  # ICD9- Acute kidney failure, unspecified\n",
    "    \"5848\"    # ICD9 - Acute kidney failure with other specified pathological lesion in kidney\n",
    "]\n",
    "\n",
    "# Filter to non-ESRD encounters first\n",
    "non_esrd_encounters = hospital_diagnosis_df[hospital_diagnosis_df['encounter_block'].isin(cohort_df['encounter_block'])]\n",
    "\n",
    "# Create mask for AKI diagnoses on the filtered data\n",
    "aki_mask = non_esrd_encounters['diagnosis_code'].isin(aki_codes)\n",
    "\n",
    "# Get encounter blocks with AKI diagnoses\n",
    "blocks_with_aki = non_esrd_encounters[aki_mask]['encounter_block'].unique()\n",
    "total_non_esrd_blocks = cohort_df['encounter_block'].nunique()\n",
    "strobe_counts['6_encounter_blocks_with_AKI_no_esrd'] = len(blocks_with_aki) \n",
    "\n",
    "# Calculate percentage\n",
    "aki_percentage = (len(blocks_with_aki) / total_non_esrd_blocks) * 100\n",
    "\n",
    "print(f\"\\nPercentage of non-ESRD encounter blocks with AKI codes: {aki_percentage:.1f}%\")\n",
    "print(f\"({len(blocks_with_aki)} out of {total_non_esrd_blocks} blocks)\")\n",
    "strobe_counts['6_Percentage_non_ESRD_encounter_blocks_with_AKI_codes'] = aki_percentage\n",
    "# Show sample of AKI diagnoses\n",
    "aki_diagnoses = non_esrd_encounters[aki_mask][['hospitalization_id', 'diagnosis_code','poa_present']].drop_duplicates()\n",
    "print(\"\\nSample of AKI-related diagnoses found: \")\n",
    "aki_diagnoses['diagnosis_code'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6af78",
   "metadata": {},
   "source": [
    "## ICU\n",
    "\n",
    "Cohort should ideally be an ICU hospitalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737bcea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter ADT data to only include hospitalizations in all_ids\n",
    "adt_final_stitched = adt_stitched[adt_stitched['hospitalization_id'].isin(cohort_df['hospitalization_id'])].copy()\n",
    "adt_final_stitched = adt_final_stitched.sort_values(by=['encounter_block', 'in_dttm'])\n",
    "desired_order = ['hospitalization_id', 'encounter_block', 'hospital_id', 'in_dttm', 'out_dttm']\n",
    "remaining_cols = [col for col in adt_final_stitched.columns if col not in desired_order]\n",
    "adt_final_stitched = adt_final_stitched[desired_order + remaining_cols]\n",
    "\n",
    "print(\"\\n=== Validating ICU Administration ===\")\n",
    "\n",
    "adt_final_stitched['is_icu'] = adt_final_stitched['location_category'] == 'icu'\n",
    "\n",
    "# Check if each hospitalization had at least one ICU stay\n",
    "hosp_icu_status = adt_final_stitched.groupby('encounter_block')['is_icu'].any()\n",
    "non_icu_hosps = hosp_icu_status[~hosp_icu_status].index.tolist()\n",
    "strobe_counts[\"6_number_hosp_without_ICU_stay\"] = len(non_icu_hosps)\n",
    "print(f\"\\nNumber of CRRT hospitalizations without any ICU stay: {len(non_icu_hosps)}\")\n",
    "if len(non_icu_hosps) > 0:\n",
    "    print(\"WARNING: Found CRRT hospitalizations without ICU stays\")\n",
    "    print(\"Number of hospitalization IDs without ICU stays:\", len(non_icu_hosps), \"check crrt_non_icu_df df\")\n",
    "else:\n",
    "    print(\"All CRRT hospitalizations had at least one ICU stay\")\n",
    "\n",
    "crrt_non_icu_df = crrt_df[crrt_df['encounter_block'].isin(non_icu_hosps)]\n",
    "crrt_non_icu_df = crrt_non_icu_df.sort_values(by=['hospitalization_id', 'encounter_block', 'recorded_dttm'])\n",
    "desired_order = ['hospitalization_id', 'encounter_block', 'recorded_dttm', 'crrt_mode_category']\n",
    "remaining_cols = [col for col in crrt_non_icu_df.columns if col not in desired_order]\n",
    "crrt_non_icu_df = crrt_non_icu_df[desired_order + remaining_cols]\n",
    "adt_df_non_icu_hosps = adt_stitched[adt_stitched['encounter_block'].isin(non_icu_hosps)]\n",
    "adt_df_non_icu_hosps.to_csv('../output/intermediate/adt_df_non_icu_hosps.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc004349",
   "metadata": {},
   "source": [
    "# Strobe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93f6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display strobe counts\n",
    "display(strobe_counts)\n",
    "\n",
    "# Save strobe counts to CSV in ../output/intermediate\n",
    "strobe_counts_df = pd.DataFrame(list(strobe_counts.items()), columns=['counter', 'value'])\n",
    "strobe_counts_df.to_csv('../output/final/strobe_counts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de0b66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import utils\n",
    "importlib.reload(utils)\n",
    "from utils import create_consort_diagram\n",
    "\n",
    "# Generate CONSORT diagram - percentages calculated automatically\n",
    "create_consort_diagram(strobe_counts=strobe_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d73b6f9",
   "metadata": {},
   "source": [
    "# Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1481a4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# OUTCOMES CALCULATION \n",
    "# ============================================================================\n",
    "\n",
    "# 1. ICU LENGTH OF STAY \n",
    "print(\"\\n1. Processing ICU segments...\")\n",
    "icu_segs = adt_final_stitched.copy()\n",
    "icu_segs = icu_segs[\n",
    "    (icu_segs['location_category'] == 'icu') &\n",
    "    (icu_segs['in_dttm'].notna()) &\n",
    "    (icu_segs['out_dttm'].notna()) &\n",
    "    (icu_segs['out_dttm'] > icu_segs['in_dttm'])\n",
    "]\n",
    "\n",
    "print(f\"   ICU segments identified: {len(icu_segs):,}\")\n",
    "\n",
    "# Calculate ICU LOS as sum of all ICU segment durations\n",
    "icu_los = icu_segs[icu_segs['encounter_block'].isin(cohort_df['encounter_block'])].copy()\n",
    "icu_los['seg_days'] = (icu_los['out_dttm'] - icu_los['in_dttm']).dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "icu_los_summary = icu_los.groupby('encounter_block').agg({\n",
    "    'seg_days': 'sum'\n",
    "}).reset_index()\n",
    "icu_los_summary.rename(columns={'seg_days': 'icu_los_days'}, inplace=True)\n",
    "\n",
    "print(f\"   Median ICU LOS: {icu_los_summary['icu_los_days'].median():.2f} days\")\n",
    "\n",
    "# ============================================================================\n",
    "# 2. HOSPITAL LENGTH OF STAY (difference between first and last vital)\n",
    "# ============================================================================\n",
    "print(\"\\n3. Calculating Hospital Length of Stay...\")\n",
    "hosp_los = cohort_df[['encounter_block']].merge(\n",
    "    vitals_range,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Hospital LOS = last_vital_dttm - first_vital_dttm\n",
    "hosp_los['hosp_los_days'] = (\n",
    "    hosp_los['last_vital_dttm'] - hosp_los['first_vital_dttm']\n",
    ").dt.total_seconds() / (24 * 3600)\n",
    "\n",
    "# Ensure non-negative values\n",
    "hosp_los['hosp_los_days'] = hosp_los['hosp_los_days'].apply(\n",
    "    lambda x: max(x, 0) if pd.notna(x) and np.isfinite(x) else np.nan\n",
    ")\n",
    "\n",
    "print(f\"   Median Hospital LOS: {hosp_los['hosp_los_days'].median():.2f} days\")\n",
    "\n",
    "# ============================================================================\n",
    "# 4. DEATH STATUS AND FINAL OUTCOME DATETIME\n",
    "# ============================================================================\n",
    "print(\"\\n4. Determining death status and final outcome datetime...\")\n",
    "\n",
    "# Get discharge category and death_dttm from hospitalization and patient tables\n",
    "patient_df = clif.patient.df[['patient_id', 'death_dttm', 'race_category', 'sex_category', 'ethnicity_category']]\n",
    "\n",
    "death_info = cohort_df.merge(\n",
    "    hosp_df[['hospitalization_id', 'patient_id', 'discharge_category', 'age_at_admission', 'admission_type_category']],\n",
    "    on='hospitalization_id',\n",
    "    how='left'\n",
    ").merge(\n",
    "    patient_df,\n",
    "    on='patient_id',\n",
    "    how='left'\n",
    ").merge(\n",
    "    vitals_range,\n",
    "    on='encounter_block',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Drop 'hospitalization_id' from death_info\n",
    "if 'hospitalization_id' in death_info.columns:\n",
    "    death_info = death_info.drop(columns=['hospitalization_id'])\n",
    "\n",
    "# Collapse to unique encounter_block, aggregating required columns\n",
    "death_info = death_info.sort_values('encounter_block')  \n",
    "\n",
    "agg_dict = {\n",
    "    'admission_type_category': 'last',\n",
    "    'discharge_category': 'last',\n",
    "    'race_category': 'last',\n",
    "    'sex_category': 'last',\n",
    "    'ethnicity_category': 'last',\n",
    "    'death_dttm': 'last',\n",
    "    'first_vital_dttm': 'min',\n",
    "    'last_vital_dttm': 'max'\n",
    "}\n",
    "\n",
    "# Include all other columns not being aggregated with \"first\" to keep at least one value per group, unless they are non-aggregatable\n",
    "for col in death_info.columns:\n",
    "    if col not in agg_dict and col not in ['encounter_block']:\n",
    "        agg_dict[col] = 'first'\n",
    "\n",
    "death_info = death_info.groupby('encounter_block', as_index=False).agg(agg_dict)\n",
    "\n",
    "# Standardize discharge category\n",
    "death_info['discharge_category'] = death_info['discharge_category'].str.lower()\n",
    "\n",
    "# Step 1: Determine if patient died (based on discharge_category)\n",
    "death_info['died'] = death_info['discharge_category'].isin(['expired', 'hospice']).astype(int)\n",
    "\n",
    "# Step 2: Determine final_outcome_dttm\n",
    "# If died: use death_dttm if available, otherwise use last_vital_dttm\n",
    "# If not died: use last_vital_dttm\n",
    "death_info['final_outcome_dttm'] = (\n",
    "    death_info['death_dttm']\n",
    "    .fillna(death_info['last_vital_dttm'])  # Fallback to last_vital\n",
    "    .where(death_info['died'] == 1, pd.NaT)  # Only keep for died==1, else NaT\n",
    ")\n",
    "\n",
    "print(f\"   Patients identified as died (expired/hospice): {death_info['died'].sum():,}\")\n",
    "\n",
    "num_with_death_dttm = ((death_info['died'] == 1) & (death_info['death_dttm'].notna())).sum()\n",
    "num_using_last_vital = ((death_info['died'] == 1) & (death_info['death_dttm'].isna())).sum()\n",
    "\n",
    "print(f\"   - With death_dttm: {num_with_death_dttm:,}\")\n",
    "print(f\"   - Using last_vital_dttm: {num_using_last_vital:,}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 5. MORTALITY CALCULATIONS\n",
    "# ============================================================================\n",
    "print(\"\\n5. Calculating mortality outcomes...\")\n",
    "\n",
    "# In-hospital death: died AND final_outcome_dttm is between first and last vital\n",
    "death_info['in_hosp_death'] = (\n",
    "    (death_info['died'] == 1) &\n",
    "    (death_info['final_outcome_dttm'].notna()) &\n",
    "    (death_info['final_outcome_dttm'] >= death_info['first_vital_dttm']) &\n",
    "    (death_info['final_outcome_dttm'] <= death_info['last_vital_dttm'])\n",
    ").astype(int)\n",
    "\n",
    "# 30-day mortality: died AND final_outcome_dttm within 30 days of first vital\n",
    "death_info['death_30d'] = (\n",
    "    (death_info['died'] == 1) &\n",
    "    (death_info['final_outcome_dttm'].notna()) &\n",
    "    (death_info['final_outcome_dttm'] <= (death_info['first_vital_dttm'] + pd.Timedelta(days=30)))\n",
    ").astype(int)\n",
    "\n",
    "\n",
    "print(f\"   In-hospital deaths: {death_info['in_hosp_death'].sum():,} ({death_info['in_hosp_death'].mean()*100:.1f}%)\")\n",
    "print(f\"   30-day deaths: {death_info['death_30d'].sum():,} ({death_info['death_30d'].mean()*100:.1f}%)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 6. COMBINE ALL OUTCOMES\n",
    "# ============================================================================\n",
    "print(\"\\n6. Combining all outcomes...\")\n",
    "outcomes_df = cohort_df[['hospitalization_id', 'encounter_block']].merge(\n",
    "    icu_los_summary, on='encounter_block', how='left'\n",
    ").merge(\n",
    "    hosp_los[['encounter_block', 'hosp_los_days']], on='encounter_block', how='left'\n",
    ").merge(\n",
    "    death_info, on='encounter_block', how='left'\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal outcomes dataset:\")\n",
    "print(f\"   Total records: {len(outcomes_df):,}\")\n",
    "print(f\"   Records with ICU LOS: {outcomes_df['icu_los_days'].notna().sum():,}\")\n",
    "print(f\"   Records with Hospital LOS: {outcomes_df['hosp_los_days'].notna().sum():,}\")\n",
    "print(f\"   In-hospital mortality rate: {outcomes_df['in_hosp_death'].mean()*100:.1f}%\")\n",
    "print(f\"   30-day mortality rate: {outcomes_df['death_30d'].mean()*100:.1f}%\")\n",
    "\n",
    "# Display summary statistics\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OUTCOMES SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ICU LOS (days):\")\n",
    "print(f\"  Median [IQR]: {outcomes_df['icu_los_days'].median():.1f} [{outcomes_df['icu_los_days'].quantile(0.25):.1f}-{outcomes_df['icu_los_days'].quantile(0.75):.1f}]\")\n",
    "print(f\"\\nHospital LOS (days):\")\n",
    "print(f\"  Median [IQR]: {outcomes_df['hosp_los_days'].median():.1f} [{outcomes_df['hosp_los_days'].quantile(0.25):.1f}-{outcomes_df['hosp_los_days'].quantile(0.75):.1f}]\")\n",
    "print(f\"\\nMortality:\")\n",
    "print(f\"  In-hospital: {outcomes_df['in_hosp_death'].sum():,}/{len(outcomes_df):,} ({outcomes_df['in_hosp_death'].mean()*100:.1f}%)\")\n",
    "print(f\"  30-day: {outcomes_df['death_30d'].sum():,}/{len(outcomes_df):,} ({outcomes_df['death_30d'].mean()*100:.1f}%)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Convert specified columns to lowercase (if they exist)\n",
    "category_cols = [\n",
    "    'admission_type_category', 'discharge_category',\n",
    "    'race_category', 'sex_category', 'ethnicity_category'\n",
    "]\n",
    "for col in category_cols:\n",
    "    if col in outcomes_df.columns:\n",
    "        outcomes_df[col] = outcomes_df[col].str.lower()\n",
    "\n",
    "# Arrange columns: patient_id, hospitalization_id, encounter_block, then everything else\n",
    "front_cols = [col for col in ['patient_id', 'hospitalization_id', 'encounter_block'] if col in outcomes_df.columns]\n",
    "other_cols = [col for col in outcomes_df.columns if col not in front_cols]\n",
    "outcomes_df = outcomes_df[front_cols + other_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3958f23d",
   "metadata": {},
   "source": [
    "# Save Intermediate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21f18d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_df.to_parquet(\"../output/intermediate/cohort_df.parquet\", index=False)\n",
    "outcomes_df.to_parquet(\"../output/intermediate/outcomes_df.parquet\", index=False)\n",
    "# Filter weight_df to hospitalization_ids present in cohort_df before saving\n",
    "weight_df_filtered = weight_df[weight_df[\"hospitalization_id\"].isin(cohort_df[\"hospitalization_id\"])]\n",
    "weight_df_filtered.to_parquet(\"../output/intermediate/weight_df.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141b69ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

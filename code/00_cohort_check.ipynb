{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05fd2e7e",
   "metadata": {},
   "source": [
    "## CRRT Cohort Check\n",
    "\n",
    "Required Checks for hospitalizations since 2021:\n",
    "\n",
    "1. Definition I  : Hospitalizations that are on a ventilator for the first 24 hours of their first icu stay.\n",
    "2. Definition II : Hospitalizations that are on vasoactive medications during the first 24 hrs of their first ICU stay. \n",
    "3. Definition III: Hospitalizations that have stage I AKI defined as \n",
    "\n",
    "    3a. 0.3 mg/dl absolute increase in serum creatinine over a 24 hour period since admission   \n",
    "\n",
    "    3b. 50% increase in serum creatinine over 7 days "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecd6d30",
   "metadata": {},
   "source": [
    "## 00 Load libraries and core CLIF tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932fa9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import json\n",
    "\n",
    "import pyCLIF\n",
    "import pyCLIF_mimic\n",
    "import waterfall\n",
    "## import outlier json\n",
    "with open('../config/outlier_config.json', 'r', encoding='utf-8') as f:\n",
    "    outlier_cfg = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196bb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = pyCLIF.load_data('clif_patient')\n",
    "hospitalization = pyCLIF.load_data('clif_hospitalization')\n",
    "adt = pyCLIF.load_data('clif_adt')\n",
    "\n",
    "# ensure id variable is of dtype character\n",
    "hospitalization['hospitalization_id']= hospitalization['hospitalization_id'].astype(str)\n",
    "patient['patient_id']= patient['patient_id'].astype(str)\n",
    "adt['hospitalization_id']= adt['hospitalization_id'].astype(str)\n",
    "\n",
    "# check for duplicates\n",
    "# patient table should be unique by patient id\n",
    "patient = pyCLIF.remove_duplicates(patient, ['patient_id'], 'patient')\n",
    "# hospitalization table should be unique by hospitalization id\n",
    "hospitalization = pyCLIF.remove_duplicates(hospitalization, ['hospitalization_id'], 'hospitalization')\n",
    "# adt table should be unique by hospitalization id and in dttm\n",
    "adt = pyCLIF.remove_duplicates(adt, ['hospitalization_id', 'hospital_id', 'in_dttm'], 'adt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b486f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize all _dttm variables to the same format\n",
    "patient = pyCLIF.convert_datetime_columns_to_site_tz(patient,  pyCLIF.helper['timezone'])\n",
    "hospitalization = pyCLIF.convert_datetime_columns_to_site_tz(hospitalization, pyCLIF.helper['timezone'])\n",
    "adt = pyCLIF.convert_datetime_columns_to_site_tz(adt,  pyCLIF.helper['timezone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33abc0b3",
   "metadata": {},
   "source": [
    "#### Hospitalizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feec31d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = hospitalization[(hospitalization['admission_dttm'].dt.year >= 2021) & \n",
    "                   (hospitalization['admission_dttm'].dt.year <= 2024) & \n",
    "                   (hospitalization['age_at_admission'] >=18)&\n",
    "                    (hospitalization['age_at_admission'] <=119)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fb0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts = {}\n",
    "strobe_counts[\"A_adult_hospitalizations_since_2021\"] = len(cohort['hospitalization_id'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3699b74a",
   "metadata": {},
   "source": [
    "#### ADT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71628f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert location category to lowercase and filter for ICU\n",
    "# Filter ADT table to include only hospitalizations from the cohort\n",
    "adt_cohort = adt[adt['hospitalization_id'].isin(cohort['hospitalization_id'])]\n",
    "adt_cohort['location_category'] = adt_cohort['location_category'].str.lower()\n",
    "# Filter to encounters that had at least one ICU stay\n",
    "icu_hospitalization_ids = adt_cohort[adt_cohort['location_category'] == 'icu']['hospitalization_id'].unique()\n",
    "adt_filtered = adt_cohort[adt_cohort['hospitalization_id'].isin(icu_hospitalization_ids)]\n",
    "strobe_counts[\"B_adult_hospitalizations_since_2021_with_icu\"] = len(adt_filtered['hospitalization_id'].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b2198",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a752490",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort = cohort[cohort['hospitalization_id'].isin(adt_filtered['hospitalization_id'])]\n",
    "print(\"Final list of cohort ids\", len(cohort['hospitalization_id'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a82569",
   "metadata": {},
   "source": [
    "# Hourly Scaffold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798dd072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) define the 'end_time' for the sequence from vitals or outcome.\n",
    "vitals_cohort = pyCLIF.load_data('clif_vitals',\n",
    "    filters={'hospitalization_id': cohort['hospitalization_id'].unique().tolist()}\n",
    ")\n",
    "vitals_cohort = pyCLIF.convert_datetime_columns_to_site_tz(vitals_cohort, pyCLIF.helper['timezone'])\n",
    "vitals_cohort = vitals_cohort.sort_values(['hospitalization_id', 'recorded_dttm'])\n",
    "\n",
    "# Get first and last vitals timestamp for each hospitalization\n",
    "vital_bounds = (\n",
    "    vitals_cohort\n",
    "    .groupby('hospitalization_id')\n",
    "    .agg({\n",
    "        'recorded_dttm': ['min', 'max']\n",
    "    })\n",
    "    .droplevel(0, axis=1)\n",
    "    .rename(columns={'min': 'first_vital_dttm', 'max': 'last_vital_dttm'})\n",
    ")\n",
    "\n",
    "# Create hourly scaffold for each hospitalization\n",
    "hourly_scaffold = pd.DataFrame([\n",
    "    (hosp_id, time)\n",
    "    for hosp_id, start, end in zip(\n",
    "        vital_bounds.index,\n",
    "        vital_bounds['first_vital_dttm'],\n",
    "        vital_bounds['last_vital_dttm']\n",
    "    )\n",
    "    for time in pd.date_range(start=start, end=end, freq='H', tz=pyCLIF.helper['timezone'])\n",
    "], columns=['hospitalization_id', 'recorded_dttm'])\n",
    "\n",
    "# Add date and hour columns\n",
    "hourly_scaffold['recorded_date'] = hourly_scaffold['recorded_dttm'].dt.date\n",
    "hourly_scaffold['recorded_hour'] = hourly_scaffold['recorded_dttm'].dt.hour\n",
    "hourly_scaffold = hourly_scaffold.drop(columns=['recorded_dttm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb9fda",
   "metadata": {},
   "source": [
    "# Definition I\n",
    "\n",
    "Hospitalizations that are on a ventilator for the first 24 hours of their first icu stay.\n",
    "\n",
    "Notes: \n",
    "\n",
    "- Use ADT table to identify hospitalizations first ICU stay ; location_category.lower == \"icu\". Fields in ADT table = hospitalization_id, location_category, in_dttm, out_dttm\n",
    "\n",
    "- Use Respiratory Support table to identify the duration of ventilator for the first ICU stay. Use device_category.lower() == \"imv\" to identify those on vent. Other vars in the table- hospitalization_id, recorded_dttm, device_category, mode_category\n",
    "- Identify hospitalizations that were on vent for the first 24 hours of their first ICU stay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803432cb",
   "metadata": {},
   "source": [
    "#### First ICU Stay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first ICU stay for each hospitalization \n",
    "\n",
    "# Convert location category to lowercase and filter for ICU\n",
    "icu_stays = adt_filtered[adt_filtered['location_category'] == 'icu'].copy()\n",
    "\n",
    "# Sort by hospitalization_id and in_dttm to get first ICU stay\n",
    "icu_stays = icu_stays.sort_values(['hospitalization_id', 'in_dttm', 'out_dttm'])\n",
    "\n",
    "# Get first ICU stay for each hospitalization\n",
    "first_icu_stays = icu_stays.groupby('hospitalization_id').first().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f565d8c",
   "metadata": {},
   "source": [
    "#### Respiratory Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf41d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load resp support \n",
    "rst_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'recorded_dttm',\n",
    "    'device_name',\n",
    "    'device_category',\n",
    "    'mode_name', \n",
    "    'mode_category',\n",
    "    'tracheostomy',\n",
    "    'fio2_set',\n",
    "    'lpm_set',\n",
    "    'resp_rate_set',\n",
    "    'peep_set',\n",
    "    'resp_rate_obs',\n",
    "    'tidal_volume_set', \n",
    "    'pressure_control_set',\n",
    "    'pressure_support_set',\n",
    "    'peak_inspiratory_pressure_set'\n",
    "\n",
    "]\n",
    "\n",
    "# 1) Load respiratory support\n",
    "resp_support_raw = pyCLIF.load_data(\n",
    "    'clif_respiratory_support',\n",
    "    columns=rst_required_columns,\n",
    "    filters={'hospitalization_id': cohort['hospitalization_id'].unique().tolist()}\n",
    ")\n",
    "\n",
    "resp_support = resp_support_raw.copy()\n",
    "resp_support['device_category'] = resp_support['device_category'].str.lower()\n",
    "resp_support['mode_category'] = resp_support['mode_category'].str.lower()\n",
    "resp_support['lpm_set'] = pd.to_numeric(resp_support['lpm_set'], errors='coerce')\n",
    "resp_support['resp_rate_set'] = pd.to_numeric(resp_support['resp_rate_set'], errors='coerce')\n",
    "resp_support['peep_set'] = pd.to_numeric(resp_support['peep_set'], errors='coerce')\n",
    "resp_support['resp_rate_obs'] = pd.to_numeric(resp_support['resp_rate_obs'], errors='coerce')\n",
    "resp_support = resp_support.sort_values(['hospitalization_id', 'recorded_dttm'])\n",
    "# del resp_support_raw\n",
    "\n",
    "print(\"\\n=== Apply outlier thresholds ===\\n\")\n",
    "resp_support['fio2_set'] = pd.to_numeric(resp_support['fio2_set'], errors='coerce')\n",
    "# (Optional) If FiO2 is >1 on average => scale by /100\n",
    "fio2_mean = resp_support['fio2_set'].mean(skipna=True)\n",
    "# If the mean is greater than 1, divide 'fio2_set' by 100\n",
    "if fio2_mean and fio2_mean > 1.0:\n",
    "    # Only divide values greater than 1 to avoid re-dividing already correct values\n",
    "    resp_support.loc[resp_support['fio2_set'] > 1, 'fio2_set'] = \\\n",
    "        resp_support.loc[resp_support['fio2_set'] > 1, 'fio2_set'] / 100\n",
    "    print(\"Updated fio2_set to be between 0.21 and 1\")\n",
    "else:\n",
    "    print(\"FIO2_SET mean=\", fio2_mean, \"is within the required range\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Identify encounters on IMV\n",
    "# Create mask to identify IMV entries\n",
    "imv_mask = resp_support['device_category'].str.contains(\"imv\", case=False, na=False)\n",
    "\n",
    "# Get unique hospitalization_ids with at least one IMV entry\n",
    "resp_stitched_imv_ids = resp_support[imv_mask][['hospitalization_id']].drop_duplicates()\n",
    "\n",
    "strobe_counts[\"C_adult_hospitalizations_since_2021_with_icu_imv\"] = len(resp_stitched_imv_ids['hospitalization_id'].drop_duplicates())\n",
    "# Filter the full table to just these hospitalization_ids\n",
    "resp_support_filtered = resp_support[\n",
    "    resp_support[\"hospitalization_id\"].isin(resp_stitched_imv_ids[\"hospitalization_id\"])\n",
    "].reset_index(drop=True)\n",
    "\n",
    "# filter down to only those hospitalization_ids that are in the cohort\n",
    "all_ids = cohort[cohort['hospitalization_id'].isin(resp_support_filtered['hospitalization_id'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ec386",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a5add",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Final list of ids adult_hospitalizations_since_2021_with_icu_imv\", len(all_ids['hospitalization_id'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c90675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"pandas\")\n",
    "\n",
    "processed_resp_support = waterfall.process_resp_support_waterfall(resp_support_filtered, \n",
    "                                                        id_col = \"hospitalization_id\",\n",
    "                                                        verbose = True)\n",
    "\n",
    "processed_resp_support = pyCLIF.convert_datetime_columns_to_site_tz(processed_resp_support, pyCLIF.helper['timezone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfbbe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vent_records = processed_resp_support.merge(\n",
    "    first_icu_stays[['hospitalization_id', 'in_dttm', 'out_dttm']], \n",
    "    on='hospitalization_id', \n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Create on_vent column (1 when device_category is IMV, 0 otherwise)\n",
    "vent_records['on_vent'] = (vent_records['device_category'].str.lower() == 'imv').astype(int)\n",
    "\n",
    "# Create in_icu column (1 when timestamp is between ICU admission and discharge)\n",
    "vent_records['in_icu'] = (\n",
    "    (vent_records['recorded_dttm'] >= vent_records['in_dttm']) & \n",
    "    (vent_records['recorded_dttm'] <= vent_records['out_dttm'])\n",
    ").astype(int)\n",
    "\n",
    "# Calculate window end (24 hours after ICU admission)\n",
    "vent_records['window_end'] = vent_records['in_dttm'] + pd.Timedelta(hours=24)\n",
    "\n",
    "# Flag records in first 24h of ICU stay\n",
    "vent_records['in_icu_24h'] = (\n",
    "    (vent_records['recorded_dttm'] >= vent_records['in_dttm']) & \n",
    "    (vent_records['recorded_dttm'] <= vent_records['window_end'])\n",
    ").astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356507d1",
   "metadata": {},
   "source": [
    "While aggregating flags at the hourly level, I used the last value during that hour assuming the last value better represents the patient's status going into the next hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dcaf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_hourly = vent_records[['hospitalization_id', 'recorded_dttm', \n",
    "                             'on_vent', 'in_icu', 'in_icu_24h']]\n",
    "\n",
    "# Create recorded_date and recorded_hour columns\n",
    "cohort_hourly['recorded_date'] = cohort_hourly['recorded_dttm'].dt.date\n",
    "cohort_hourly['recorded_hour'] = cohort_hourly['recorded_dttm'].dt.hour\n",
    "\n",
    "# Aggregate by hospitalization_id, recorded_date, and recorded_hour\n",
    "# First sort by time and get last value in hour, preserving the actual timestamp\n",
    "cohort_hourly_agg = (\n",
    "    cohort_hourly\n",
    "    .sort_values(['hospitalization_id', 'recorded_dttm'])\n",
    "    .groupby(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .agg({\n",
    "        'on_vent': 'last',        # Last vent status in hour\n",
    "        'in_icu': 'last',         # Last ICU status in hour\n",
    "        'in_icu_24h': 'last'      # Last 24h status in hour\n",
    "    })\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0552ff05",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = hourly_scaffold.merge(\n",
    "    cohort_hourly_agg,\n",
    "    on=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "final_df = (\n",
    "    final_df\n",
    "    .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .groupby(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .last()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce18da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  forward fill missing hours\n",
    "final_df = (\n",
    "    final_df\n",
    "    .set_index('hospitalization_id')\n",
    "    .groupby('hospitalization_id')\n",
    "    .ffill()\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf5d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate def_1 flag directly from final_df\n",
    "def_1_status = (\n",
    "    final_df[final_df['in_icu_24h'] == 1]  # Only look at records in first 24h\n",
    "    .groupby('hospitalization_id')\n",
    "    .agg({\n",
    "        'on_vent': 'min'  # Will be 1 only if ALL hours in first 24h were on_vent=1\n",
    "    })\n",
    ")\n",
    "\n",
    "def_1_status['def_1'] = (def_1_status['on_vent'] == 1).astype(int)\n",
    "\n",
    "# Merge back to original dataframe\n",
    "final_df = final_df.merge(\n",
    "    def_1_status[['def_1']], \n",
    "    on='hospitalization_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Hospitalizations meeting def_1: {def_1_status['def_1'].sum()}\")\n",
    "strobe_counts[\"Hospitalizations meeting def_1 (On vent for first 24 hrs of first ICU stay)\"] = def_1_status['def_1'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e57ee5b",
   "metadata": {},
   "source": [
    "# Definition II\n",
    "Hospitalizations that are on vasoactive medications during the first 24 hrs of their first ICU stay.\n",
    "\n",
    "\n",
    "#### Medication Admin Continuous\n",
    "\n",
    "- Filter down to the required meds and the cohort\n",
    "- Identify if any of these meds were administered continuously during that hour, and create a flag for each med at the hourly level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe15f638",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'admin_dttm',\n",
    "    'med_name',\n",
    "    'med_category',\n",
    "    'med_dose',\n",
    "    'med_dose_unit'\n",
    "]\n",
    "meds_of_interest = [\n",
    "    'norepinephrine', 'epinephrine', 'phenylephrine', 'vasopressin',\n",
    "    'dopamine', 'angiotensin','dobutamine'\n",
    "]\n",
    "\n",
    "meds_filters = {\n",
    "    'hospitalization_id': all_ids['hospitalization_id'].unique().tolist(),\n",
    "    'med_category': meds_of_interest\n",
    "}\n",
    "meds = pyCLIF.load_data('clif_medication_admin_continuous', columns=meds_required_columns, filters=meds_filters)\n",
    "\n",
    "# ensure correct format\n",
    "meds['hospitalization_id']= meds['hospitalization_id'].astype(str)\n",
    "meds['med_dose_unit'] = meds['med_dose_unit'].str.lower()\n",
    "meds = pyCLIF.convert_datetime_columns_to_site_tz(meds,  pyCLIF.helper['timezone'])\n",
    "meds['med_dose'] = pd.to_numeric(meds['med_dose'], errors='coerce')\n",
    "# Create 'date' and 'hour_of_day' columns\n",
    "meds['recorded_date'] = meds['admin_dttm'].dt.date\n",
    "meds['recorded_hour'] = meds['admin_dttm'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbb6459",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts[\"D_adult_hospitalizations_since_2021_icu_meds\"] = len(meds['hospitalization_id'].drop_duplicates())\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2d225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meds.value_counts('med_category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0a0081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter meds_filtered for the medications in red_meds_list\n",
    "meds_filtered = meds[meds['med_category'].isin(meds_of_interest)].copy()\n",
    "\n",
    "# Create a flag for each medication in red_meds_list\n",
    "for med in meds_of_interest:\n",
    "    # Create a flag that is 1 if the medication was administered in that hour, 0 otherwise\n",
    "    meds_filtered[med + '_flag'] = np.where((meds_filtered['med_category'] == med) & \n",
    "                                         (meds_filtered['med_dose'] > 0.0) & \n",
    "                                         (meds_filtered['med_dose'].notna()), 1, 0).astype(int)\n",
    "\n",
    "# Aggregate to get the maximum value for each flag (per hospitalization_id, recorded_date, recorded_hour)\n",
    "# This ensures that if the medication was administered even once in the hour, the flag is 1\n",
    "meds_flags = meds_filtered.groupby(['hospitalization_id', 'recorded_date', 'recorded_hour']).agg(\n",
    "    {med + '_flag': 'max' for med in meds_of_interest}\n",
    ").reset_index()\n",
    "\n",
    "#  combine all flags into a single 'red_meds_flag', you can do so like this:\n",
    "meds_flags['vasoactive_meds_flag'] = meds_flags[[med + '_flag' for med in meds_of_interest]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89abe84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(\n",
    "    meds_flags[['hospitalization_id', 'recorded_date', 'recorded_hour', 'vasoactive_meds_flag']],\n",
    "    on=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec0b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill vasoactive_meds_flag within each hospitalization\n",
    "final_df = (\n",
    "    final_df\n",
    "    .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .assign(vasoactive_meds_flag=lambda x: x.groupby('hospitalization_id')['vasoactive_meds_flag'].ffill())\n",
    ")\n",
    "\n",
    "# Calculate def_2 flag for vasoactive medications in first 24h\n",
    "def_2_status = (\n",
    "    final_df[final_df['in_icu_24h'] == 1]  # Only look at records in first 24h\n",
    "    .groupby('hospitalization_id')\n",
    "    .agg({\n",
    "        'vasoactive_meds_flag': 'max'  # 1 if ANY hour in first 24h had vasoactive meds\n",
    "    })\n",
    ")\n",
    "\n",
    "def_2_status['def_2'] = (def_2_status['vasoactive_meds_flag'] == 1).astype(int)\n",
    "\n",
    "# Merge back to original dataframe\n",
    "final_df = final_df.merge(\n",
    "    def_2_status[['def_2']], \n",
    "    on='hospitalization_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"Hospitalizations meeting def_2 (vasoactive meds in first 24h): {def_2_status['def_2'].sum()}\")\n",
    "strobe_counts[\"Hospitalizations meeting def_2 (vasoactive meds in first 24h)\"] = def_2_status['def_2'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94434772",
   "metadata": {},
   "source": [
    "# Definition III\n",
    "\n",
    "Hospitalizations that have stage I AKI defined as \n",
    "\n",
    "    3a. 0.3 mg/dl absolute increase in serum creatinine over a 24 hour period since admission   \n",
    "\n",
    "    3b. 50% increase in serum creatinine over 7 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccde3e9",
   "metadata": {},
   "source": [
    "#### Labs- Creatinine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5e5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs_required_columns = [\n",
    "    'hospitalization_id',\n",
    "    'lab_result_dttm',\n",
    "    'lab_name',\n",
    "    'lab_category',\n",
    "    'lab_value',\n",
    "    'lab_value_numeric'\n",
    "]\n",
    "labs_of_interest = ['creatinine']\n",
    "\n",
    "# Import labs\n",
    "labs_filters = {\n",
    "    'hospitalization_id': cohort['hospitalization_id'].unique().tolist(),\n",
    "    'lab_category': labs_of_interest\n",
    "}\n",
    "labs = pyCLIF.load_data('clif_labs', columns=labs_required_columns, filters=labs_filters)\n",
    "print(\"unique encounters in labs\", pyCLIF.count_unique_encounters(labs))\n",
    "labs['hospitalization_id']= labs['hospitalization_id'].astype(str)\n",
    "labs = labs.sort_values(by=['hospitalization_id', 'lab_result_dttm'])\n",
    "labs = pyCLIF.convert_datetime_columns_to_site_tz(labs, pyCLIF.helper['timezone'])\n",
    "labs['lab_value_numeric'] = pd.to_numeric(labs['lab_value_numeric'], errors='coerce')\n",
    "labs['recorded_hour'] = labs['lab_result_dttm'].dt.hour\n",
    "labs['recorded_date'] = labs['lab_result_dttm'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7463258",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts[\"E_adult_hospitalizations_since_2021_icu_creatinine\"] = len(labs['hospitalization_id'].drop_duplicates())\n",
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b54dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "creatinine = labs[['hospitalization_id','recorded_date', 'recorded_hour', 'lab_value_numeric']]\n",
    "creatinine = creatinine.sort_values(by=['hospitalization_id', 'recorded_date', 'recorded_hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b58832d",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.merge(\n",
    "    creatinine,\n",
    "    on=['hospitalization_id', 'recorded_date', 'recorded_hour'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da024e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First, get baseline creatinine (first value after ICU admission) for each hospitalization\n",
    "# baseline_creat = (\n",
    "#     final_df[final_df['lab_value_numeric'].notna()]\n",
    "#     .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "#     .groupby('hospitalization_id')\n",
    "#     .first()\n",
    "#     [['lab_value_numeric']]\n",
    "#     .rename(columns={'lab_value_numeric': 'baseline_creatinine'})\n",
    "# )\n",
    "\n",
    "# # Merge baseline back to main df\n",
    "# final_df = final_df.merge(baseline_creat, on='hospitalization_id', how='left')\n",
    "\n",
    "# # Forward fill creatinine for up to 24 hours only\n",
    "# final_df = (\n",
    "#     final_df\n",
    "#     .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "#     .assign(\n",
    "#         # Create a flag for values within 24h of baseline measurement\n",
    "#         within_24h_baseline=lambda x: x.groupby('hospitalization_id')['recorded_date'].transform(\n",
    "#             lambda g: (g <= g.iloc[0] + pd.Timedelta(days=1))\n",
    "#         ),\n",
    "#         # Forward fill creatinine only within 24h window\n",
    "#         lab_value_numeric_filled=lambda x: x.groupby('hospitalization_id').apply(\n",
    "#             lambda group: group['lab_value_numeric'].where(\n",
    "#                 group['within_24h_baseline'], np.nan\n",
    "#             ).ffill()\n",
    "#         ).reset_index(0, drop=True)\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Calculate def_3a: 0.3 mg/dl increase over 24h period\n",
    "# creat_24h = (\n",
    "#     final_df[final_df['within_24h_baseline']]\n",
    "#     .groupby('hospitalization_id')\n",
    "#     .agg({\n",
    "#         'lab_value_numeric_filled': 'last',  # Creatinine at 24h\n",
    "#         'baseline_creatinine': 'first'\n",
    "#     })\n",
    "# )\n",
    "# creat_24h['def_3a'] = (\n",
    "#     (creat_24h['lab_value_numeric_filled'] - creat_24h['baseline_creatinine']) >= 0.3\n",
    "# ).astype(int)\n",
    "\n",
    "# # Calculate def_3b: 50% increase over 7 days\n",
    "# # Create 7-day window flag\n",
    "# final_df['within_7d_baseline'] = final_df.groupby('hospitalization_id')['recorded_date'].transform(\n",
    "#     lambda g: (g <= g.iloc[0] + pd.Timedelta(days=7))\n",
    "# )\n",
    "\n",
    "# creat_7d = (\n",
    "#     final_df[final_df['within_7d_baseline'] & final_df['lab_value_numeric'].notna()]\n",
    "#     .groupby('hospitalization_id')\n",
    "#     .agg({\n",
    "#         'lab_value_numeric': 'last',  # Creatinine at 7 days (no forward fill beyond 24h)\n",
    "#         'baseline_creatinine': 'first'\n",
    "#     })\n",
    "# )\n",
    "# creat_7d['def_3b'] = (\n",
    "#     (creat_7d['lab_value_numeric'] / creat_7d['baseline_creatinine']) >= 1.5\n",
    "# ).astype(int)\n",
    "\n",
    "# # Combine def_3a and def_3b\n",
    "# aki_flags = creat_24h[['def_3a']].merge(creat_7d[['def_3b']], on='hospitalization_id', how='outer').fillna(0)\n",
    "# aki_flags['def_3'] = ((aki_flags['def_3a'] == 1) | (aki_flags['def_3b'] == 1)).astype(int)\n",
    "\n",
    "# # Merge back to final_df\n",
    "# final_df = final_df.merge(aki_flags, on='hospitalization_id', how='left')\n",
    "\n",
    "# print(f\"Hospitalizations with def_3a (0.3 mg/dl increase in 24h): {aki_flags['def_3a'].sum()}\")\n",
    "# print(f\"Hospitalizations with def_3b (50% increase in 7d): {aki_flags['def_3b'].sum()}\")\n",
    "# print(f\"Hospitalizations with def_3 (either 3a or 3b): {aki_flags['def_3'].sum()}\")\n",
    "\n",
    "# strobe_counts[\"Hospitalizations with def_3a (0.3 mg/dl increase in 24h)\"] = aki_flags['def_3a'].sum()\n",
    "# strobe_counts[\"Hospitalizations with def_3b (50% increase in 7d)\"] = aki_flags['def_3b'].sum()\n",
    "# strobe_counts[\"Hospitalizations with def_3 (either 3a or 3b)\"] =aki_flags['def_3'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8127d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "strobe_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e4bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get ICU admission times for reference\n",
    "icu_admission_times = first_icu_stays[['hospitalization_id', 'in_dttm']].copy()\n",
    "icu_admission_times['icu_admission_date'] = icu_admission_times['in_dttm'].dt.date\n",
    "\n",
    "# Merge ICU admission reference to final_df\n",
    "final_df = final_df.merge(icu_admission_times[['hospitalization_id', 'icu_admission_date']], \n",
    "                         on='hospitalization_id', how='left')\n",
    "\n",
    "# Get baseline creatinine (first value at or after ICU admission)\n",
    "baseline_creat = (\n",
    "    final_df[\n",
    "        (final_df['lab_value_numeric'].notna()) & \n",
    "        (final_df['recorded_date'] >= final_df['icu_admission_date'])  # Only after ICU admission\n",
    "    ]\n",
    "    .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .groupby('hospitalization_id')\n",
    "    .first()\n",
    "    [['lab_value_numeric', 'recorded_date']]\n",
    "    .rename(columns={'lab_value_numeric': 'baseline_creatinine', \n",
    "                    'recorded_date': 'baseline_creatinine_date'})\n",
    ")\n",
    "\n",
    "# Merge baseline back to main df\n",
    "final_df = final_df.merge(baseline_creat, on='hospitalization_id', how='left')\n",
    "\n",
    "# Create proper time windows from ICU admission\n",
    "final_df['within_24h_icu'] = (\n",
    "    (final_df['recorded_date'] >= final_df['icu_admission_date']) &\n",
    "    (final_df['recorded_date'] <= (final_df['icu_admission_date'] + pd.Timedelta(days=1)))\n",
    ")\n",
    "\n",
    "final_df['within_7d_icu'] = (\n",
    "    (final_df['recorded_date'] >= final_df['icu_admission_date']) &\n",
    "    (final_df['recorded_date'] <= (final_df['icu_admission_date'] + pd.Timedelta(days=7)))\n",
    ")\n",
    "\n",
    "# Forward fill creatinine for up to 24 hours from ICU admission only\n",
    "final_df = (\n",
    "    final_df\n",
    "    .sort_values(['hospitalization_id', 'recorded_date', 'recorded_hour'])\n",
    "    .assign(\n",
    "        # Forward fill creatinine only within 24h window from ICU admission\n",
    "        lab_value_numeric_filled=lambda x: x.groupby('hospitalization_id').apply(\n",
    "            lambda group: group['lab_value_numeric'].where(\n",
    "                group['within_24h_icu'], np.nan\n",
    "            ).ffill()\n",
    "        ).reset_index(0, drop=True)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate def_3a: 0.3 mg/dl increase within 24h of ICU admission\n",
    "creat_24h = (\n",
    "    final_df[final_df['within_24h_icu']]\n",
    "    .groupby('hospitalization_id')\n",
    "    .agg({\n",
    "        'lab_value_numeric_filled': 'last',  # Last creatinine in 24h window from ICU admission\n",
    "        'baseline_creatinine': 'first'\n",
    "    })\n",
    ")\n",
    "\n",
    "# Only calculate def_3a if we have both baseline and 24h values\n",
    "creat_24h = creat_24h.dropna()\n",
    "creat_24h['def_3a'] = (\n",
    "    (creat_24h['lab_value_numeric_filled'] - creat_24h['baseline_creatinine']) >= 0.3\n",
    ").astype(int)\n",
    "\n",
    "# Calculate def_3b: 50% increase within 7 days of ICU admission\n",
    "creat_7d = (\n",
    "    final_df[\n",
    "        (final_df['within_7d_icu']) & \n",
    "        (final_df['lab_value_numeric'].notna())  # Only actual measurements, no forward fill\n",
    "    ]\n",
    "    .groupby('hospitalization_id')\n",
    "    .agg({\n",
    "        'lab_value_numeric': 'last',  # Last actual creatinine in 7d window from ICU admission\n",
    "        'baseline_creatinine': 'first'\n",
    "    })\n",
    ")\n",
    "\n",
    "# Only calculate def_3b if we have both baseline and 7d values\n",
    "creat_7d = creat_7d.dropna()\n",
    "creat_7d['def_3b'] = (\n",
    "    (creat_7d['lab_value_numeric'] / creat_7d['baseline_creatinine']) >= 1.5\n",
    ").astype(int)\n",
    "\n",
    "# Combine def_3a and def_3b\n",
    "aki_flags = creat_24h[['def_3a']].merge(creat_7d[['def_3b']], on='hospitalization_id', how='outer').fillna(0)\n",
    "aki_flags['def_3'] = ((aki_flags['def_3a'] == 1) | (aki_flags['def_3b'] == 1)).astype(int)\n",
    "\n",
    "# Merge back to final_df\n",
    "final_df = final_df.merge(aki_flags[['def_3a', 'def_3b', 'def_3']], on='hospitalization_id', how='left').fillna(0)\n",
    "\n",
    "print(f\"Hospitalizations with def_3a (0.3 mg/dl increase in 24h from ICU admission): {aki_flags['def_3a'].sum()}\")\n",
    "print(f\"Hospitalizations with def_3b (50% increase in 7d from ICU admission): {aki_flags['def_3b'].sum()}\")\n",
    "print(f\"Hospitalizations with def_3 (either 3a or 3b): {aki_flags['def_3'].sum()}\")\n",
    "\n",
    "# Update strobe counts\n",
    "strobe_counts[\"Hospitalizations with def_3a (0.3 mg/dl increase in 24h from ICU admission)\"] = aki_flags['def_3a'].sum()\n",
    "strobe_counts[\"Hospitalizations with def_3b (50% increase in 7d from ICU admission)\"] = aki_flags['def_3b'].sum()\n",
    "strobe_counts[\"Hospitalizations with def_3 (either 3a or 3b from ICU admission)\"] = aki_flags['def_3'].sum()\n",
    "\n",
    "# Optional: Show some validation statistics\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"Hospitalizations with baseline creatinine: {baseline_creat.shape[0]}\")\n",
    "print(f\"Hospitalizations with 24h creatinine data: {creat_24h.shape[0]}\")\n",
    "print(f\"Hospitalizations with 7d creatinine data: {creat_7d.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc560ee0",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218fb236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import UpSet, from_indicators\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs('../output/final', exist_ok=True)\n",
    "\n",
    "# Create a summary dataframe with all definitions\n",
    "summary_df = final_df[['hospitalization_id', 'def_1', 'def_2', 'def_3']].drop_duplicates()\n",
    "\n",
    "# Fill NaN values with 0 for the definitions\n",
    "summary_df = summary_df.fillna(0)\n",
    "\n",
    "# Convert to boolean for upset plot\n",
    "summary_df['def_1'] = summary_df['def_1'].astype(bool)\n",
    "summary_df['def_2'] = summary_df['def_2'].astype(bool) \n",
    "summary_df['def_3'] = summary_df['def_3'].astype(bool)\n",
    "\n",
    "# Create upset plot with better sizing\n",
    "fig = plt.figure(figsize=(16, 12))  # Larger figure size\n",
    "upset_data = from_indicators(['def_1', 'def_2', 'def_3'], \n",
    "                           data=summary_df.set_index('hospitalization_id'))\n",
    "\n",
    "upset = UpSet(upset_data, \n",
    "              subset_size='count',\n",
    "              show_counts=True,\n",
    "              sort_by='cardinality',\n",
    "              element_size=50,  # Larger dots\n",
    "              with_lines=True)  # Add connecting lines for clarity\n",
    "\n",
    "# Plot with custom spacing\n",
    "upset.plot(fig=fig)\n",
    "\n",
    "# Adjust spacing to prevent overlapping\n",
    "plt.subplots_adjust(left=0.2, bottom=0.2, right=0.95, top=0.85, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Add title with more space\n",
    "plt.suptitle('Overlap of Clinical Definitions\\n(def_1: 24h ventilation, def_2: 24h vasoactives, def_3: AKI)', \n",
    "             fontsize=16, y=0.95)\n",
    "\n",
    "# Adjust font sizes for better readability\n",
    "for ax in fig.get_axes():\n",
    "    for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "                 ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "        item.set_fontsize(12)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig('../output/final/definition_overlap_upset_plot.png', dpi=300, bbox_inches='tight')\n",
    "plt.savefig('../output/final/definition_overlap_upset_plot.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Create detailed summary table\n",
    "combinations = []\n",
    "\n",
    "# Individual definitions\n",
    "combinations.append({\n",
    "    'Combination': 'def_1 only',\n",
    "    'Description': '24h ventilation only',\n",
    "    'Count': int(((summary_df['def_1']) & (~summary_df['def_2']) & (~summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "combinations.append({\n",
    "    'Combination': 'def_2 only', \n",
    "    'Description': '24h vasoactives only',\n",
    "    'Count': int(((~summary_df['def_1']) & (summary_df['def_2']) & (~summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "combinations.append({\n",
    "    'Combination': 'def_3 only',\n",
    "    'Description': 'AKI only', \n",
    "    'Count': int(((~summary_df['def_1']) & (~summary_df['def_2']) & (summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "# Pairwise combinations\n",
    "combinations.append({\n",
    "    'Combination': 'def_1 & def_2',\n",
    "    'Description': '24h ventilation + 24h vasoactives',\n",
    "    'Count': int(((summary_df['def_1']) & (summary_df['def_2']) & (~summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "combinations.append({\n",
    "    'Combination': 'def_1 & def_3',\n",
    "    'Description': '24h ventilation + AKI',\n",
    "    'Count': int(((summary_df['def_1']) & (~summary_df['def_2']) & (summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "combinations.append({\n",
    "    'Combination': 'def_2 & def_3', \n",
    "    'Description': '24h vasoactives + AKI',\n",
    "    'Count': int(((~summary_df['def_1']) & (summary_df['def_2']) & (summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "# All three\n",
    "combinations.append({\n",
    "    'Combination': 'def_1 & def_2 & def_3',\n",
    "    'Description': 'All three conditions',\n",
    "    'Count': int(((summary_df['def_1']) & (summary_df['def_2']) & (summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "# None\n",
    "combinations.append({\n",
    "    'Combination': 'None',\n",
    "    'Description': 'No conditions met',\n",
    "    'Count': int(((~summary_df['def_1']) & (~summary_df['def_2']) & (~summary_df['def_3'])).sum())\n",
    "})\n",
    "\n",
    "# Create summary table\n",
    "combo_df = pd.DataFrame(combinations)\n",
    "combo_df['Percentage'] = (combo_df['Count'] / len(summary_df) * 100).round(1)\n",
    "\n",
    "print(\"Summary Table of Definition Combinations:\")\n",
    "print(\"=\" * 60)\n",
    "print(combo_df.to_string(index=False))\n",
    "\n",
    "# Also show totals for each individual definition\n",
    "individual_totals = {\n",
    "    'def_1_24h_ventilation_count': int(summary_df['def_1'].sum()),\n",
    "    'def_1_24h_ventilation_percentage': float(summary_df['def_1'].mean()*100),\n",
    "    'def_2_24h_vasoactives_count': int(summary_df['def_2'].sum()),\n",
    "    'def_2_24h_vasoactives_percentage': float(summary_df['def_2'].mean()*100),\n",
    "    'def_3_aki_count': int(summary_df['def_3'].sum()),\n",
    "    'def_3_aki_percentage': float(summary_df['def_3'].mean()*100),\n",
    "    'total_hospitalizations': int(len(summary_df))\n",
    "}\n",
    "\n",
    "print(\"\\n\\nIndividual Definition Totals:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"def_1 (24h ventilation): {individual_totals['def_1_24h_ventilation_count']} ({individual_totals['def_1_24h_ventilation_percentage']:.1f}%)\")\n",
    "print(f\"def_2 (24h vasoactives): {individual_totals['def_2_24h_vasoactives_count']} ({individual_totals['def_2_24h_vasoactives_percentage']:.1f}%)\")\n",
    "print(f\"def_3 (AKI): {individual_totals['def_3_aki_count']} ({individual_totals['def_3_aki_percentage']:.1f}%)\")\n",
    "print(f\"Total hospitalizations: {individual_totals['total_hospitalizations']}\")\n",
    "\n",
    "# Save the summary tables\n",
    "combo_df.to_csv('../output/final/definition_combinations_summary.csv', index=False)\n",
    "\n",
    "# Save individual totals as JSON for easy reading\n",
    "import json\n",
    "with open('../output/final/individual_definition_totals.json', 'w') as f:\n",
    "    json.dump(individual_totals, f, indent=2)\n",
    "\n",
    "# Save the final strobe counts\n",
    "with open('../output/final/strobe_counts.json', 'w') as f:\n",
    "    # Convert numpy types to native Python types for JSON serialization\n",
    "    strobe_counts_serializable = {}\n",
    "    for key, value in strobe_counts.items():\n",
    "        if hasattr(value, 'item'):  # numpy scalar\n",
    "            strobe_counts_serializable[key] = value.item()\n",
    "        elif isinstance(value, (np.integer, np.int64, np.int32)):\n",
    "            strobe_counts_serializable[key] = int(value)\n",
    "        elif isinstance(value, (np.floating, np.float64, np.float32)):\n",
    "            strobe_counts_serializable[key] = float(value)\n",
    "        else:\n",
    "            strobe_counts_serializable[key] = value\n",
    "    json.dump(strobe_counts_serializable, f, indent=2)\n",
    "\n",
    "print(f\"\\n\\nFiles saved to output/final/:\")\n",
    "print(\"- definition_overlap_upset_plot.png\")\n",
    "print(\"- definition_overlap_upset_plot.pdf\") \n",
    "print(\"- definition_combinations_summary.csv\")\n",
    "print(\"- individual_definition_totals.json\")\n",
    "print(\"- strobe_counts.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7778be49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".crrt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
